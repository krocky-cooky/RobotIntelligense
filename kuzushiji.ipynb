{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# くずし字 MNIST データセットの学習\n",
    "[github](https://github.com/rois-codh/kmnist)からダウンロードしたくずし字データセットを今回作成したニューラルネットワークのクラスneuralNetworkを用いて学習させ、その精度を求めた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural import neuralNetwork #自作ライブラリ\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "t_train = np.identity(10)[t_train]\n",
    "t_test = np.identity(10)[t_test]\n",
    "x_train = x_train.reshape((60000,-1))\n",
    "x_test = x_test.reshape((10000,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< successfully layers are updated >>\n"
     ]
    }
   ],
   "source": [
    "net = neuralNetwork(\n",
    "    epoch = 33000,\n",
    "    learning_rate = 0.05,\n",
    "    batch_size = 500\n",
    ")\n",
    "layer_list = [784,[500,80],10]\n",
    "net.set_layer(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch0 ---------\n",
      "loss : 363.3290027790962\n",
      "accuracy : 0.112\n",
      "time : 0.05027008056640625 [sec]\n",
      "--------------------------\n",
      "\n",
      "--------- epoch100 ---------\n",
      "loss : 138.73707333009642\n",
      "accuracy : 0.76\n",
      "time : 3.5741240978240967 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch200 ---------\n",
      "loss : 114.66171616351994\n",
      "accuracy : 0.778\n",
      "time : 7.42105507850647 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch300 ---------\n",
      "loss : 104.95167107973808\n",
      "accuracy : 0.816\n",
      "time : 11.268707036972046 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch400 ---------\n",
      "loss : 96.94527795343151\n",
      "accuracy : 0.814\n",
      "time : 15.029253959655762 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch500 ---------\n",
      "loss : 91.39363687323205\n",
      "accuracy : 0.836\n",
      "time : 18.97148895263672 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch600 ---------\n",
      "loss : 79.79922263112856\n",
      "accuracy : 0.872\n",
      "time : 22.550989151000977 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch700 ---------\n",
      "loss : 80.44433139322584\n",
      "accuracy : 0.868\n",
      "time : 26.225855112075806 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch800 ---------\n",
      "loss : 77.46947665157276\n",
      "accuracy : 0.858\n",
      "time : 30.211004972457886 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch900 ---------\n",
      "loss : 78.6750843337268\n",
      "accuracy : 0.856\n",
      "time : 33.87389302253723 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch1000 ---------\n",
      "loss : 67.0894571279965\n",
      "accuracy : 0.884\n",
      "time : 37.66529297828674 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1100 ---------\n",
      "loss : 66.04776332266634\n",
      "accuracy : 0.9\n",
      "time : 41.55128598213196 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1200 ---------\n",
      "loss : 71.21344102501297\n",
      "accuracy : 0.868\n",
      "time : 45.39480900764465 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1300 ---------\n",
      "loss : 63.68834405171994\n",
      "accuracy : 0.894\n",
      "time : 49.094290018081665 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1400 ---------\n",
      "loss : 61.95498349929892\n",
      "accuracy : 0.9\n",
      "time : 52.36699604988098 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1500 ---------\n",
      "loss : 63.20466236536696\n",
      "accuracy : 0.884\n",
      "time : 56.00801610946655 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1600 ---------\n",
      "loss : 64.66077971460594\n",
      "accuracy : 0.88\n",
      "time : 59.973225116729736 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1700 ---------\n",
      "loss : 57.92809970255884\n",
      "accuracy : 0.908\n",
      "time : 64.98819994926453 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1800 ---------\n",
      "loss : 51.325460081420395\n",
      "accuracy : 0.93\n",
      "time : 68.94476699829102 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1900 ---------\n",
      "loss : 57.001641906629025\n",
      "accuracy : 0.91\n",
      "time : 72.88464403152466 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2000 ---------\n",
      "loss : 59.98906924427585\n",
      "accuracy : 0.896\n",
      "time : 76.638503074646 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2100 ---------\n",
      "loss : 56.17110952160262\n",
      "accuracy : 0.916\n",
      "time : 80.44335603713989 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2200 ---------\n",
      "loss : 53.47833482607314\n",
      "accuracy : 0.906\n",
      "time : 84.22591495513916 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2300 ---------\n",
      "loss : 52.48245986055224\n",
      "accuracy : 0.922\n",
      "time : 87.72018504142761 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2400 ---------\n",
      "loss : 51.04824309827141\n",
      "accuracy : 0.926\n",
      "time : 91.33152914047241 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2500 ---------\n",
      "loss : 47.67441086323288\n",
      "accuracy : 0.92\n",
      "time : 94.92405009269714 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2600 ---------\n",
      "loss : 50.11162300633202\n",
      "accuracy : 0.926\n",
      "time : 98.67337894439697 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2700 ---------\n",
      "loss : 51.73301563234536\n",
      "accuracy : 0.918\n",
      "time : 103.15005111694336 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2800 ---------\n",
      "loss : 46.35608914896649\n",
      "accuracy : 0.924\n",
      "time : 106.78572607040405 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2900 ---------\n",
      "loss : 46.94517495641773\n",
      "accuracy : 0.922\n",
      "time : 110.84994506835938 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3000 ---------\n",
      "loss : 41.34578470540459\n",
      "accuracy : 0.942\n",
      "time : 114.71714496612549 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3100 ---------\n",
      "loss : 47.68111282703868\n",
      "accuracy : 0.932\n",
      "time : 118.7303831577301 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3200 ---------\n",
      "loss : 49.10390715461075\n",
      "accuracy : 0.916\n",
      "time : 122.5089099407196 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3300 ---------\n",
      "loss : 38.12535785805568\n",
      "accuracy : 0.958\n",
      "time : 126.26801896095276 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3400 ---------\n",
      "loss : 43.85092049986409\n",
      "accuracy : 0.924\n",
      "time : 130.31111311912537 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3500 ---------\n",
      "loss : 44.245067094417855\n",
      "accuracy : 0.922\n",
      "time : 134.54951095581055 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3600 ---------\n",
      "loss : 38.22988262013703\n",
      "accuracy : 0.942\n",
      "time : 139.23116612434387 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3700 ---------\n",
      "loss : 36.538727744854896\n",
      "accuracy : 0.952\n",
      "time : 142.69160294532776 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3800 ---------\n",
      "loss : 43.3085178078329\n",
      "accuracy : 0.932\n",
      "time : 146.32247614860535 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3900 ---------\n",
      "loss : 42.549819398299526\n",
      "accuracy : 0.926\n",
      "time : 150.10767316818237 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4000 ---------\n",
      "loss : 37.24752178810396\n",
      "accuracy : 0.956\n",
      "time : 153.9487280845642 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4100 ---------\n",
      "loss : 43.931250409415426\n",
      "accuracy : 0.928\n",
      "time : 157.72850012779236 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4200 ---------\n",
      "loss : 41.74108848302153\n",
      "accuracy : 0.934\n",
      "time : 161.24990916252136 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4300 ---------\n",
      "loss : 37.89161767101752\n",
      "accuracy : 0.966\n",
      "time : 165.07392406463623 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4400 ---------\n",
      "loss : 36.974683977146455\n",
      "accuracy : 0.96\n",
      "time : 168.4831941127777 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4500 ---------\n",
      "loss : 40.04236562813878\n",
      "accuracy : 0.942\n",
      "time : 172.14317512512207 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4600 ---------\n",
      "loss : 41.35514314856397\n",
      "accuracy : 0.94\n",
      "time : 176.31360697746277 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4700 ---------\n",
      "loss : 38.375593618605194\n",
      "accuracy : 0.938\n",
      "time : 180.13150095939636 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4800 ---------\n",
      "loss : 36.63439888517097\n",
      "accuracy : 0.952\n",
      "time : 183.67854404449463 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4900 ---------\n",
      "loss : 34.60785498944117\n",
      "accuracy : 0.946\n",
      "time : 187.4421501159668 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5000 ---------\n",
      "loss : 35.591845986402774\n",
      "accuracy : 0.948\n",
      "time : 191.15776801109314 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5100 ---------\n",
      "loss : 36.826187950757\n",
      "accuracy : 0.946\n",
      "time : 194.9022979736328 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5200 ---------\n",
      "loss : 37.067870943402454\n",
      "accuracy : 0.94\n",
      "time : 198.3153100013733 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5300 ---------\n",
      "loss : 35.35255121333295\n",
      "accuracy : 0.934\n",
      "time : 202.04217195510864 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5400 ---------\n",
      "loss : 36.19256313686756\n",
      "accuracy : 0.95\n",
      "time : 205.4204399585724 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5500 ---------\n",
      "loss : 34.350813849309304\n",
      "accuracy : 0.95\n",
      "time : 210.25126194953918 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5600 ---------\n",
      "loss : 32.52194472783073\n",
      "accuracy : 0.958\n",
      "time : 214.91937112808228 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5700 ---------\n",
      "loss : 31.94113099693202\n",
      "accuracy : 0.954\n",
      "time : 219.50323605537415 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5800 ---------\n",
      "loss : 35.83896602305198\n",
      "accuracy : 0.954\n",
      "time : 223.32879209518433 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5900 ---------\n",
      "loss : 34.230695638720576\n",
      "accuracy : 0.95\n",
      "time : 226.8219621181488 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6000 ---------\n",
      "loss : 33.8150355164463\n",
      "accuracy : 0.94\n",
      "time : 230.26755213737488 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6100 ---------\n",
      "loss : 32.45679794635748\n",
      "accuracy : 0.96\n",
      "time : 233.77821898460388 [sec]\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch6200 ---------\n",
      "loss : 33.70901190770036\n",
      "accuracy : 0.958\n",
      "time : 237.55121612548828 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6300 ---------\n",
      "loss : 33.752248827383156\n",
      "accuracy : 0.956\n",
      "time : 242.18638610839844 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6400 ---------\n",
      "loss : 30.873214817546625\n",
      "accuracy : 0.962\n",
      "time : 246.12248396873474 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6500 ---------\n",
      "loss : 30.6847753338347\n",
      "accuracy : 0.954\n",
      "time : 250.33747506141663 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6600 ---------\n",
      "loss : 31.070930308634367\n",
      "accuracy : 0.954\n",
      "time : 253.77099299430847 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6700 ---------\n",
      "loss : 27.81820488100822\n",
      "accuracy : 0.966\n",
      "time : 257.23845195770264 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6800 ---------\n",
      "loss : 31.04791989786742\n",
      "accuracy : 0.954\n",
      "time : 260.7291491031647 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6900 ---------\n",
      "loss : 31.101006536932577\n",
      "accuracy : 0.944\n",
      "time : 264.21441197395325 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7000 ---------\n",
      "loss : 31.89439437432631\n",
      "accuracy : 0.946\n",
      "time : 267.6760129928589 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7100 ---------\n",
      "loss : 24.84084681790464\n",
      "accuracy : 0.974\n",
      "time : 271.06702399253845 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7200 ---------\n",
      "loss : 32.44774019465632\n",
      "accuracy : 0.954\n",
      "time : 274.6682860851288 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7300 ---------\n",
      "loss : 31.02182366298779\n",
      "accuracy : 0.952\n",
      "time : 278.2225821018219 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7400 ---------\n",
      "loss : 26.386559022841578\n",
      "accuracy : 0.964\n",
      "time : 281.75992012023926 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7500 ---------\n",
      "loss : 30.773988208680976\n",
      "accuracy : 0.956\n",
      "time : 285.67555713653564 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7600 ---------\n",
      "loss : 29.879573333741835\n",
      "accuracy : 0.962\n",
      "time : 289.11775612831116 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7700 ---------\n",
      "loss : 34.44047063611103\n",
      "accuracy : 0.942\n",
      "time : 292.66180205345154 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7800 ---------\n",
      "loss : 25.83268207946859\n",
      "accuracy : 0.974\n",
      "time : 296.21927213668823 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7900 ---------\n",
      "loss : 27.813266613525066\n",
      "accuracy : 0.974\n",
      "time : 299.91908502578735 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8000 ---------\n",
      "loss : 29.161674980461335\n",
      "accuracy : 0.968\n",
      "time : 303.31841802597046 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8100 ---------\n",
      "loss : 25.958714592978712\n",
      "accuracy : 0.966\n",
      "time : 307.0392460823059 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8200 ---------\n",
      "loss : 24.23618182245768\n",
      "accuracy : 0.974\n",
      "time : 310.8182461261749 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8300 ---------\n",
      "loss : 29.960745782672692\n",
      "accuracy : 0.958\n",
      "time : 314.2930130958557 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8400 ---------\n",
      "loss : 28.615631005388\n",
      "accuracy : 0.958\n",
      "time : 318.0536789894104 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8500 ---------\n",
      "loss : 29.847484423980493\n",
      "accuracy : 0.956\n",
      "time : 321.8160181045532 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8600 ---------\n",
      "loss : 26.20725593973755\n",
      "accuracy : 0.966\n",
      "time : 325.33363914489746 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8700 ---------\n",
      "loss : 26.963156922724366\n",
      "accuracy : 0.962\n",
      "time : 329.03244614601135 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8800 ---------\n",
      "loss : 25.049545750578094\n",
      "accuracy : 0.968\n",
      "time : 332.562607049942 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8900 ---------\n",
      "loss : 24.695411270925135\n",
      "accuracy : 0.98\n",
      "time : 336.1014881134033 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9000 ---------\n",
      "loss : 25.576306246040602\n",
      "accuracy : 0.976\n",
      "time : 339.3748481273651 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9100 ---------\n",
      "loss : 25.287297935887175\n",
      "accuracy : 0.976\n",
      "time : 342.92048811912537 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9200 ---------\n",
      "loss : 24.595020137400635\n",
      "accuracy : 0.974\n",
      "time : 346.346647977829 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9300 ---------\n",
      "loss : 24.023866706507945\n",
      "accuracy : 0.968\n",
      "time : 349.92087411880493 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9400 ---------\n",
      "loss : 24.403755569808325\n",
      "accuracy : 0.978\n",
      "time : 353.79280614852905 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9500 ---------\n",
      "loss : 27.497885157514855\n",
      "accuracy : 0.96\n",
      "time : 357.3039381504059 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9600 ---------\n",
      "loss : 23.148788377307927\n",
      "accuracy : 0.974\n",
      "time : 360.88637614250183 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9700 ---------\n",
      "loss : 24.566864719972763\n",
      "accuracy : 0.958\n",
      "time : 364.4205379486084 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9800 ---------\n",
      "loss : 22.329887770766465\n",
      "accuracy : 0.978\n",
      "time : 368.00760102272034 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9900 ---------\n",
      "loss : 25.17193262093607\n",
      "accuracy : 0.972\n",
      "time : 371.33969616889954 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch10000 ---------\n",
      "loss : 22.505954741008217\n",
      "accuracy : 0.976\n",
      "time : 374.70339703559875 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10100 ---------\n",
      "loss : 24.57920085008313\n",
      "accuracy : 0.968\n",
      "time : 378.23555612564087 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10200 ---------\n",
      "loss : 22.62569616010738\n",
      "accuracy : 0.97\n",
      "time : 381.71943497657776 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10300 ---------\n",
      "loss : 23.668064379669193\n",
      "accuracy : 0.974\n",
      "time : 385.57204508781433 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10400 ---------\n",
      "loss : 22.81926072433197\n",
      "accuracy : 0.974\n",
      "time : 389.12080216407776 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10500 ---------\n",
      "loss : 23.957449156595608\n",
      "accuracy : 0.972\n",
      "time : 392.5946481227875 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10600 ---------\n",
      "loss : 22.517235222601652\n",
      "accuracy : 0.976\n",
      "time : 396.1252911090851 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10700 ---------\n",
      "loss : 20.816885756461225\n",
      "accuracy : 0.974\n",
      "time : 399.63679909706116 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10800 ---------\n",
      "loss : 25.601956381143463\n",
      "accuracy : 0.964\n",
      "time : 403.0924310684204 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10900 ---------\n",
      "loss : 20.947895086214867\n",
      "accuracy : 0.98\n",
      "time : 406.3620719909668 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11000 ---------\n",
      "loss : 19.800340343908907\n",
      "accuracy : 0.984\n",
      "time : 409.8867361545563 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11100 ---------\n",
      "loss : 20.28122643178482\n",
      "accuracy : 0.982\n",
      "time : 413.26809215545654 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11200 ---------\n",
      "loss : 21.02214437258953\n",
      "accuracy : 0.982\n",
      "time : 417.2740800380707 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11300 ---------\n",
      "loss : 20.604235872063267\n",
      "accuracy : 0.978\n",
      "time : 420.8104021549225 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11400 ---------\n",
      "loss : 19.15936431936867\n",
      "accuracy : 0.982\n",
      "time : 424.2673101425171 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11500 ---------\n",
      "loss : 20.240944775438113\n",
      "accuracy : 0.984\n",
      "time : 427.9158339500427 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11600 ---------\n",
      "loss : 22.524930075976144\n",
      "accuracy : 0.972\n",
      "time : 431.5157289505005 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11700 ---------\n",
      "loss : 22.90849814508482\n",
      "accuracy : 0.972\n",
      "time : 435.0461061000824 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11800 ---------\n",
      "loss : 19.259840623850394\n",
      "accuracy : 0.984\n",
      "time : 438.3449740409851 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11900 ---------\n",
      "loss : 23.408401004487963\n",
      "accuracy : 0.966\n",
      "time : 441.89186906814575 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12000 ---------\n",
      "loss : 18.61799696883138\n",
      "accuracy : 0.984\n",
      "time : 445.28101801872253 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12100 ---------\n",
      "loss : 21.858169175919592\n",
      "accuracy : 0.97\n",
      "time : 448.89776611328125 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12200 ---------\n",
      "loss : 22.822054375277396\n",
      "accuracy : 0.968\n",
      "time : 452.8052740097046 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch12300 ---------\n",
      "loss : 19.143623112878785\n",
      "accuracy : 0.986\n",
      "time : 456.2841830253601 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12400 ---------\n",
      "loss : 17.769637518891862\n",
      "accuracy : 0.984\n",
      "time : 459.80297899246216 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12500 ---------\n",
      "loss : 17.68043068332907\n",
      "accuracy : 0.988\n",
      "time : 463.3378429412842 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12600 ---------\n",
      "loss : 21.628068810718265\n",
      "accuracy : 0.982\n",
      "time : 466.83443903923035 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12700 ---------\n",
      "loss : 22.65399744836519\n",
      "accuracy : 0.966\n",
      "time : 470.13038301467896 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12800 ---------\n",
      "loss : 21.721196229742276\n",
      "accuracy : 0.972\n",
      "time : 473.4984800815582 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12900 ---------\n",
      "loss : 20.07413070298228\n",
      "accuracy : 0.972\n",
      "time : 476.97711300849915 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13000 ---------\n",
      "loss : 20.75055150936429\n",
      "accuracy : 0.97\n",
      "time : 480.42065811157227 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13100 ---------\n",
      "loss : 17.761323960188093\n",
      "accuracy : 0.984\n",
      "time : 484.3898460865021 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13200 ---------\n",
      "loss : 18.805115751474602\n",
      "accuracy : 0.982\n",
      "time : 487.8742849826813 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13300 ---------\n",
      "loss : 16.634341283334642\n",
      "accuracy : 0.988\n",
      "time : 491.33649706840515 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13400 ---------\n",
      "loss : 22.03128179446596\n",
      "accuracy : 0.972\n",
      "time : 494.8893880844116 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13500 ---------\n",
      "loss : 21.058158088948158\n",
      "accuracy : 0.974\n",
      "time : 498.3707950115204 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13600 ---------\n",
      "loss : 19.54694576037238\n",
      "accuracy : 0.984\n",
      "time : 501.72807216644287 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13700 ---------\n",
      "loss : 16.85991364178526\n",
      "accuracy : 0.986\n",
      "time : 504.98843693733215 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13800 ---------\n",
      "loss : 20.120184526758187\n",
      "accuracy : 0.974\n",
      "time : 508.5703101158142 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13900 ---------\n",
      "loss : 19.793329232202847\n",
      "accuracy : 0.976\n",
      "time : 511.96331810951233 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14000 ---------\n",
      "loss : 18.253834896997517\n",
      "accuracy : 0.984\n",
      "time : 515.8680860996246 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14100 ---------\n",
      "loss : 22.071807665034637\n",
      "accuracy : 0.972\n",
      "time : 519.4901010990143 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14200 ---------\n",
      "loss : 17.78001802175045\n",
      "accuracy : 0.984\n",
      "time : 523.096272945404 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14300 ---------\n",
      "loss : 18.09890650892972\n",
      "accuracy : 0.976\n",
      "time : 526.6548120975494 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14400 ---------\n",
      "loss : 19.72974877533499\n",
      "accuracy : 0.974\n",
      "time : 530.2123370170593 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14500 ---------\n",
      "loss : 20.691240522130848\n",
      "accuracy : 0.974\n",
      "time : 535.7935171127319 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14600 ---------\n",
      "loss : 19.554054008145556\n",
      "accuracy : 0.976\n",
      "time : 539.7562220096588 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14700 ---------\n",
      "loss : 19.05037176906329\n",
      "accuracy : 0.972\n",
      "time : 543.7200469970703 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14800 ---------\n",
      "loss : 17.44565630451532\n",
      "accuracy : 0.978\n",
      "time : 547.8574459552765 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14900 ---------\n",
      "loss : 17.104130688703034\n",
      "accuracy : 0.988\n",
      "time : 552.1380341053009 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15000 ---------\n",
      "loss : 14.495738743444996\n",
      "accuracy : 0.99\n",
      "time : 557.9912140369415 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15100 ---------\n",
      "loss : 18.95584141122797\n",
      "accuracy : 0.982\n",
      "time : 562.0346460342407 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15200 ---------\n",
      "loss : 19.596053317484895\n",
      "accuracy : 0.976\n",
      "time : 565.9764540195465 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15300 ---------\n",
      "loss : 17.351820462821607\n",
      "accuracy : 0.984\n",
      "time : 570.3007950782776 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15400 ---------\n",
      "loss : 18.60559281943197\n",
      "accuracy : 0.984\n",
      "time : 576.5652871131897 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15500 ---------\n",
      "loss : 17.878559180279147\n",
      "accuracy : 0.98\n",
      "time : 580.746344089508 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15600 ---------\n",
      "loss : 15.462214185021008\n",
      "accuracy : 0.986\n",
      "time : 584.180459022522 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15700 ---------\n",
      "loss : 17.73969984517211\n",
      "accuracy : 0.98\n",
      "time : 587.4532430171967 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15800 ---------\n",
      "loss : 17.617083582450284\n",
      "accuracy : 0.982\n",
      "time : 590.8692581653595 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15900 ---------\n",
      "loss : 13.66577256642826\n",
      "accuracy : 0.994\n",
      "time : 594.2999861240387 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16000 ---------\n",
      "loss : 18.883147475957834\n",
      "accuracy : 0.974\n",
      "time : 597.9604380130768 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16100 ---------\n",
      "loss : 19.3904494310607\n",
      "accuracy : 0.982\n",
      "time : 602.316164970398 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16200 ---------\n",
      "loss : 16.893746376343806\n",
      "accuracy : 0.976\n",
      "time : 605.9295909404755 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16300 ---------\n",
      "loss : 16.694503089822213\n",
      "accuracy : 0.976\n",
      "time : 609.5667431354523 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16400 ---------\n",
      "loss : 17.696546314328927\n",
      "accuracy : 0.972\n",
      "time : 613.1458139419556 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16500 ---------\n",
      "loss : 16.317836256189654\n",
      "accuracy : 0.972\n",
      "time : 616.6069650650024 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16600 ---------\n",
      "loss : 16.332269672874908\n",
      "accuracy : 0.99\n",
      "time : 620.0272879600525 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16700 ---------\n",
      "loss : 15.851597184300404\n",
      "accuracy : 0.992\n",
      "time : 623.2959411144257 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16800 ---------\n",
      "loss : 15.08667322154325\n",
      "accuracy : 0.988\n",
      "time : 626.7495579719543 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16900 ---------\n",
      "loss : 15.573985548942016\n",
      "accuracy : 0.984\n",
      "time : 630.109218120575 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17000 ---------\n",
      "loss : 14.447168325681252\n",
      "accuracy : 0.988\n",
      "time : 634.440582036972 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17100 ---------\n",
      "loss : 15.483054273440585\n",
      "accuracy : 0.988\n",
      "time : 638.0987720489502 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17200 ---------\n",
      "loss : 16.754116059545254\n",
      "accuracy : 0.982\n",
      "time : 641.9335050582886 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17300 ---------\n",
      "loss : 14.758243385471266\n",
      "accuracy : 0.988\n",
      "time : 646.3917050361633 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17400 ---------\n",
      "loss : 15.960153432198865\n",
      "accuracy : 0.984\n",
      "time : 660.6044731140137 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17500 ---------\n",
      "loss : 16.31468212517507\n",
      "accuracy : 0.982\n",
      "time : 671.5753309726715 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17600 ---------\n",
      "loss : 16.099277921497332\n",
      "accuracy : 0.984\n",
      "time : 677.4208309650421 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17700 ---------\n",
      "loss : 15.676718402139436\n",
      "accuracy : 0.982\n",
      "time : 680.4792959690094 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17800 ---------\n",
      "loss : 17.015060178789895\n",
      "accuracy : 0.98\n",
      "time : 683.2190101146698 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17900 ---------\n",
      "loss : 15.973973594879503\n",
      "accuracy : 0.982\n",
      "time : 687.6064269542694 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18000 ---------\n",
      "loss : 18.62024548600137\n",
      "accuracy : 0.968\n",
      "time : 691.2643320560455 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18100 ---------\n",
      "loss : 15.37076043315237\n",
      "accuracy : 0.978\n",
      "time : 696.2093379497528 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18200 ---------\n",
      "loss : 17.13251881084501\n",
      "accuracy : 0.974\n",
      "time : 701.011039018631 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch18300 ---------\n",
      "loss : 14.666230788814579\n",
      "accuracy : 0.978\n",
      "time : 705.6745891571045 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18400 ---------\n",
      "loss : 15.09523531960623\n",
      "accuracy : 0.988\n",
      "time : 710.2143089771271 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18500 ---------\n",
      "loss : 12.919121125897469\n",
      "accuracy : 0.992\n",
      "time : 714.8064870834351 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18600 ---------\n",
      "loss : 13.077826504134507\n",
      "accuracy : 0.99\n",
      "time : 719.0454461574554 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18700 ---------\n",
      "loss : 13.98381329426456\n",
      "accuracy : 0.988\n",
      "time : 722.9495811462402 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18800 ---------\n",
      "loss : 14.16368379228864\n",
      "accuracy : 0.99\n",
      "time : 728.2705359458923 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18900 ---------\n",
      "loss : 15.17054528220248\n",
      "accuracy : 0.984\n",
      "time : 731.7139070034027 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19000 ---------\n",
      "loss : 15.439384750813092\n",
      "accuracy : 0.984\n",
      "time : 734.7041051387787 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19100 ---------\n",
      "loss : 14.647355044709835\n",
      "accuracy : 0.99\n",
      "time : 737.4826600551605 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19200 ---------\n",
      "loss : 13.819396595254373\n",
      "accuracy : 0.986\n",
      "time : 740.5889639854431 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19300 ---------\n",
      "loss : 13.942335173929957\n",
      "accuracy : 0.99\n",
      "time : 743.1914310455322 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19400 ---------\n",
      "loss : 13.283737443585158\n",
      "accuracy : 0.99\n",
      "time : 745.9584980010986 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19500 ---------\n",
      "loss : 12.888698872118123\n",
      "accuracy : 0.992\n",
      "time : 748.5791990756989 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19600 ---------\n",
      "loss : 11.512205134146912\n",
      "accuracy : 0.992\n",
      "time : 751.2725059986115 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19700 ---------\n",
      "loss : 14.054196585124206\n",
      "accuracy : 0.986\n",
      "time : 753.7952761650085 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19800 ---------\n",
      "loss : 13.652410186124644\n",
      "accuracy : 0.986\n",
      "time : 756.2733659744263 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19900 ---------\n",
      "loss : 13.688466641102217\n",
      "accuracy : 0.99\n",
      "time : 758.8559939861298 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20000 ---------\n",
      "loss : 12.580606318960157\n",
      "accuracy : 0.992\n",
      "time : 761.4004361629486 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20100 ---------\n",
      "loss : 13.410409519969216\n",
      "accuracy : 0.986\n",
      "time : 763.9368970394135 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20200 ---------\n",
      "loss : 11.82920636560782\n",
      "accuracy : 0.992\n",
      "time : 766.3721179962158 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20300 ---------\n",
      "loss : 13.294624389703046\n",
      "accuracy : 0.986\n",
      "time : 768.8326580524445 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20400 ---------\n",
      "loss : 14.148683560791358\n",
      "accuracy : 0.986\n",
      "time : 771.3385741710663 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20500 ---------\n",
      "loss : 12.343178587663488\n",
      "accuracy : 0.99\n",
      "time : 774.1146750450134 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20600 ---------\n",
      "loss : 12.810487992473714\n",
      "accuracy : 0.988\n",
      "time : 779.0326471328735 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20700 ---------\n",
      "loss : 15.090335633200631\n",
      "accuracy : 0.984\n",
      "time : 781.7916030883789 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20800 ---------\n",
      "loss : 14.984710067688617\n",
      "accuracy : 0.986\n",
      "time : 784.3557260036469 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20900 ---------\n",
      "loss : 12.255508173458399\n",
      "accuracy : 0.99\n",
      "time : 786.9147951602936 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21000 ---------\n",
      "loss : 12.474349734957901\n",
      "accuracy : 0.99\n",
      "time : 789.9918420314789 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21100 ---------\n",
      "loss : 12.050768093420878\n",
      "accuracy : 0.994\n",
      "time : 793.2446491718292 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21200 ---------\n",
      "loss : 10.936181239046197\n",
      "accuracy : 0.998\n",
      "time : 796.1043660640717 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21300 ---------\n",
      "loss : 11.728462105890841\n",
      "accuracy : 0.99\n",
      "time : 799.3351609706879 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21400 ---------\n",
      "loss : 12.22450944714009\n",
      "accuracy : 0.992\n",
      "time : 802.0299770832062 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21500 ---------\n",
      "loss : 11.409893068472487\n",
      "accuracy : 0.996\n",
      "time : 806.9077370166779 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21600 ---------\n",
      "loss : 10.304300754696644\n",
      "accuracy : 0.994\n",
      "time : 810.2770731449127 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21700 ---------\n",
      "loss : 11.96314270962386\n",
      "accuracy : 0.988\n",
      "time : 812.9780220985413 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21800 ---------\n",
      "loss : 14.74734867396127\n",
      "accuracy : 0.982\n",
      "time : 815.5775110721588 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21900 ---------\n",
      "loss : 12.235623528006421\n",
      "accuracy : 0.994\n",
      "time : 818.507807970047 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22000 ---------\n",
      "loss : 13.486505039028202\n",
      "accuracy : 0.99\n",
      "time : 821.5189781188965 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22100 ---------\n",
      "loss : 12.46713027299873\n",
      "accuracy : 0.99\n",
      "time : 824.0932049751282 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22200 ---------\n",
      "loss : 11.666731033976358\n",
      "accuracy : 0.992\n",
      "time : 826.6742391586304 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22300 ---------\n",
      "loss : 13.124041782809911\n",
      "accuracy : 0.982\n",
      "time : 829.3656330108643 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22400 ---------\n",
      "loss : 11.764742750099519\n",
      "accuracy : 0.988\n",
      "time : 832.0858540534973 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22500 ---------\n",
      "loss : 12.984656066379657\n",
      "accuracy : 0.986\n",
      "time : 835.0008511543274 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22600 ---------\n",
      "loss : 12.831978012926825\n",
      "accuracy : 0.988\n",
      "time : 837.9415440559387 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22700 ---------\n",
      "loss : 12.213122137733274\n",
      "accuracy : 0.988\n",
      "time : 841.1465661525726 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22800 ---------\n",
      "loss : 12.313299308646613\n",
      "accuracy : 0.988\n",
      "time : 844.1346571445465 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22900 ---------\n",
      "loss : 10.817694203987118\n",
      "accuracy : 0.994\n",
      "time : 847.0711560249329 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23000 ---------\n",
      "loss : 11.361164142532333\n",
      "accuracy : 0.998\n",
      "time : 849.8011910915375 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23100 ---------\n",
      "loss : 14.10477922287315\n",
      "accuracy : 0.982\n",
      "time : 852.6039400100708 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23200 ---------\n",
      "loss : 10.913378952472065\n",
      "accuracy : 0.992\n",
      "time : 855.5742700099945 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23300 ---------\n",
      "loss : 10.983468949988517\n",
      "accuracy : 0.99\n",
      "time : 858.2872099876404 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23400 ---------\n",
      "loss : 11.099383467262236\n",
      "accuracy : 0.988\n",
      "time : 862.1071491241455 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23500 ---------\n",
      "loss : 10.803708196139494\n",
      "accuracy : 0.992\n",
      "time : 865.9573211669922 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23600 ---------\n",
      "loss : 13.7932580975633\n",
      "accuracy : 0.978\n",
      "time : 869.5080530643463 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23700 ---------\n",
      "loss : 11.857668797588468\n",
      "accuracy : 0.99\n",
      "time : 872.7208800315857 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23800 ---------\n",
      "loss : 11.461921724162247\n",
      "accuracy : 0.988\n",
      "time : 875.4544110298157 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23900 ---------\n",
      "loss : 11.81440677472065\n",
      "accuracy : 0.986\n",
      "time : 878.2338020801544 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24000 ---------\n",
      "loss : 11.010624685545732\n",
      "accuracy : 0.994\n",
      "time : 881.1630370616913 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24100 ---------\n",
      "loss : 12.447953400962392\n",
      "accuracy : 0.982\n",
      "time : 884.2242729663849 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24200 ---------\n",
      "loss : 13.912362685556566\n",
      "accuracy : 0.992\n",
      "time : 887.1428210735321 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24300 ---------\n",
      "loss : 13.096958777386957\n",
      "accuracy : 0.99\n",
      "time : 889.8150651454926 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch24400 ---------\n",
      "loss : 9.760775973942597\n",
      "accuracy : 0.994\n",
      "time : 892.8731541633606 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24500 ---------\n",
      "loss : 10.513987818170259\n",
      "accuracy : 0.99\n",
      "time : 895.7365729808807 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24600 ---------\n",
      "loss : 9.559225247797151\n",
      "accuracy : 0.994\n",
      "time : 898.656238079071 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24700 ---------\n",
      "loss : 11.656585292273183\n",
      "accuracy : 0.98\n",
      "time : 901.3553111553192 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24800 ---------\n",
      "loss : 10.024806491176287\n",
      "accuracy : 0.992\n",
      "time : 904.2248771190643 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24900 ---------\n",
      "loss : 10.291192900075348\n",
      "accuracy : 0.99\n",
      "time : 907.1939251422882 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25000 ---------\n",
      "loss : 10.922480847425874\n",
      "accuracy : 0.984\n",
      "time : 910.135852098465 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25100 ---------\n",
      "loss : 10.329977047908258\n",
      "accuracy : 0.998\n",
      "time : 913.0847020149231 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25200 ---------\n",
      "loss : 12.726148762575564\n",
      "accuracy : 0.982\n",
      "time : 915.7648150920868 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25300 ---------\n",
      "loss : 13.151665406178493\n",
      "accuracy : 0.99\n",
      "time : 918.7034201622009 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25400 ---------\n",
      "loss : 12.48900929987281\n",
      "accuracy : 0.988\n",
      "time : 921.6501891613007 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25500 ---------\n",
      "loss : 11.230929588242395\n",
      "accuracy : 0.99\n",
      "time : 924.5851330757141 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25600 ---------\n",
      "loss : 12.855379182886061\n",
      "accuracy : 0.986\n",
      "time : 927.5384311676025 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25700 ---------\n",
      "loss : 9.924199727432587\n",
      "accuracy : 0.996\n",
      "time : 930.4155440330505 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25800 ---------\n",
      "loss : 11.208706021096798\n",
      "accuracy : 0.986\n",
      "time : 933.0511441230774 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25900 ---------\n",
      "loss : 9.782878688991318\n",
      "accuracy : 0.994\n",
      "time : 935.958428144455 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26000 ---------\n",
      "loss : 10.183647745367988\n",
      "accuracy : 0.994\n",
      "time : 938.9089951515198 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26100 ---------\n",
      "loss : 11.642525577799903\n",
      "accuracy : 0.988\n",
      "time : 941.8665010929108 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26200 ---------\n",
      "loss : 9.813559863784013\n",
      "accuracy : 0.992\n",
      "time : 944.8019750118256 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26300 ---------\n",
      "loss : 11.051472251657984\n",
      "accuracy : 0.992\n",
      "time : 947.7974810600281 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26400 ---------\n",
      "loss : 11.365407396217307\n",
      "accuracy : 0.992\n",
      "time : 950.635204076767 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26500 ---------\n",
      "loss : 10.716619718774728\n",
      "accuracy : 0.994\n",
      "time : 953.2937271595001 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26600 ---------\n",
      "loss : 8.814590029461115\n",
      "accuracy : 0.996\n",
      "time : 956.1261651515961 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26700 ---------\n",
      "loss : 9.951931828177717\n",
      "accuracy : 0.986\n",
      "time : 959.5518391132355 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26800 ---------\n",
      "loss : 11.322660760347045\n",
      "accuracy : 0.988\n",
      "time : 962.4170269966125 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26900 ---------\n",
      "loss : 9.70531643538694\n",
      "accuracy : 0.996\n",
      "time : 965.0766639709473 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27000 ---------\n",
      "loss : 8.6617855012543\n",
      "accuracy : 0.998\n",
      "time : 967.6511080265045 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27100 ---------\n",
      "loss : 11.841190951749441\n",
      "accuracy : 0.98\n",
      "time : 970.2963111400604 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27200 ---------\n",
      "loss : 9.39004934968797\n",
      "accuracy : 0.992\n",
      "time : 972.913311958313 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27300 ---------\n",
      "loss : 9.931214217399189\n",
      "accuracy : 0.998\n",
      "time : 975.6383140087128 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27400 ---------\n",
      "loss : 10.426186471154255\n",
      "accuracy : 0.992\n",
      "time : 978.5196580886841 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27500 ---------\n",
      "loss : 12.162157273259869\n",
      "accuracy : 0.986\n",
      "time : 981.2453479766846 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27600 ---------\n",
      "loss : 12.142285648506098\n",
      "accuracy : 0.988\n",
      "time : 984.1928491592407 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27700 ---------\n",
      "loss : 8.729049114551334\n",
      "accuracy : 0.996\n",
      "time : 986.9504029750824 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27800 ---------\n",
      "loss : 11.449611576115803\n",
      "accuracy : 0.994\n",
      "time : 989.5589809417725 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27900 ---------\n",
      "loss : 9.455946375108574\n",
      "accuracy : 0.984\n",
      "time : 992.239825963974 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28000 ---------\n",
      "loss : 10.090426838961225\n",
      "accuracy : 0.99\n",
      "time : 995.1460981369019 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28100 ---------\n",
      "loss : 8.84067017744945\n",
      "accuracy : 0.998\n",
      "time : 998.1419720649719 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28200 ---------\n",
      "loss : 9.318676352176926\n",
      "accuracy : 0.994\n",
      "time : 1000.8583469390869 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28300 ---------\n",
      "loss : 9.227332478948671\n",
      "accuracy : 0.99\n",
      "time : 1003.4858090877533 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28400 ---------\n",
      "loss : 9.5507755857189\n",
      "accuracy : 0.996\n",
      "time : 1006.3810880184174 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28500 ---------\n",
      "loss : 10.239728423985785\n",
      "accuracy : 0.99\n",
      "time : 1009.3463699817657 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28600 ---------\n",
      "loss : 10.368591463328327\n",
      "accuracy : 0.988\n",
      "time : 1012.141077041626 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28700 ---------\n",
      "loss : 10.325853908777674\n",
      "accuracy : 0.996\n",
      "time : 1015.3464059829712 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28800 ---------\n",
      "loss : 9.454042877928943\n",
      "accuracy : 0.998\n",
      "time : 1020.5439450740814 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28900 ---------\n",
      "loss : 9.40193092514418\n",
      "accuracy : 0.99\n",
      "time : 1023.525768995285 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29000 ---------\n",
      "loss : 10.600163392050302\n",
      "accuracy : 0.986\n",
      "time : 1027.106101989746 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29100 ---------\n",
      "loss : 9.098261584064712\n",
      "accuracy : 0.992\n",
      "time : 1031.105798959732 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29200 ---------\n",
      "loss : 7.729413819379533\n",
      "accuracy : 0.996\n",
      "time : 1034.3515920639038 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29300 ---------\n",
      "loss : 10.509075430015177\n",
      "accuracy : 0.986\n",
      "time : 1037.3180711269379 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29400 ---------\n",
      "loss : 8.396535191746567\n",
      "accuracy : 0.994\n",
      "time : 1041.6135611534119 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29500 ---------\n",
      "loss : 8.299210322412517\n",
      "accuracy : 0.998\n",
      "time : 1048.1394410133362 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29600 ---------\n",
      "loss : 10.180655257431722\n",
      "accuracy : 0.992\n",
      "time : 1051.0564241409302 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29700 ---------\n",
      "loss : 8.296814986561612\n",
      "accuracy : 0.996\n",
      "time : 1053.789530992508 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29800 ---------\n",
      "loss : 8.74468948087518\n",
      "accuracy : 0.996\n",
      "time : 1056.461727142334 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29900 ---------\n",
      "loss : 9.521815620532653\n",
      "accuracy : 0.996\n",
      "time : 1059.2254700660706 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30000 ---------\n",
      "loss : 9.614448949865233\n",
      "accuracy : 0.992\n",
      "time : 1061.7463419437408 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30100 ---------\n",
      "loss : 11.649580501573542\n",
      "accuracy : 0.988\n",
      "time : 1064.3098101615906 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30200 ---------\n",
      "loss : 11.402343343674833\n",
      "accuracy : 0.988\n",
      "time : 1067.302165031433 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30300 ---------\n",
      "loss : 9.948080686816748\n",
      "accuracy : 0.988\n",
      "time : 1070.0425310134888 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30400 ---------\n",
      "loss : 8.815986991986206\n",
      "accuracy : 0.996\n",
      "time : 1072.6300871372223 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch30500 ---------\n",
      "loss : 8.557007040343967\n",
      "accuracy : 0.99\n",
      "time : 1075.196758031845 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30600 ---------\n",
      "loss : 8.584565752773237\n",
      "accuracy : 0.994\n",
      "time : 1077.8747210502625 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30700 ---------\n",
      "loss : 9.58749126321202\n",
      "accuracy : 0.996\n",
      "time : 1080.6445791721344 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30800 ---------\n",
      "loss : 8.884147938780222\n",
      "accuracy : 0.994\n",
      "time : 1083.3109941482544 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30900 ---------\n",
      "loss : 9.565475479418431\n",
      "accuracy : 0.994\n",
      "time : 1085.8331639766693 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31000 ---------\n",
      "loss : 8.856179743616497\n",
      "accuracy : 0.99\n",
      "time : 1088.7125389575958 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31100 ---------\n",
      "loss : 9.680126936713691\n",
      "accuracy : 0.994\n",
      "time : 1091.4848110675812 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31200 ---------\n",
      "loss : 8.579835398849202\n",
      "accuracy : 0.998\n",
      "time : 1094.1323590278625 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31300 ---------\n",
      "loss : 10.021501498826952\n",
      "accuracy : 0.988\n",
      "time : 1096.8735361099243 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31400 ---------\n",
      "loss : 10.320590572539649\n",
      "accuracy : 0.986\n",
      "time : 1099.7975771427155 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31500 ---------\n",
      "loss : 9.774560643689137\n",
      "accuracy : 0.996\n",
      "time : 1102.5649199485779 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31600 ---------\n",
      "loss : 8.584986132847124\n",
      "accuracy : 0.992\n",
      "time : 1105.5877540111542 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31700 ---------\n",
      "loss : 8.184580598262013\n",
      "accuracy : 0.99\n",
      "time : 1108.4363689422607 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31800 ---------\n",
      "loss : 8.077736007928255\n",
      "accuracy : 0.992\n",
      "time : 1111.7053091526031 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31900 ---------\n",
      "loss : 8.49163094870826\n",
      "accuracy : 0.994\n",
      "time : 1114.5207300186157 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32000 ---------\n",
      "loss : 8.732724291975513\n",
      "accuracy : 0.992\n",
      "time : 1118.132140159607 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32100 ---------\n",
      "loss : 8.007408944912424\n",
      "accuracy : 0.998\n",
      "time : 1121.2420091629028 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32200 ---------\n",
      "loss : 9.341422269701306\n",
      "accuracy : 0.992\n",
      "time : 1125.8714380264282 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32300 ---------\n",
      "loss : 8.829507067668679\n",
      "accuracy : 0.992\n",
      "time : 1130.2169179916382 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32400 ---------\n",
      "loss : 7.7368504830998654\n",
      "accuracy : 0.996\n",
      "time : 1133.8447279930115 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32500 ---------\n",
      "loss : 9.580626768765304\n",
      "accuracy : 0.992\n",
      "time : 1137.4266109466553 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32600 ---------\n",
      "loss : 7.7664487381286005\n",
      "accuracy : 0.994\n",
      "time : 1141.2262871265411 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32700 ---------\n",
      "loss : 7.8413795300801725\n",
      "accuracy : 0.996\n",
      "time : 1145.3799140453339 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32800 ---------\n",
      "loss : 8.913740087677487\n",
      "accuracy : 0.99\n",
      "time : 1148.3998341560364 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32900 ---------\n",
      "loss : 7.6065484009427875\n",
      "accuracy : 0.994\n",
      "time : 1151.0761959552765 [sec]\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "<< All training epochs ended. >>\n",
      "========= result =========\n",
      "Elapsed time : 1154.1802380084991 [sec]\n",
      "Train set accuracy : 0.9934666666666667\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "elapsed_time,train_acc = net.train(x_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.9934666666666667\n",
      "test accuracy : 0.903\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy : {}\\ntest accuracy : {}'.format(\n",
    "    net.accuracy(x_train,t_train),net.accuracy(x_test,t_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEWCAYAAAA3h9P4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd8VFX6+PHPk0boHaRJExVQmqCsKGLHgqi7trUgsrruV/zaO5bV9aerq65tVVwLujZsK2ulWNDvUkV6kS4BpBMCIZBknt8f5ySZhEkyhNzMJPO8X695zZ1zz733mQnMM+fcc88VVcUYY4yJV0mxDsAYY4wpiyUqY4wxcc0SlTHGmLhmicoYY0xcs0RljDEmrlmiMsYYE9csUZnAiMiLInJvGevvFpF/VmVM/rjnicgaEdkpIr2r+vg1kYg8ICL/KmXdIBHJqOqYTM2REusATLBEZBXwB1WdWNXHVtVrw+IYBPxLVduGrf9/VR2T9zdgpKp+EqPjG2P2g7WoEpyIJOKPlfbAglgHEUmC/j2MKZMlqhpMRN4EDgb+47u5bheRDiKiIjJCRH4BvvZ13xeRX0UkU0Qmi0j3sP28LiLPi8hnIpIlItNEpLNfJyLylIhs9NvOFZEjwrb7i4jUBb4AWvs4dopI65LdRSJyjogsEJHtIvKtiHQNW7dKRG71+88UkfdEJL2U950kIqNEZLWP6w0RaSgitURkJ5AMzBGR5aVs/7TvGtwhIj+KyPFh65J9l+Vy/1n8KCLt/LruIjJBRLaKyAYRuTv8cwjbR7GuMP/e7hCRucAuEUkRkTvDjrFQRM4rEePVIrIobH0fEblNRD4sUe9ZEfl7Ke+z1GOIyJUi8oOI/E1EtonIShE5I2x9RxH5zm87AWgW6RilHLer//tu93/vc8LWneljyRKRtSJyqy9vJiKf+m22isj3ImLfX4lCVe1Rgx/AKuCUsNcdAAXeAOoCtX35VUB9oBbwd2B22DavA1uBo3HdxW8B7/p1pwM/Ao0AAboCrcK2+4tfHgRklIjtAVx3IMChwC7gVCAVuB1YBqSFvY/pQGugCbAIuLaU93yV37YTUA/4CHgzbL0Ch5TxmV0GNPXv9RbgVyDdr7sNmAcc5t9vT1+3PrDe10/3r48p+TlE+iz8e5sNtAv7e1zg32sScJH/bFqFrVsL9PMxHIJrJbby9Rr5einARuCoUt5nWce4EsgFrsYl9j8B6wDx66cAT+L+vQwEsgr+lhGOU/h+/d92GXA3kAac5Lc9zK9fDxzvlxsDffzyI8CLfvtU4PiCWOxR8x/2iyRxPaCqu1R1N4CqvqqqWaq6B5dAeopIw7D6H6nqdFXNwyWqXr48F/elfDjui2ORqq6vQDwXAZ+p6gRVzcWdR6oNHBtW5xlVXaeqW4H/hMVQ0qXAk6q6QlV3AncBF0uU3Wqq+i9V3aKqear6BO7L+DC/+g/AKFVdos4cVd0CnA38qqpPqGqO/yyn7cf7f0ZV14T9Pd737zWkqu8BS3E/FApieExVZ/gYlqnqav+5T8YlIIDBwGZV/bGU91nWMQBWq+rLqpoPjMElwpYicjAuSd6rqntUdTLu7xGN/rgfD4+q6l5V/Rr4FLjEr88FuolIA1XdpqqzwspbAe1VNVdVv1dVm6g0QViiSlxrChZ8d9ajvhtoB+4XPhTvzvk1bDkb92WD/6J5Dnge2CAio0WkQQXiaQ2sLnihqiEfY5vyYihvX345BWgZTSAicovvVssUke1AQ4o+i3ZApC7D0sqjtSb8hYhcISKzfVfXduCIKGIAl1Au88uXAW+WdsByjgFhn7eqZvvFerjPd5uq7gqrG/55l6U1sMb/fcO3Lfg7/xY4E1jtuxZ/48sfx7XExovIChG5M8rjmRrAElXNV9qvzvDy3wNDgVNwX8odfLlEdQDVZ1T1KKA7rgvvtv2Io8A6XPeVO7CI4L6Q10YTQ1n7wp2nywM2lLehPx91B3Ah0FhVGwGZFH0Wa4DOETYtrRxcl1qdsNcHRahT+PmISHvgZWAk0NTHMD+KGAD+DfQQd57wbFzrdx9RHKMs64HG4s49Fjg4iu3A/W3alTi/dDD+7+xbiUOBFv69jPXlWap6i6p2AoYAN4vIyVEe01Rzlqhqvg24czVlqQ/sAbbgvlCjHjYuIv1E5BgRScV9IecA+aXE0bREd2K4scBZInKy39ctPqb/RhtLmHeAm/wJ/3q49/Oe77YsT31cUtsEpIjIfUB4C/GfwEMi0kWcHiLSFNd9dZCI3Chu0EZ9ETnGbzMbOFNEmojIQcCN5cRQF5e4NgGIyHBcayc8hltF5CgfwyE+8aCqOcAHwNvAdFX9pYLHKJWqrgZmAn8WkTQROQ6XPKIxDffv5HYRSRV32cIQ4F2/r0tFpKHv/t2B/7ckImf79ylh5ZH+nZkayBJVzfcIMMp379xaSp03cN0va4GFwNT92H8D3C/zbX4fW3Dnl4pR1cW4BLLCx9K6xPoluK6qZ4HNuC+vIaq6dz9iKfAqrstrMrASlzyvj3Lbr3AjFH/27yeH4t1yT+KS6njcF+YruAEQWbiBIENwXWZLgRP9Nm8Cc3BdquOB98oKQFUXAk/gBixsAI4E/i9s/fvAw7hklIVreTQJ28UYv02p3X7lHSMKvweOwQ2yuR/3b6hc/u95DnAG7u/8D+AK/+8D4HJgle+CvpaibswuwERgp4/5H6r67X7Ea6oxsfORxtQsfrDDYuAgVd0R63iMOVDWojKmBvHnfm7GXT5gScrUCHYVvDE1hB/csAHXZTk4xuEYU2ms688YY0xcs64/Y4wxca3adf0lJSVp7dq1Yx2GMcZUK9nZ2aqq1bJxUu0SVe3atdm1a1f5FY0xxhQSkd2xjqGiqmV2NcYYkzgsURljjIlrlqiMMcbEtWp3jsoYU7Pl5uaSkZFBTk5OrEOpltLT02nbti2pqamxDqXSWKIyxsSVjIwM6tevT4cOHXBz0JpoqSpbtmwhIyODjh07xjqcSmNdf8aYuJKTk0PTpk0tSVWAiNC0adMa1xq1RGWMiTuWpCquJn52iZOoVk+Brx+GvIrcNcIYY0ysJE6iypgOkx+DUG6sIzHGGLMfEidRGWNMHMnLi+aG0wYSMVHZbPHGmHKce+65HHXUUXTv3p3Ro0cD8OWXX9KnTx969uzJySefDMDOnTsZPnw4Rx55JD169ODDDz8EoF69eoX7+uCDD7jyyisBuPLKK7n55ps58cQTueOOO5g+fTrHHnssvXv35thjj2XJkiUA5Ofnc+uttxbu99lnn2XSpEmcd955hfudMGEC559/flV8HDGXQMPTa94JRmNquj//ZwEL11Xu/R+7tW7A/UO6l1nn1VdfpUmTJuzevZt+/foxdOhQrr76aiZPnkzHjh3ZunUrAA899BANGzZk3rx5AGzbtq3c4//8889MnDiR5ORkduzYweTJk0lJSWHixIncfffdfPjhh4wePZqVK1fy008/kZKSwtatW2ncuDHXXXcdmzZtonnz5rz22msMHz78wD+QaiCBEpUxxkTnmWee4eOPPwZgzZo1jB49moEDBxZem9SkSRMAJk6cyLvvvlu4XePGjcvd9wUXXEBycjIAmZmZDBs2jKVLlyIi5ObmFu732muvJSUlpdjxLr/8cv71r38xfPhwpkyZwhtvvFFJ7xhEJB2YDNTC5YYPVPV+EXkdOAHI9FWvVNXZ4oYXPg2cCWT78lmVFlCYBExU1vVnTHVRXssnCN9++y0TJ05kypQp1KlTh0GDBtGzZ8/CbrlwqhpxOHh4WclrmurWrVu4fO+993LiiSfy8ccfs2rVKgYNGlTmfocPH86QIUNIT0/nggsuKExklWQPcJKq7hSRVOAHEfnCr7tNVT8oUf8MoIt/HAO84J8rXeKco6qB1xYYYypfZmYmjRs3pk6dOixevJipU6eyZ88evvvuO1auXAlQ2PV32mmn8dxzzxVuW9D117JlSxYtWkQoFCpsmZV2rDZt2gDw+uuvF5afdtppvPjii4UDLgqO17p1a1q3bs1f/vKXwvNelUWdnf5lqn+U9ct+KPCG324q0EhEWlVqUF5giUpEXhWRjSIyv5T1IiLPiMgyEZkrIn2CisUYY6I1ePBg8vLy6NGjB/feey/9+/enefPmjB49mvPPP5+ePXty0UUXATBq1Ci2bdvGEUccQc+ePfnmm28AePTRRzn77LM56aSTaNWq9O/u22+/nbvuuosBAwaQn59fWP6HP/yBgw8+mB49etCzZ0/efvvtwnWXXnop7dq1o1u3bpX+3kUkWURmAxuBCao6za962H9PPyUitXxZG2BN2OYZvqzy49KARsGJyEBgJy7jHhFh/ZnA9bj+zWOAp1W13GZj3bp1tUI3TvzvszB+FNy5BtIb7P/2xpgqsWjRIrp27RrrMOLWyJEj6d27NyNGjCi1TqTPUET2AvPCikar6uhI24tII+Bj3Hf0FuBXIA0YDSxX1QdF5DPgEVX9wW8zCbhdVX+s8JsrRWDnqFR1soh0KKNKYbMRmCoijUSklaquDyYi6/pLBJm7c0lJEurWqvg/7T15+ezMyaNpvVrFynNy88nem8/evBAHNUyPen/rtu8mOUloWjeNrdl7Wbw+i3lrM7lmYCe2Ze/l5ckr6NG2EUN6ti7cJjc/xPbsXNJSkpiXkUmHZnXI3J1L14MasDFrD7XTktm2ay9tG9dma/Ze1mzNpnGdNNZu383n837lhEObMXXFVhau38FZR7Zi5eZddG/dgBe+W86Llx3FjFVbefG75Zzfuy3dWjfg7Wm/cHyXZogILRvUIic3xIpNO+nboTHN66WzZEMWt74/h/vO7kbrRrV5a9pqsnLyOKVrCyYs3MDxXZqzKWsP7810P7CvGtCR2mlJ9OvQhPlrM/nb+J8B+OS6AQx9/v/o2qoBu/bksT17Lzty8jirRys2Ze0hNVm4+sha5GZsj/rzrZWSTF6++5us3e5uYtuodhpZe3IJqTvfE41WDdPZmLWH/FDp9ZNECMXoEpfaaclcfMYg6tatyxNPPFGRXeSpat9oKqrqdhH5Fhisqn/zxXtE5DXgVv86A2gXtllbYF1FAitPYC0qAJ+oPi2lRfUp8GiJbHyHqs6MUPca4BqAtLS0o/bs2bP/wfz3ORh/j7WoYmDhuh2MfGcWZ/dozeX929O8vksAb0/7hZ83ZPHAOd3JDykTF23gtG4tC08iqyrjF26gX4cmvP7fVYwY0JGGdVKZm7GdJnXTaNu4Do99uZhm9Wpx1XEdmb82k7Of/YFaKUk8//s+nNKtZakxzcvIZMhzPwDwzyv68soPK8nem8eVAzpw03tzAPjjwE7szs3njSmrS93P0R2bMH3l1n3Kr/hN+zK3M6V7+ZxWtDy4U6zDiFs92jYqt04pLapsVa1byiaISHMg1yep2sB44K/Aj6q63o/yewrIUdU7ReQsYCRFvWLPqOrRFX1fZYlloqpQs7HiXX+WqCrix9VbaVg7jUNauAsYs/fm8fOGnfRo05DnvllGWkoSj36xmMm3ncjsjO3c++/5vHT5USxev4Nt2bk8PWnpfh/zrCNb8dm8gBrWJu5ZoipbgImqBzAGSMaNXxjru/i+BprjuqVmA9f6kYECPAcMxg1PHx6poVEZYjk8vcqajcUl3vD0PXn5fLN4I4OPKDqpO+rf82jdqDZ/OqEzIYUdu3OZk7Gdpyb8TLfWDTn8oPrs3JPH41+5IbnDftOeMWW0EAY+/k3h8sWjpx5QvJakjImsWYnu6MqkqnOB3hHKTyqlvgLXBRZQmFgmqnHASBF5F9dszAzu/BQ1Znj6mq3ZtGhQi1op7oJBVWXl5l10al6vcH2tlCQ279zLxqwcrnxtRpn7e+zLfa8NmZORuU9ZWUnKGFM1DmoQ/bnRmiSwRCUi7wCDgGYikgHcjxuXj6q+CHyO69tchm82BhVLvAqFlE/mrOWcnm1ITio9ka7dvpvVm3fRp31jjn+sqOXy1EU9C8+njDqrKxcffXCx9cZUF2kpSezNC1Xa/mqlJLMnzw33blwnjW3ZxW/vUz89lawcNwtEg/RUaqUmsSlrD20b1yFjWzYALRukUyctmSQRVmzaSdvGddi5J6/YvuqkpZCTm184wKJz83os37STJBHaN61DfkhpVCeNvXn5/LJ1Nx2a1iE3X0lKovDH5lw/cKRZvVqkJAm/7sihYe1U9uaFaNu4Nhuz9pC528WaVMb3RE0W6DmqIFT4HNWU5+Gru+GO1VC7/D7eqvDm1NXc++/53HraoZzfpy1rtmbz88adXN6/PR3u/CzW4ZkEseQvg8nKyePvE3+mTaM6/PXLxQCc1aMVn80t6uSINHDkixuO54ynv6dfh8Zk5eRxUb92tGyQziEt6vHBjxk0rZvGI18s5r6zu3F2z1bsyQ0xevIKbjr1UPJDWjiwBiAvP8S27Fw2/LKcLoceRlKSIMDC9W6uv66tGrB111427HAzPSSJ0Ll5PZZuzKJTs7pkbNtNnbQUDm5aB4C9eSFEIDXZXS4aUiU/pIWv80MhQPb5kZibH6Jxwwbs3LmTSHLzQqQkS6k3KMzLD5EkEnVSUVXyfFzhy+FCISWkSkpydJe+VuQcVTxLoET1D/jqripJVL9syWb11l0c36V5qXVy80M8O2kpz3y9bJ911590CM9GKDfx7bCW9VmyISuquvXTU8jKiXybhxcu7UOD2qkkJwlXvDqdV4f1I6RKl5b12LhjDz3bNeKFb5czZcUWNmftYdix7WnRIJ0TujQnKUnYsnMPM1ZtY9eePG55fw7n9W7DUxf1YtnGnaQkCR2aVd13lary7ZJNDDqsedR3ni35Jbt7bz7JSUJaSlJYWR4pyUn7fKFXlnr16pWaqKoDS1QxVh0SVUFraNWjZ/Hp3HV8t2QTa7Zl8+dzjqBpvTSenPAzb0/7JdAYTPnCE8uhLetxwqHN+WjWWrbs2vcu0Of3aUPbRrULf1h0bFaXcSMHUD89tVi9z+aup0OzOjRITyU9NRlFaVg7ldx8JSVJ2LUnD8V1N+3OzSc3P4TAPtdsVZbt2XupVysl6l/i8SAeLvgtSFSqyu23384XX3yBiDBq1Cguuugi1q9fz0UXXcSOHTvIy8vjhRde4Nhjj2XEiBHMnDkTEeGqq67ipptuikn8NS1R2aS0laDDnZ9xef/2jDq7K8lhvxpfnryChz9fVPj69L9PrvRjJ6ITD2vON0s2RVz34NDuHNayPi9/v5KJizYUll99fEeSkoSXvlsBuB8RoZAy5Lkf+E2npow6201Hc89Z3dievZc1W3cTUqVDs7o0rF2UjPp3asoxnZqWek7xrB6Rp8spuP44PTW5sCy8hRCURnXSAj9GoL64E36dV369/XHQkXDGo1FV/eijj5g9ezZz5sxh8+bN9OvXj4EDB/L2229z+umnc88995Cfn092djazZ89m7dq1zJ/vZo3bvj36i5ZN2RInUQU06m9jlusvf3Pqat6cWnxkXHiSMtFp06g2Pds1pEuL+nRv3YBr3ix+Wd2os7py1YCObN/tZm2oVyuF+Wsz2bAjh5O7Fl3ge0ynpuSHlOy9eYWtnlBIufr4TtRNc//sk5KEz/73+H1iaFQnrdQv+GMPaVZZb9VUAz/88AOXXHIJycnJtGzZkhNOOIEZM2bQr18/rrrqKnJzczn33HPp1asXnTp1YsWKFVx//fWcddZZnHbaabEOv8ZInERViXJy81m2cSd/n7i02K/2RHfcIc2YtzazcIRSgVFndeXUbi1p37Qu3y7ZyLyMTK4/uQvLNmbRuE4a932ygM/mrWfVo2fts88fR53C+swc8kNKz3ZFXbZN6hYlkiPaNOSINg332TY5SYp1zSUlSaDXoZgARNnyCUppp0YGDhzI5MmT+eyzz7j88su57bbbuOKKK5gzZw5fffUVzz//PGPHjuXVV1+t4ohrpsRLVJVwTu7we7+shECqp0UPDuavXy7m9f+u4rhDmvGvPxzDzxuyyNiWzUmHtyQvP0ReSMncnUv/RybxwqV9il1oPOiwFgw6rAUAh7SoD8Azl/TmiQt7Rjxe03q1Ajt/Y0x5Bg4cyEsvvcSwYcPYunUrkydP5vHHH2f16tW0adOGq6++ml27djFr1izOPPNM0tLS+O1vf0vnzp0r/TYciSyBEtX+d/0t/nUHqzbvYm5GJmNnruHzG46nRf2ac8Fdz3aN+NMJnQFo16Q2aclJLP41i+6tG9CpeT2WbdxJ8/q1aFg7le+XbmLJr1nUTkvmnrO68ts+bTmyrWvFHNqyPoe2dEknJTmJlGR3LmblI/u2kCJJThKSk5LLr2hMFTvvvPOYMmUKPXv2RER47LHHOOiggxgzZgyPP/44qamp1KtXjzfeeIO1a9cyfPhwQiF3PdgjjzwS4+hrjsQZ9Tf1RfjyDrh9JdRpEtUmNelapv+MPI6OzetyxP1f0bx+LR77bQ9OPLxFrMMyZh/xMOqvurNRfzXUuu27mbR4I5f3bw9QeNFjdXHCoc2ZsWor2Xvz+cNxHTmzRyvaN6nDv2ev44jWDQpbP5NuOYFWDdOpk2Z/emNM9ZA431bljPq78rXp/LxhJ03rpnFcl2a88O3yKgosOke1b8yPq7cVvm5RvxbjbxpI5u5cftmazfFdmnPHB3N5b+Ya/jSoc+F5nRHHdSy2n85+TkBjjKkuEidRlWPrLjdS7X/emsXxXWI/BPmuMw7nkS9cq65gNFxObj6PfrGYW047tHA0W6M6abRv6lrzD517BH88oZMNPjDVnqpGPZOFKa66nc6JRvW5XL2ylPJH3Lyz6GaM3y/dXFXRADD+poEc3aEJLRvUKnx9yTEHA8Wn9U9PTeaBc7rvMxtCgbSUpMJZ1I2prtLT09myZUuN/MINmqqyZcsW0tNrzqAvSKgWVfz9OuvVrhGDDmtOlxb1GHvtb/ZZ/8MdJxabtNOYRNC2bVsyMjLYtCny7COmbOnp6bRt2zbWYVSqBEpUpdsWYW63oNx86qGccGhzPpyVwZ/P6V5m90bbxnWqLC5j4kVqaiodO3Ysv6JJGAmYqIp3J2TvzaP3QxMCP2paShLzHjit8B404bMsGGOMKV3iJKoILZdQSDnz6e8r9TBpyUnszQ/x5oijy7zNhzHGmOgk3mCKMK//dxWrtmRX6j6P7hjdxcTGGBNPRCRdRKaLyBwRWSAif/blHUVkmogsFZH3RCTNl9fyr5f59R2Cii3xElXYSKIHP11Yqbse0rN1pe7PGGOq0B7gJFXtCfQCBotIf+CvwFOq2gXYBozw9UcA21T1EOApXy8QiZeoAjD7vlOZfd+pPHlhT7q0dMPDG1f3+wAZYxKKOgW3NU71DwVOAj7w5WOAc/3yUP8av/5kCejit4RNVBnbKt7lN/2ek1n16Fkc2rLomqVGddJITU7irjO68u41/SPedsIYY2IoRURmhj2uKVlBRJJFZDawEZgALAe2q2qer5IBtPHLbYA1AH59JtA0kMCD2Gl1cNxfv6nQdnPuP63wjq9vXHUMk3/eVOwme2kpSfTvFMjfyhhjDkSeqvYtq4Kq5gO9RKQR8DEQaXbggvMnkVpPgVylnYAtKmXjjpwKbXn/kG7Fbkt+UMN0LuzXrrICM8aYuKCq24Fvgf5AIxEpaNS0Bdb55QygHYBf3xDYGkQ8iZOowrpOrxozo0K7GD7ALkI0xtRMItLct6QQkdrAKcAi4Bvgd77aMOATvzzOv8av/1oDmvcqcRKVt2N3LvPX7oi6/kNDuwcYjTHGxI1WwDciMheYAUxQ1U+BO4CbRWQZ7hzUK77+K0BTX34zcGdQgSXcOarlm3aWXylMt9YNOL9PG5JsJmdjTA2mqnOB3hHKVwBHRyjPAS6ogtASKVG5RBOKomV6Yd+23HDKobzy/Up6tWvMUe3tIl5jjImVBEpUTihUfqK65yw3aOK+Id2qICJjjDFlSbxEVU6LatnDZ5CSnHCn7owxJm4lzjeyP8c0b21mmdUsSRljTHxJuG/ll75bXvq6y4+qwkiMMcZEI+ESVWlj95rVq8Xp3Q+q0liMMcaUL9BEJSKDRWSJnwZ+nzH2InKwiHwjIj+JyFwROTPAaMpc+36EW8EbY4yJvcASlYgkA88DZwDdgEtEpOQwulHAWFXtDVwM/COoeMry/rW/oWOzurE4tDHGmHIE2aI6GlimqitUdS/wLm5a+HAKNPDLDSmaQyowEmHOxH4d7DopY4yJV0EOTy+cAt7LAI4pUecBYLyIXA/Uxc0ttQ8/Hf01AGlpFbzPk80sYYwx1VKQLapopoC/BHhdVdsCZwJvisg+ManqaFXtq6p9U1IqN7e2bpheqfszxhhTuYJMVIVTwHvh08MXGAGMBVDVKUA60CzAmPbp+nt1eL8gD2eMMeYABZmoZgBdRKSjiKThBkuMK1HnF+BkABHpiktUm4IJZ98G3pXHduDwgxpEqGuMMSZeBJao/K2JRwJf4e5pMlZVF4jIgyJyjq92C3C1iMwB3gGuDOp+JpE8cI7dwsMYY+JdoHP9qernwOclyu4LW14IDAgyhpJsSIUxxlQviTMzhY36M8aYailxEpUxxphqyRKVMcaYuJZwiSrSzBTGGGPiVwIlKjtHZYwxpRGRdn6S8EUiskBEbvDlD4jIWhGZ7R9nhm1zl590fImInB5UbAl3h98C157QOdYhGGNMPMkDblHVWSJSH/hRRCb4dU+p6t/CK/tJxi8GugOtgYkicqiq5ld2YAnUonIKuv46NbfZ0o0xpoCqrlfVWX45C3f9a5syNhkKvKuqe1R1JbAMNxl5pUucRGXD040xiS1FRGaGPa4praKIdAB6A9N80Uh/z8BXRaSxL4s08XhZia3CEidRGWNMYssrmNzbP0ZHqiQi9YAPgRtVdQfwAtAZ6AWsB54oqBph80BGqyVcoipoWNlt540xpjgRScUlqbdU9SMAVd2gqvmqGgJepqh7L5qJxytFAiWq4sm/Ye3UGMVhjDHxR0QEeAVYpKpPhpW3Cqt2HjDfL48DLhaRWiLSEegCTA8itoQd9WeMMaaYAcDlwDwRme3L7gYuEZFeuG69VcAfAfwk42OBhbgRg9f6VINiAAAgAElEQVQFMeIPEjJRKa9e2TfWQRhjTFxR1R+IfN7p8whlBds8DDwcWFBe4nT9hY36a5Bu3X7GGFNdJE6iCpOUZEPVjTGmuki4RCUobRvVjnUYxhhjopRAiaqoFdWiQXoM4zDGGLM/EihRGWOMqY4SLlHZ2SljjKleEidR2Vx/xhhTLSVOojLGGFMtJVyisjv8GmNM9ZJAicq6/owxpjqKKlGJyIcicpaIJFBiM8YYEw+iTTwvAL8HlorIoyJyeIAxBcq6/owxpnqJKlGp6kRVvRTog5s9d4KI/FdEhvv7l8Q/G/VnjDHVUtRdeSLSFLgS+APwE/A0LnFNCCQyY4wxhihv8yEiHwGHA28CQ1R1vV/1nojMDCo4Y4wxJtr7UT2nql9HWqGq1ermTtYBaIwx1Uu0XX9dRaRRwQsRaSwi/xNQTIGwIRTGGFM9RZuorlbV7QUvVHUbcHV5G4nIYBFZIiLLROTOUupcKCILRWSBiLwdZTz7TXduBCCFQO6UbIwxJiDRJqokkaJhcyKSDKSVtYGv8zxwBtANuEREupWo0wW4Cxigqt2BG/cj9v2TmQFAE7ICO4QxxlRXItJORL4RkUW+4XCDL28iIhNEZKl/buzLRUSe8Q2RuSLSJ6jYok1UXwFjReRkETkJeAf4spxtjgaWqeoKVd0LvAsMLVHnauB530JDVTdGH/r+CbXrD8B26gZ1CGOMqc7ygFtUtSvQH7jONy7uBCapahdgkn8NrhHSxT+uwV1vG4hoE9UdwNfAn4DrcMHeXs42bYA1Ya8zfFm4Q4FDReT/RGSqiAyOtCMRuUZEZorIzLy8vChDLk79Wx3Wv12FtjfGmJpMVder6iy/nAUswn1nDwXG+GpjgHP98lDgDXWmAo1EpFUQsUU16k9VQ7hsuT8ZM9IAu5JjGlJw2XgQ0Bb4XkSOCD8f5o8/GhgNULdu3QqNi1A/+1Oy2LAKY4wpi4h0AHoD04CWBZckqep6EWnhq5XWGFlPJYv2OqouwCO4c02F93FX1U5lbJYBhDdf2gLrItSZqqq5wEoRWYJLXDOiiWu/+ESVZOP/jDGJKaXEda+jfSOgGBGpB3wI3KiqO6T0WX2iaYxUimi7/l7DtabygBOBN3AX/5ZlBtBFRDqKSBpwMTCuRJ1/+/0hIs1wXYErooxpv2TvDQEwZVlgp8GMMSae5alq37BHpCSViktSb6nqR754Q0GXnn8u+BKNpjFSKaJNVLVVdRIgqrpaVR8ATiprA1XNA0biBmIsAsaq6gIReVBEzvHVvgK2iMhC4BvgNlXdUpE3Up6sXJeoVm2yUX/GGFOSH9n9CrBIVZ8MWzUOGOaXhwGfhJVf4Uf/9Qcyw2YtirT/G0Skga//iojMEpHTookt2pkpcvwtPpaKyEhgLdCinG1Q1c+Bz0uU3Re2rMDN/hGoOmluNP01x7cP+lDGGFMdDQAuB+aJyGxfdjfwKG7U9wjgF+ACv+5z4ExgGZANDC9n/1ep6tMicjrQ3Nd/DRhfXmDRJqobgTrA/wIP4brrhpW5RZwJJSUDkJZkkygZY0xJqvoDpc8yd3KE+oobBR6tgn2fCbymqnPCr88tS7mJyl+4e6Gq3gbspPysGZdU3eeRRCjGkRhjTEL6UUTGAx2Bu0SkPkT3hVxuolLVfBE5SkTEZ9BqSSlIVNX2LRhjTHU2AugFrFDVbBFpQpQNn2i7/n4CPhGR94FdBYVho0LinhYOT7cWlTHGxMBvgNmquktELsPdz/DpaDaMdtRfE2ALbqTfEP84uwKBxozm5QBQL3tNOTWNMcYE4AUgW0R64mY2Wo271Klc0c5MUS3PS4WrvWoSAN0XPgHn3xLjaIwxJuHkqaqKyFDgaVV9RUSiGpQX7cwUrxHhimNVvWr/4owdFfdWRe02H8YYEwNZInIXbgj88X6gXmo0G0Z7jurTsOV04DwCugI5KKGU2kBRwjLGGFOlLgJ+j7ue6lcRORh4PJoNozpHpaofhj3eAi4EjqhwuDGwo4ub8Pfn7jfEOBJjjEk8qvor8BbQUETOBnJUNapzVNEOpiipC3BwBbeNifwk18JMyc+JcSTGGJN4RORCYDpuZosLgWki8rtoto32HFUWxc9R/Yq7R1W1kZS9FYCDl78F3Fd2ZWOMMZXtHqBfwQ1yRaQ5MBH4oLwNox31V/+AwosDe+u5+3mtOuwqusY4FmOMSUBJJe7ivoUoe/WiqiQi54lIw7DXjUTk3LK2iTfqc7JUuLfTGGPMAfhSRL4SkStF5ErgM0pMWl6aaL+171fVzIIX/g689+93mDGU7+c+TNKK3creGGNMxfn5YkcDPYCeuBs3RnUKKdqx2pESWrUa56242dOTQ3tiHIkxxiQmVf0Qd2PG/RJti2qmiDwpIp1FpJOIPAX8uL8Hi6V8/1Y7z3sqxpEYY0ziEJEsEdkR4ZElIjui2Ue0raLrgXuB9/zr8cCoCsQcM/mSHOsQjDEm4VTGYLxoR/3tAu480IPFlNggCmOMqY6iHfU3QUQahb1uLCJfBRdW5QvZaD9jjKmWov32buZH+gGgqtuAFsGEFIxQyG6YaIwx1VG0iSrkJxAEQEQ6EGE29XhWrYI1xpgqJiKvishGEZkfVvaAiKwVkdn+cWbYurtEZJmILBGR04OMLdrBFPcAP4jId/71QOCaYEIKRkgtVRljTBleB55j35sZPqWqfwsvEJFuwMVAd6A1MFFEDlUN5j5K0c6e/iXQF1iCG/l3C7A7iICMMcZUPVWdDGyNsvpQ4F1V3aOqK4FlwNFBxRbtpLR/AG4A2gKzgf7AFNyt6asHa1AZYxJbiojMDHs9WlVHR7HdSBG5ApgJ3OLHKLQBpobVyfBlgYj2HNUNQD9gtaqeCPQGNgUVVBAsTxljElyeqvYNe0STpF4AOgO9gPXAE75cItQN7Gs22kSVo6o5ACJSS1UXA4cFFVQQ7BSVMcbsH1XdoKr5qhoCXqaoey8DaBdWtS0B3vU92kSV4a+j+jcwQUQ+CTKowIUCOd9njDE1ioi0Cnt5HlAwInAccLGI1BKRjrib6U4PKo5oZ6Y4zy8+ICLfAA2BL4MKKgga3irNy4G0urELxhhj4oyIvAMMApqJSAbuDhmDRKQXrltvFfBHAFVdICJjgYVAHnBdUCP+oAIzoKvqd+XXij/Fuv5yLVEZY0w4Vb0kQvErZdR/GHg4uIiKJMy8QsVOUW1ZGqswjDHG7KeESVTFfPfXWEdgjDEmSoEmKhEZ7KfXWCYipc6+LiK/ExEVkb5BxaLhfX/Lvw7qMMYYYypZYIlKRJKB54EzgG7AJX7ajZL16gP/C0wLKhaw66iMMaa6CrJFdTSwTFVXqOpe4F3ctBslPQQ8BuQEGItlKmOMqaaCTFRtgDVhr/eZYkNEegPtVPXTsnYkIteIyEwRmZmXl1f5kRpjjIlbQSaqMqfYEJEk4CncBLdlUtXRBdN+pKTs94h6f2BlUahd+RWNMcbElSATVXlTbNQHjgC+FZFVuIluxwU1oEIVkqz/zxhjqp0gE9UMoIuIdBSRNNy9S8YVrFTVTFVtpqodVLUDbibec1R1ZuTdHRhV+EveZUHs2hhjTIACS1SqmgeMBL4CFgFj/bQbD4rIOUEdtyzrtGksDmuMMeYAVOyET5RU9XPg8xJl95VSd1CgsQDLtXWQhzDGGBOAhJmZwl3wGza+49d5MYvFGGNM9BInUZUsWFKtJn83xpiElTCJah/f/CXWERhjjIlCwiQqu8OvMcZUTwmTqGwOJWOMqZ4SJlFZi8oYY6qnxElUsQ7AGGNMhSRMoopoy/JYR2CMMaYcCZOoCrr+Nhz//4oKn+0Tm2CMMSbOiMirIrJRROaHlTURkQkistQ/N/blIiLP+JvizhWRQL9MEydR+c6/vY06xTgSY4yJS68Dg0uU3QlMUtUuwCT/GtwNcbv4xzXAC0EGljiJquAkVVJq8RXb1+xT1xhjEo2qTga2ligeCozxy2OAc8PK31BnKtBIRFoFFVvCJKoCe1qVuIvI34+ITSDGGFO1UgpuQOsf10SxTUtVXQ/gn1v48nJvjFuZAp2UNp4UjvpLSo5lGMYYEyt5qlpZ9/sr88a4lS1hWlRa2PcX4fPNLtnaNcYYA2wo6NLzzxt9eXk3xq1UCZOoCkik3wGPdazyOIwxphoYBwzzy8OAT8LKr/Cj//oDmQVdhEFImK6/AgIgSaChWIdijDFxQ0TeAQYBzUQkA7gfeBQYKyIjgF+AC3z1z4EzgWVANjA8yNgSJlEVm0Kp27mw4KPiFUIhSEq4BqYxxgCgqpeUsurkCHUVuC7YiIokzDdzwXVUIgLn/mPfCqt/qOKIjDHGRCNxEpVvUQlAau19K4wZYjPXGmNMHEqYRFUg4mCKAmOGVFkcxhhjopMwiWqfxtKVn+9badX3kLenSuIxxhgTncRJVP5ZCq6j6jAgcsXHOsOK76okJmOMMeVLnESlBYMpyqm4NwveOCf4gIwxxkQlYRJVRKM2ll/HGGNMTCVMooo4ni+lVukbPNsX1kwPKhxjjDFRSphEVZCp9un6u3VZ5PpblsIrp8LmpbBrM+zaEmh4xhhjIkucmSnCL/gNV6952Ru+dgbs2uSWH8gMIDJjjDFlSZwWlVfeWIp9FCQpY4wxMZEwiarMSSfuWBXdTqY8XxmhGGOM2Q+Jk6j8c8Th6bUbR7eTr+6GlZMrKyRjjDFRCDRRichgEVkiIstE5M4I628WkYUiMldEJolI+6BiKZrrb787/4ormBMwN8dmsTDGmCoQWKISkWTgeeAMoBtwiYh0K1HtJ6CvqvYAPgAeCyqeosEUpVS4cX70O/voGni4JfylBWxacuDBGWOMKVWQLaqjgWWqukJV9wLvAkPDK6jqN6qa7V9Oxd3OOFCltqcatYO7MqLbybyxRcvPHw1rZ7mHMcaYShdkomoDrAl7neHLSjMC+CLSChG5RkRmisjMvLy8CgUT1R08atWHP02Bmxbs385fPtE9PvpjhWIzxhhTuiATVaTGS8R0ISKXAX2BxyOtV9XRqtpXVfumpFTs0q/CA5d3iqplN2jYFg46cv8PMvfdovNXO9bv//bGGGP2EWSiygDahb1uC6wrWUlETgHuAc5R1eBGJxRMShvtYIqrxlfsOE91d+evnjwc1v0EO9bBj6/bTRmNMaaCgpyZYgbQRUQ6AmuBi4Hfh1cQkd7AS8BgVa2SGWLLnT29QFqdih1gx9qi5dGDipbz9sIx11Rsn8YYUwVEZBWQBeQDearaV0SaAO8BHYBVwIWquq0q4wqsRaWqecBI4CtgETBWVReIyIMiUnAfjceBesD7IjJbRMYFFk9FNhoxAYY8A8def+ABfHEbvDoYxpwDiz6F3VX6dzbGmGidqKq9VLWvf30nMElVuwCT/OsqFehcf6r6OfB5ibL7wpZPCfL4xY/rnvfrKqp2R7sHQKte8OGIAwvilynueWXYjRlt/kBjTHwbCgzyy2OAb4E7qjKAxJmZQkuZlDZaR/4umKTy6zz3vHExfH4bvHdZ5R/DGGMgpWD0tH9EOhehwHgR+TFsfUtVXQ/gn1tUVcAFEmb29AIHOC9FUbJ6oOGB7sl58bh9y7K3QnojyM2GWvUq5zjGmESXF9adV5oBqrpORFoAE0RkcVUEVp7EaVFV9g7vC/Ac02Md4cHG8Egb2LYquOMYY0wYVV3nnzcCH+MmbtggIq0A/HOV3xo9cRJVaTdOrKikJLh5EQwNeEb1p3u61tvDrWFvNqz4Dtb+CBsXwRd3ui5DY4w5QCJSV0TqFywDpwHzgXHAMF9tGPBJVceWMF1/hbOnH3jnX5EGraH3ZXDoYMjPhWkvwLJJsGE/5g2MVu4u+H+t9i2f9oINyDDGVIaWwMf+PH4K8LaqfikiM4CxIjIC+AW4oKoDS5hEVagS81Shus3c86kPusdLJ8D62QEcqBTh58u6DoFu57rpoGo3gZbdXTMytXbVxWOMqXZUdQXQM0L5FuDkqo+oSMIkKq3KmSGGfwF7d0K9FvBkt+IXAQdt0X/co6Rbl7mE+udGcNzNcMr9VReTMcYcgIQ5R1Wg0s5RlSWtjktSADcvhJsWQo+Lq+DAZfjbIS5JAfzwJPw6303vBJCTCQvH2TRPxpi4lEAtKvdcFXlqHw3bwPkvucfmpdA0LGnEyosDIpcPeQaOGua6E5sfDn/6LyQlu3WhfMjeUpSEjTGmCiROouIAL/itLM26uOf//QmWTiya/6+yrss6UP/5X/cA2LQYHmxSdn0byGGMCVjiJKpYtqgiadKp+CS1D2RCzg53bqtBa8jMcDOxx7uCBHvKn+Gb/wfnPAMT7oedv0KzQ+F/prlzdHk5RUl6f+Tthfw9bnCIMSYhJU6i8s+xblCVKb2Be4C7J9ZFb0FKOjTuAGMvh40LYcjT8J8bYhpmRBP94IyPw24euflnd+FyJA3awuBH3PsCuHONe+85OyCtrutuDIXglVPdCMrwltuO9bBmGnQ/N5j3YoyJK1Klo+EqQd26dXXXrl37vd2CdZnM+mU7F/drR2pyNRxDEgrBrk1QvyVk/Oi+vPuNgC3L4dk+sY6uapxwB/S4qOj9Xvw2NOkMLQ4vXm/HOqjbAvfzRCC5jN9jmWtda63gB4IxNZSIZKtq3VjHUREJk6hqtCVfQJ2mRTO979nppl86++/u5o2zxsQ2vqrUqD1sX1287NZlbs7E1Nrw1oWw9CsYMRFCefDaYDe45fof3cwfc9+FFt3g4P6xid+YgFiiqkKWqCqg4DzSHye7L+q2fWHxp7GNKd70uhRmv1W8bORMWDsLVn0PJ93ruiN/eAoG3WWTBZtqxxJVFbJEVckmPeQGbsx9FwbcAP/3tCvvOwLWzoT1c2IbX3VwxG9h/odu+dSHoHZjGDfSvU5Og+7nQeOO8N2j7nPtdAIcfKzrctyxFnZvhw3z4Kgr3aifJZ+7abkKLgsAyPrV1W1zVJW/PVMzWKKqQpaoqti6nwBxtxyp1xLSG7ov03Ej4ecvYx1dzdb5JLjsI3ft3fP9XNk137nP/uT73fRYe3fBL1Pdj4qT7nWzj3z7KHQaBO2OcdfrDbgRTv1zdMdcNxta9Yw86mjpBJdcS3aLblriRnjG9UglY4mqClmiihO7NsPjnWHQ3XCsbz3MegMWfAwjxsOMV6BFV3jtDLfumD+5CXRNbKTWdRMbR3JQDzjmWpj0Z9i5Ac5+Cqb/E3ZvhcPPhsbtod/V8HBLV//id2D8KLh6kmtxvzHUbdPzEjdKNZTvLilIq+B3YigfEHeHAlNpLFFVIUtU1Uz2VqjVoGjk3Zblbtj69NFuAt292TD+ntjGaILXcSAceWFRl2inE2HgrZBcC1r3gvVzITXd3TD0qW6uzuX/hkYHw4YFbqBQxgw46EjXPb1tNfz2n66F9/VDcNxNbl+hPFcmApuXwcrv3OhYY4mqKlmiquGyNrgpmraucF1KKbWgQRt3XVneHti1Eeo2d12RCz6GvlfBr/Ncl9X8D10XmDEldR2y72TNF4wBDbmL7wHS6sGMl+E318F3j7lb+KQ3cpc/bFgASSnwr99C5hroeg78/BXcs979u1zyOfz7T3DpB1C/FTTtXPwc4451LoGWvHBdNbou0727YE8W1D+owh+BJaoqZInKlCo3B375L7To7pKdiLv+DC3+pQHuP/7qKW6AwoyX3ZfNeS/Bulnw2S2uTvOusGmRW254MGT+UqVvxyS4ATfC//29eNkBTFlmiaoKWaIygcvb426EWXII+vY1sHS8GzjQ8XhXFgq55Nj0EJAk9wu95K/e1VPctVs/POUuUN663JUPfR4+uc4l1qQkl2i3LC3a7uBj3b6NKXDNt9C6d4U2tURVhSxRmWovPw9CuaXfzLJwYkrfJbRwnOsK7XwiNDvMncvZtsoNfW/Qumi7l09253vmvQ9/mOT288OTMOcd6HA89Pq9m4dx10Y3Ldchp8Ihp8A7FwX5bk1lq2CryhJVFbJEZUwly9vrukaTkl0CrNOs9AuaC86pqLqBC7s2uWS5YSFkrYMV37qprnIyIbUO1GniBtAs+cKNAkXdOaH0RjDtJZdUj/mj21dSKvz3GTh/tJvLceIDcMKdbjRp1rqirthEH0FqiSr+WaIyxpQpP889F4w0zdkBi8a52UfCBy6EQu65oGz7Ly7R9r4M9uxwF26rwob50LCde25zFGxd6bpxT/uL6+5dOt61Ulv1gtlvuyH7l38E//iN696d977rEk6p5c6NNukEU//hEm7uLpeIL/8YJj8B2Zvd7XXCNWznBnAA3Lul7Lkry1BeohKRwcDTQDLwT1V9tEIHCoAlKmOMSQBlJSoRSQZ+Bk4FMoAZwCWqurAKQyyVXVFnjDHmaGCZqq5Q1b3Au8DQGMdUyBKVMcYkhhQRmRn2CLtzK22ANWGvM3xZXEiYGycaY0yCy1PVvqWsi3TVcdycF7IWlTHGmAygXdjrtsC6GMWyD0tUxhhjZgBdRKSjiKQBFwPjYhxToUATlYgMFpElIrJMRO6MsL6WiLzn108TkQ5BxmOMMWZfqpoHjAS+AhYBY1V1QWyjKhLY8PRohjuKyP8APVT1WhG5GDhPVcu8TN6GpxtjzP6rzhf8Btmiima441BgjF/+ADhZxO6+ZowxpkiQo/4iDXc8prQ6qponIplAU2BzeCU/jLJgKKWKyO4KxpQC5FVw21iqrnFD9Y3d4q5aFnfwSplcMv4FmaiiGe4Y1ZBIVR0NjD7ggERmljE8M25V17ih+sZucVcti9uUJciuv2iGOxbWEZEUoCGwNcCYjDHGVDNBJqpohjuOA4b55d8BX2t1m3zQGGNMoALr+vPnnAqGOyYDr6rqAhF5EJipquOAV4A3RWQZriV1cVDxeAfcfRgj1TVuqL6xW9xVy+I2pap2s6cbY4xJLDYzhTHGmLhmicoYY0xcS5hEVd50TrEgIqtEZJ6IzBaRmb6siYhMEJGl/rmxLxcRecbHP1dE+oTtZ5ivv1REhpV2vAOI81UR2Sgi88PKKi1OETnKfw7L/LaVctF3KXE/ICJr/Wc+W0TODFt3l49hiYicHlYe8d+OHyg0zb+f9/ygocqIu52IfCMii0RkgYjc4Mvj+jMvI+64/sxFJF1EpovIHB/3n8s6lpQx9dv+vh8TJVWt8Q/cYI7lQCcgDZgDdIuDuFYBzUqUPQbc6ZfvBP7ql88EvsBde9YfmObLmwAr/HNjv9y4kuMcCPQB5gcRJzAd+I3f5gvgjADjfgC4NULdbv7fRS2go//3klzWvx1gLHCxX34R+FMlxd0K6OOX6+OmIusW7595GXHH9WfuP4N6fjkVmOY/x4jHAv4HeNEvXwy8V9H3Y4/oHonSoorru1eWED6t1Bjg3LDyN9SZCjQSkVbA6cAEVd2qqtuACcDgygxIVSez7/VtlRKnX9dAVaeo+9/+Rti+goi7NEOBd1V1j6quBJbh/t1E/LfjWyAn4ab+guKfwYHGvV5VZ/nlLNwkoW2I88+8jLhLExefuf/cdvqXqf6hZRyrtKnf9uv9HGjciSRRElW83r1SgfEi8qMU3W2zpaquB/cfH2jhy0t7D7F6b5UVZxu/XLI8SCN9F9mrBd1n5cQXqbwpsF3drNPh5ZXKdyv1xv3KrzafeYm4Ic4/cxFJFpHZwEZcQl9exrGKTf0GFEz9Fm//R2uMRElU8Xr3ygGq2gc4A7hORAaWUbe09xBv721/46zq+F8AOgO9gPXAE7487uIWkXrAh8CNqrqjrKqlxBKT2CPEHfefuarmq2ov3Aw6RwNdyzhW3MSdKBIlUcXl3StVdZ1/3gh8jPsPssF3zeCfN/rqpb2HWL23yoozwy+XLA+Eqm7wX0oh4GXcZ16RuDfjuthSSpRXChFJxX3Zv6WqH/niuP/MI8VdXT5zH+t24FvcOarSjlXa1G/x9n+0xkiURBV3d68UkboiUr9gGTgNmE/xaaWGAZ/45XHAFX6EV38g03f/fAWcJiKNfZfKab4saJUSp1+XJSL9fT//FWH7qnQFX/TeebjPvCDui/2Iro5AF9yAg4j/dvy5nW9wU39B8c/gQGMU3Kwti1T1ybBVcf2ZlxZ3vH/mItJcRBr55drAKbjza6Udq7Sp3/br/Rxo3Akl1qM5quqBGxn1M67v+Z44iKcTbvTPHGBBQUy4vu5JwFL/3MSXC/C8j38e0DdsX1fhTtwuA4YHEOs7uC6bXNyvwxGVGSfQF/fltRx4Dj9jSkBxv+njmov7smgVVv8eH8MSwkbBlfZvx/8Np/v38z5Qq5LiPg7XNTQXmO0fZ8b7Z15G3HH9mQM9gJ98fPOB+8o6FpDuXy/z6ztV9P3YI7qHTaFkjDEmriVK158xxphqyhKVMcaYuGaJyhhjTFyzRGWMMSauWaIyxhgT1yxRGVOFRGSQiHwa6ziMqU4sURljjIlrlqiMiUBELvP3KJotIi/5SUt3isgTIjJLRCaJSHNft5eITPWTrn4sRfeJOkREJoq7z9EsEensd19PRD4QkcUi8paf0cEYUwpLVMaUICJdgYtwkwb3AvKBS4G6wCx1Ewl/B9zvN3kDuENVe+BmYCgofwt4XlV7AsfiZskAN6v4jbj7F3UCBgT+poypxlLKr2JMwjkZOAqY4Rs7tXETwIaA93ydfwEfiUhDoJGqfufLxwDv+3kc26jqxwCqmgPg9zddVTP869lAB+CH4N+WMdWTJSpj9iXAGFW9q1ihyL0l6pU1/1hZ3Xl7wpbzsf+HxpTJuv6M2dck4Hci0gJARJqISHvc/5eC2bR/D/ygqpnANhE53pdfDnyn7j5MGSJyrt9HLRGpU6Xvwpgawn7JGVOCqi4UkVG4uy8n4WZfvw7YBXQXkR9xd3W9yG8yDHjRJ6IVwHBffjnwkog86PdxQRW+DWNqDJs93ZgoichOVa0X6ziMSTTW9WeMMSauWQ1tkVEAAAAvSURBVIvKGGNMXLMWlTHGmLhmicoYY0xcs0RljDEmrlmiMsYYE9csURljjIlr/x+RfVALmd6FWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfdf8b0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully network was constructed!\n"
     ]
    }
   ],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net = neuralNetwork.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.326\n",
      "epoch : 101, loss : 0.0313\n",
      "epoch : 201, loss : 0.024\n",
      "epoch : 301, loss : 0.0174\n",
      "epoch : 401, loss : 0.0159\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device('cpu')\n",
    "model = MLP(784,400,50,10).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(y,t)\n",
    "\n",
    "def train_step(x,t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    #print(preds.shape)\n",
    "    loss = compute_loss(t,preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 500\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    batch = np.random.choice(x_train.shape[0],batch_size)\n",
    "    x_ = x_train[batch]\n",
    "    t_ = t_train[batch]\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    t_ = torch.Tensor(t_).to(device)\n",
    "    \n",
    "    loss = train_step(x_,t_)\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        \n",
    "        print('epoch : {}, loss : {:.3}'.format(\n",
    "            epoch + 1,\n",
    "            train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc : 0.979, test_acc : 0.893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_step(x,t):\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t,preds)\n",
    "    return loss,preds\n",
    "\n",
    "test_loss,test_preds = test_step(x_test,t_test)\n",
    "train_loss,train_preds = test_step(x_train,t_train)\n",
    "test_loss = test_loss.item()\n",
    "train_loss = train_loss.item()\n",
    "test_preds = np.argmax(test_preds.data.cpu().numpy(),axis=1)\n",
    "train_preds = np.argmax(train_preds.data.cpu().numpy(),axis=1)\n",
    "test_ans = np.argmax(t_test,axis=1)\n",
    "test_acc = accuracy_score(test_ans,test_preds)\n",
    "train_ans = np.argmax(t_train,axis=1)\n",
    "train_acc = accuracy_score(train_ans,train_preds)\n",
    "\n",
    "print('train_acc : {:.3f}, test_acc : {:.3f}'.format(\n",
    "    train_acc,\n",
    "    test_acc\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1208e-04, 5.7649e-04, 1.5671e-03, 4.2597e-03, 1.1579e-02, 3.1475e-02,\n",
       "         8.5559e-02, 2.3257e-01, 6.3220e-01]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7,8,9]])\n",
    "a = torch.Tensor(a).to(device)\n",
    "l = nn.Softmax(dim = 1)\n",
    "l(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,train = True):\n",
    "        x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "        t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "        x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "        t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "        t_train = np.identity(10)[t_train]\n",
    "        t_test = np.identity(10)[t_test]\n",
    "        x_train = x_train.reshape((60000,-1)).astype(float)\n",
    "        x_test = x_test.reshape((10000,-1)).astype(float)\n",
    "        x_train = x_train/255\n",
    "        x_test = x_test/255\n",
    "        if train:\n",
    "            #self.x = torch.from_numpy(x_train).float\n",
    "            #self.t = torch.from_numpy(t_train).long\n",
    "            self.x = x_train\n",
    "            self.t = t_train\n",
    "            self.size = x_train.shape[0]\n",
    "        else:\n",
    "            #self.x = torch.from_numpy(x_test).float\n",
    "            #self.t = torch.from_numpy(t_test).long\n",
    "            self.x = x_test\n",
    "            self.t = t_test\n",
    "            self.size = x_test.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kuzushijiMNIST(batch_size = 500):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(True),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(False),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train' : train_loader,\n",
    "        'test' : test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "history = {\n",
    "    'train_loss' : [],\n",
    "    'test_loss' : [],\n",
    "    'test_acc' : []\n",
    "}\n",
    "\n",
    "net = Net(784,400,40,10)\n",
    "loaders = load_kuzushijiMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0157, 0.7804, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0471, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0039, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4824, 0.4000, 0.1255],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4549,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9412, 0.0941, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7569, 0.1451, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5216, 0.5412, 0.0353]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6824, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0980, 0.2627,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0431, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.6118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9843, 0.3020, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0353,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0784, 0.1765, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.1490,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0588, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.5804, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.8941, 0.3490, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9529, 0.3098, 0.0039],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2902, 0.0784, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0314, 0.1922],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3216, 0.1451, 0.0196],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.2706,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3843, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4235, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0627, 0.3137, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1216, 0.8824, 0.1765,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.2314, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6118, 0.9843, 0.6118,  ..., 0.4824, 0.0078, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data,target in loaders['train']:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(params = net.parameters(),lr = 0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1,batch : 128/60000,loss : 0.32562965154647827\n",
      "epoch : 1,batch : 1408/60000,loss : 0.15830664336681366\n",
      "epoch : 1,batch : 2688/60000,loss : 0.10345988720655441\n",
      "epoch : 1,batch : 3968/60000,loss : 0.07579276710748672\n",
      "epoch : 1,batch : 5248/60000,loss : 0.07180974632501602\n",
      "epoch : 1,batch : 6528/60000,loss : 0.07020606100559235\n",
      "epoch : 1,batch : 7808/60000,loss : 0.060317933559417725\n",
      "epoch : 1,batch : 9088/60000,loss : 0.05069664120674133\n",
      "epoch : 1,batch : 10368/60000,loss : 0.05856812745332718\n",
      "epoch : 1,batch : 11648/60000,loss : 0.04413367435336113\n",
      "epoch : 1,batch : 12928/60000,loss : 0.039065614342689514\n",
      "epoch : 1,batch : 14208/60000,loss : 0.047319211065769196\n",
      "test accuracy : 0.8411\n",
      "epoch : 2,batch : 128/60000,loss : 0.03204628825187683\n",
      "epoch : 2,batch : 1408/60000,loss : 0.025458727031946182\n",
      "epoch : 2,batch : 2688/60000,loss : 0.03425682336091995\n",
      "epoch : 2,batch : 3968/60000,loss : 0.028589818626642227\n",
      "epoch : 2,batch : 5248/60000,loss : 0.02421424724161625\n",
      "epoch : 2,batch : 6528/60000,loss : 0.02936953492462635\n",
      "epoch : 2,batch : 7808/60000,loss : 0.023337045684456825\n",
      "epoch : 2,batch : 9088/60000,loss : 0.030201995745301247\n",
      "epoch : 2,batch : 10368/60000,loss : 0.03466672822833061\n",
      "epoch : 2,batch : 11648/60000,loss : 0.023305097594857216\n",
      "epoch : 2,batch : 12928/60000,loss : 0.026867486536502838\n",
      "epoch : 2,batch : 14208/60000,loss : 0.03513367101550102\n",
      "test accuracy : 0.8708\n",
      "epoch : 3,batch : 128/60000,loss : 0.02319392003118992\n",
      "epoch : 3,batch : 1408/60000,loss : 0.01709127239882946\n",
      "epoch : 3,batch : 2688/60000,loss : 0.018111469224095345\n",
      "epoch : 3,batch : 3968/60000,loss : 0.014557821676135063\n",
      "epoch : 3,batch : 5248/60000,loss : 0.01512590330094099\n",
      "epoch : 3,batch : 6528/60000,loss : 0.017109690234065056\n",
      "epoch : 3,batch : 7808/60000,loss : 0.017189402133226395\n",
      "epoch : 3,batch : 9088/60000,loss : 0.019132234156131744\n",
      "epoch : 3,batch : 10368/60000,loss : 0.020565830171108246\n",
      "epoch : 3,batch : 11648/60000,loss : 0.018769145011901855\n",
      "epoch : 3,batch : 12928/60000,loss : 0.01944355107843876\n",
      "epoch : 3,batch : 14208/60000,loss : 0.01974104717373848\n",
      "test accuracy : 0.8862\n",
      "epoch : 4,batch : 128/60000,loss : 0.011614253744482994\n",
      "epoch : 4,batch : 1408/60000,loss : 0.012034856714308262\n",
      "epoch : 4,batch : 2688/60000,loss : 0.009736406616866589\n",
      "epoch : 4,batch : 3968/60000,loss : 0.021139031276106834\n",
      "epoch : 4,batch : 5248/60000,loss : 0.015447190962731838\n",
      "epoch : 4,batch : 6528/60000,loss : 0.013809082098305225\n",
      "epoch : 4,batch : 7808/60000,loss : 0.010202538222074509\n",
      "epoch : 4,batch : 9088/60000,loss : 0.013362913392484188\n",
      "epoch : 4,batch : 10368/60000,loss : 0.026109125465154648\n",
      "epoch : 4,batch : 11648/60000,loss : 0.011653976514935493\n",
      "epoch : 4,batch : 12928/60000,loss : 0.020759090781211853\n",
      "epoch : 4,batch : 14208/60000,loss : 0.016076456755399704\n",
      "test accuracy : 0.8965\n",
      "epoch : 5,batch : 128/60000,loss : 0.012907855212688446\n",
      "epoch : 5,batch : 1408/60000,loss : 0.01028241217136383\n",
      "epoch : 5,batch : 2688/60000,loss : 0.011401785537600517\n",
      "epoch : 5,batch : 3968/60000,loss : 0.013149754144251347\n",
      "epoch : 5,batch : 5248/60000,loss : 0.014900248497724533\n",
      "epoch : 5,batch : 6528/60000,loss : 0.010914977639913559\n",
      "epoch : 5,batch : 7808/60000,loss : 0.013847623020410538\n",
      "epoch : 5,batch : 9088/60000,loss : 0.014637126587331295\n",
      "epoch : 5,batch : 10368/60000,loss : 0.01335443090647459\n",
      "epoch : 5,batch : 11648/60000,loss : 0.014864697121083736\n",
      "epoch : 5,batch : 12928/60000,loss : 0.01892690733075142\n",
      "epoch : 5,batch : 14208/60000,loss : 0.020673399791121483\n",
      "test accuracy : 0.8996\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    loss = None\n",
    "    net.train()\n",
    "    \n",
    "    for j ,(data,target) in enumerate(loaders['train']):\n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        #print('flag')\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 10 == 0:\n",
    "            print('epoch : {},batch : {}/60000,loss : {}'.format(\n",
    "                i+1,\n",
    "                (j+1)*128,\n",
    "                loss.item()\n",
    "            ))\n",
    "    history['train_loss'].append(loss)\n",
    "    \n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in loaders['test']:\n",
    "            data = data.float()\n",
    "            target = target.float()\n",
    "            output = net(data)\n",
    "            test_loss += criterion(output,target).item()\n",
    "            pred = output.argmax(dim=1,keepdim = False)\n",
    "            ans = target.argmax(dim = 1,keepdim=False)\n",
    "            correct += (pred == ans).sum().item()\n",
    "    test_loss /= 10000\n",
    "    \n",
    "    print('test accuracy : {}'.format(correct/10000))\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(correct/10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
