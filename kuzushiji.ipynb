{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# くずし字 MNIST データセットの学習\n",
    "[github](https://github.com/rois-codh/kmnist)からダウンロードしたくずし字データセットを今回作成したニューラルネットワークのクラスneuralNetworkを用いて学習させ、その精度を求めた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural import neuralNetwork #自作ライブラリ\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "t_train = np.identity(10)[t_train]\n",
    "t_test = np.identity(10)[t_test]\n",
    "x_train = x_train.reshape((60000,-1))\n",
    "x_test = x_test.reshape((10000,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< successfully layers are updated >>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural.neuralNetwork at 0x7fdccd914978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = neuralNetwork(\n",
    "    epoch = 33000,\n",
    "    learning_rate = 0.05,\n",
    "    batch_size = 500\n",
    ")\n",
    "layer_list = [784,[500,80],10]\n",
    "net.set_layer(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch0 ---------\n",
      "loss : 1162.5721240588816\n",
      "accuracy : 0.114\n",
      "time : 0.02149200439453125 [sec]\n",
      "--------------------------\n",
      "\n",
      "--------- epoch100 ---------\n",
      "loss : 984.9107651557969\n",
      "accuracy : 0.472\n",
      "time : 2.4940690994262695 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch200 ---------\n",
      "loss : 767.1408073916086\n",
      "accuracy : 0.616\n",
      "time : 4.848241090774536 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch300 ---------\n",
      "loss : 606.073812948242\n",
      "accuracy : 0.648\n",
      "time : 7.208186149597168 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch400 ---------\n",
      "loss : 474.92875648308654\n",
      "accuracy : 0.728\n",
      "time : 9.61250901222229 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch500 ---------\n",
      "loss : 450.19574532461024\n",
      "accuracy : 0.75\n",
      "time : 12.291325092315674 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch600 ---------\n",
      "loss : 380.6405004903724\n",
      "accuracy : 0.774\n",
      "time : 14.78856110572815 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch700 ---------\n",
      "loss : 358.05169436136686\n",
      "accuracy : 0.796\n",
      "time : 17.406227111816406 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch800 ---------\n",
      "loss : 306.6364472508459\n",
      "accuracy : 0.808\n",
      "time : 19.910097122192383 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch900 ---------\n",
      "loss : 357.772107694655\n",
      "accuracy : 0.776\n",
      "time : 22.403127193450928 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch1000 ---------\n",
      "loss : 303.24691810910065\n",
      "accuracy : 0.816\n",
      "time : 24.85385298728943 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1100 ---------\n",
      "loss : 255.62735886503913\n",
      "accuracy : 0.836\n",
      "time : 27.335569143295288 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1200 ---------\n",
      "loss : 292.811736884463\n",
      "accuracy : 0.84\n",
      "time : 29.9396550655365 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1300 ---------\n",
      "loss : 285.19562736459795\n",
      "accuracy : 0.828\n",
      "time : 32.52012801170349 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1400 ---------\n",
      "loss : 257.72110019423366\n",
      "accuracy : 0.858\n",
      "time : 35.013522148132324 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1500 ---------\n",
      "loss : 251.8909914099026\n",
      "accuracy : 0.848\n",
      "time : 37.485584020614624 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1600 ---------\n",
      "loss : 242.8234876277378\n",
      "accuracy : 0.858\n",
      "time : 40.073002099990845 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1700 ---------\n",
      "loss : 246.3462827592076\n",
      "accuracy : 0.862\n",
      "time : 42.62759518623352 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1800 ---------\n",
      "loss : 253.58917572123613\n",
      "accuracy : 0.824\n",
      "time : 45.26337218284607 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1900 ---------\n",
      "loss : 274.11468823109647\n",
      "accuracy : 0.842\n",
      "time : 47.826539039611816 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2000 ---------\n",
      "loss : 207.37962080918462\n",
      "accuracy : 0.874\n",
      "time : 50.33866500854492 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2100 ---------\n",
      "loss : 199.24889908335314\n",
      "accuracy : 0.892\n",
      "time : 52.885316133499146 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2200 ---------\n",
      "loss : 203.4232208086388\n",
      "accuracy : 0.878\n",
      "time : 55.41818714141846 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2300 ---------\n",
      "loss : 236.8407537679377\n",
      "accuracy : 0.86\n",
      "time : 57.912373065948486 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2400 ---------\n",
      "loss : 212.03013511292778\n",
      "accuracy : 0.89\n",
      "time : 60.468759059906006 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2500 ---------\n",
      "loss : 237.16856370240754\n",
      "accuracy : 0.864\n",
      "time : 62.9887421131134 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2600 ---------\n",
      "loss : 237.8345208666418\n",
      "accuracy : 0.862\n",
      "time : 65.50102114677429 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2700 ---------\n",
      "loss : 220.20413486387037\n",
      "accuracy : 0.876\n",
      "time : 68.05591416358948 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2800 ---------\n",
      "loss : 167.0392705705184\n",
      "accuracy : 0.906\n",
      "time : 70.54453611373901 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2900 ---------\n",
      "loss : 179.8250538045464\n",
      "accuracy : 0.902\n",
      "time : 73.14609599113464 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3000 ---------\n",
      "loss : 210.4917923101981\n",
      "accuracy : 0.88\n",
      "time : 75.67927598953247 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3100 ---------\n",
      "loss : 223.64233135830378\n",
      "accuracy : 0.864\n",
      "time : 78.1560800075531 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3200 ---------\n",
      "loss : 176.59541825300036\n",
      "accuracy : 0.9\n",
      "time : 80.73036909103394 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3300 ---------\n",
      "loss : 172.85057336643968\n",
      "accuracy : 0.898\n",
      "time : 83.22200512886047 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3400 ---------\n",
      "loss : 172.40007224878343\n",
      "accuracy : 0.906\n",
      "time : 85.73588609695435 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3500 ---------\n",
      "loss : 170.4671298289417\n",
      "accuracy : 0.878\n",
      "time : 88.28723216056824 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3600 ---------\n",
      "loss : 175.107257394864\n",
      "accuracy : 0.892\n",
      "time : 90.77501702308655 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3700 ---------\n",
      "loss : 193.87661216864333\n",
      "accuracy : 0.89\n",
      "time : 93.26046895980835 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3800 ---------\n",
      "loss : 175.69133447583658\n",
      "accuracy : 0.916\n",
      "time : 95.74233102798462 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3900 ---------\n",
      "loss : 194.2337273519636\n",
      "accuracy : 0.892\n",
      "time : 98.2521870136261 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4000 ---------\n",
      "loss : 169.3651301930467\n",
      "accuracy : 0.916\n",
      "time : 100.77155303955078 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4100 ---------\n",
      "loss : 163.49522771556371\n",
      "accuracy : 0.9\n",
      "time : 103.25910210609436 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4200 ---------\n",
      "loss : 170.57157414145868\n",
      "accuracy : 0.9\n",
      "time : 105.74457001686096 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4300 ---------\n",
      "loss : 204.1525379135928\n",
      "accuracy : 0.886\n",
      "time : 108.250892162323 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4400 ---------\n",
      "loss : 118.3294069645643\n",
      "accuracy : 0.934\n",
      "time : 110.77087306976318 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4500 ---------\n",
      "loss : 132.29111096904126\n",
      "accuracy : 0.926\n",
      "time : 113.2713520526886 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4600 ---------\n",
      "loss : 150.96676825946292\n",
      "accuracy : 0.908\n",
      "time : 115.71523213386536 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4700 ---------\n",
      "loss : 158.05016326356503\n",
      "accuracy : 0.908\n",
      "time : 118.18865418434143 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4800 ---------\n",
      "loss : 158.47059908035135\n",
      "accuracy : 0.912\n",
      "time : 120.68582510948181 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4900 ---------\n",
      "loss : 154.34568000794224\n",
      "accuracy : 0.902\n",
      "time : 123.2209529876709 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5000 ---------\n",
      "loss : 114.97145835153874\n",
      "accuracy : 0.938\n",
      "time : 125.64767408370972 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5100 ---------\n",
      "loss : 159.94404715777398\n",
      "accuracy : 0.922\n",
      "time : 128.14030718803406 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5200 ---------\n",
      "loss : 122.6234929781309\n",
      "accuracy : 0.928\n",
      "time : 130.62916016578674 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5300 ---------\n",
      "loss : 100.45448938900172\n",
      "accuracy : 0.946\n",
      "time : 133.11581897735596 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5400 ---------\n",
      "loss : 152.5233402658945\n",
      "accuracy : 0.91\n",
      "time : 135.6219220161438 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5500 ---------\n",
      "loss : 144.45879952779956\n",
      "accuracy : 0.908\n",
      "time : 138.10907101631165 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5600 ---------\n",
      "loss : 138.78179438939335\n",
      "accuracy : 0.92\n",
      "time : 140.56302618980408 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5700 ---------\n",
      "loss : 116.98592243372228\n",
      "accuracy : 0.936\n",
      "time : 143.17870616912842 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5800 ---------\n",
      "loss : 138.0179035754752\n",
      "accuracy : 0.912\n",
      "time : 145.93871402740479 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5900 ---------\n",
      "loss : 142.6574568390102\n",
      "accuracy : 0.92\n",
      "time : 148.76702904701233 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6000 ---------\n",
      "loss : 113.91991633990459\n",
      "accuracy : 0.942\n",
      "time : 151.63485097885132 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6100 ---------\n",
      "loss : 117.68955326088903\n",
      "accuracy : 0.922\n",
      "time : 154.37461519241333 [sec]\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch6200 ---------\n",
      "loss : 116.80719924617189\n",
      "accuracy : 0.93\n",
      "time : 157.08914613723755 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6300 ---------\n",
      "loss : 133.31068785697784\n",
      "accuracy : 0.916\n",
      "time : 159.5571060180664 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6400 ---------\n",
      "loss : 114.21327641623938\n",
      "accuracy : 0.934\n",
      "time : 161.99715113639832 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6500 ---------\n",
      "loss : 136.30986083409562\n",
      "accuracy : 0.922\n",
      "time : 164.49008202552795 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6600 ---------\n",
      "loss : 126.77927467157984\n",
      "accuracy : 0.918\n",
      "time : 166.91342210769653 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6700 ---------\n",
      "loss : 108.43990177315924\n",
      "accuracy : 0.948\n",
      "time : 169.38929510116577 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6800 ---------\n",
      "loss : 114.00133124129634\n",
      "accuracy : 0.938\n",
      "time : 171.91936016082764 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6900 ---------\n",
      "loss : 139.15889087718608\n",
      "accuracy : 0.94\n",
      "time : 174.40669298171997 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7000 ---------\n",
      "loss : 106.40410056140945\n",
      "accuracy : 0.946\n",
      "time : 176.88350009918213 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7100 ---------\n",
      "loss : 132.05051012180598\n",
      "accuracy : 0.916\n",
      "time : 179.36390113830566 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7200 ---------\n",
      "loss : 112.09246472049001\n",
      "accuracy : 0.934\n",
      "time : 181.8318920135498 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7300 ---------\n",
      "loss : 92.0673053792155\n",
      "accuracy : 0.96\n",
      "time : 184.31991600990295 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7400 ---------\n",
      "loss : 85.57157700941005\n",
      "accuracy : 0.954\n",
      "time : 186.74759101867676 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7500 ---------\n",
      "loss : 144.23794404366782\n",
      "accuracy : 0.93\n",
      "time : 189.22220611572266 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7600 ---------\n",
      "loss : 86.30196723408558\n",
      "accuracy : 0.956\n",
      "time : 191.70639514923096 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7700 ---------\n",
      "loss : 84.60963323056541\n",
      "accuracy : 0.96\n",
      "time : 194.16990113258362 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7800 ---------\n",
      "loss : 79.17662269217763\n",
      "accuracy : 0.952\n",
      "time : 196.6649191379547 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7900 ---------\n",
      "loss : 97.0716593427833\n",
      "accuracy : 0.952\n",
      "time : 199.12869215011597 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8000 ---------\n",
      "loss : 86.7647253892726\n",
      "accuracy : 0.942\n",
      "time : 201.6411120891571 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8100 ---------\n",
      "loss : 106.62835860347396\n",
      "accuracy : 0.936\n",
      "time : 204.12002515792847 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8200 ---------\n",
      "loss : 109.27658798981429\n",
      "accuracy : 0.952\n",
      "time : 206.53654098510742 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8300 ---------\n",
      "loss : 90.75496679701882\n",
      "accuracy : 0.956\n",
      "time : 209.02979516983032 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8400 ---------\n",
      "loss : 92.29736778054492\n",
      "accuracy : 0.94\n",
      "time : 211.47507500648499 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8500 ---------\n",
      "loss : 85.11558729811271\n",
      "accuracy : 0.95\n",
      "time : 213.93657803535461 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8600 ---------\n",
      "loss : 83.68010176427862\n",
      "accuracy : 0.96\n",
      "time : 216.40665912628174 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8700 ---------\n",
      "loss : 101.75867333157035\n",
      "accuracy : 0.954\n",
      "time : 218.81629705429077 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8800 ---------\n",
      "loss : 58.210515208358004\n",
      "accuracy : 0.974\n",
      "time : 221.30480003356934 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8900 ---------\n",
      "loss : 93.04888176931146\n",
      "accuracy : 0.956\n",
      "time : 223.750422000885 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9000 ---------\n",
      "loss : 94.48882232130623\n",
      "accuracy : 0.954\n",
      "time : 226.21648406982422 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9100 ---------\n",
      "loss : 82.66978128589287\n",
      "accuracy : 0.964\n",
      "time : 228.7015311717987 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9200 ---------\n",
      "loss : 62.75509880907914\n",
      "accuracy : 0.968\n",
      "time : 231.1502649784088 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9300 ---------\n",
      "loss : 63.43193836931286\n",
      "accuracy : 0.964\n",
      "time : 233.63688898086548 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9400 ---------\n",
      "loss : 70.5713491061466\n",
      "accuracy : 0.964\n",
      "time : 236.08693313598633 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9500 ---------\n",
      "loss : 110.24278501651654\n",
      "accuracy : 0.946\n",
      "time : 238.52197408676147 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9600 ---------\n",
      "loss : 92.10284576417217\n",
      "accuracy : 0.952\n",
      "time : 241.01849913597107 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9700 ---------\n",
      "loss : 62.41383036053028\n",
      "accuracy : 0.972\n",
      "time : 243.43910813331604 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9800 ---------\n",
      "loss : 87.49905769151357\n",
      "accuracy : 0.95\n",
      "time : 245.91073417663574 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9900 ---------\n",
      "loss : 75.3065501782036\n",
      "accuracy : 0.952\n",
      "time : 248.4053361415863 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch10000 ---------\n",
      "loss : 95.90029751765266\n",
      "accuracy : 0.94\n",
      "time : 250.84283900260925 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10100 ---------\n",
      "loss : 70.5910283976186\n",
      "accuracy : 0.97\n",
      "time : 253.36770606040955 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10200 ---------\n",
      "loss : 77.08591422786982\n",
      "accuracy : 0.958\n",
      "time : 255.78844213485718 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10300 ---------\n",
      "loss : 69.96517395574395\n",
      "accuracy : 0.956\n",
      "time : 258.33200001716614 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10400 ---------\n",
      "loss : 60.17401660073663\n",
      "accuracy : 0.966\n",
      "time : 260.7965111732483 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10500 ---------\n",
      "loss : 62.88195664735528\n",
      "accuracy : 0.966\n",
      "time : 263.2432851791382 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10600 ---------\n",
      "loss : 66.0164906128996\n",
      "accuracy : 0.962\n",
      "time : 265.72801208496094 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10700 ---------\n",
      "loss : 70.08312334588253\n",
      "accuracy : 0.964\n",
      "time : 268.21566104888916 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10800 ---------\n",
      "loss : 60.31152680809687\n",
      "accuracy : 0.976\n",
      "time : 270.82533407211304 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10900 ---------\n",
      "loss : 81.51555990185999\n",
      "accuracy : 0.956\n",
      "time : 273.2631139755249 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11000 ---------\n",
      "loss : 67.9845012587482\n",
      "accuracy : 0.966\n",
      "time : 275.7412850856781 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11100 ---------\n",
      "loss : 46.352950792318694\n",
      "accuracy : 0.974\n",
      "time : 278.1967191696167 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11200 ---------\n",
      "loss : 56.86399406053029\n",
      "accuracy : 0.968\n",
      "time : 280.61823201179504 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11300 ---------\n",
      "loss : 61.22255047417929\n",
      "accuracy : 0.974\n",
      "time : 283.1215121746063 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11400 ---------\n",
      "loss : 48.07198337820161\n",
      "accuracy : 0.966\n",
      "time : 285.5453681945801 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11500 ---------\n",
      "loss : 61.191251636236444\n",
      "accuracy : 0.974\n",
      "time : 288.03537702560425 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11600 ---------\n",
      "loss : 56.81180913749728\n",
      "accuracy : 0.976\n",
      "time : 290.5142180919647 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11700 ---------\n",
      "loss : 58.67455183896133\n",
      "accuracy : 0.97\n",
      "time : 292.9495701789856 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11800 ---------\n",
      "loss : 61.18778362704238\n",
      "accuracy : 0.974\n",
      "time : 295.4378101825714 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11900 ---------\n",
      "loss : 44.812078792904856\n",
      "accuracy : 0.982\n",
      "time : 297.86477303504944 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12000 ---------\n",
      "loss : 72.1289640537765\n",
      "accuracy : 0.972\n",
      "time : 300.3132870197296 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12100 ---------\n",
      "loss : 48.03983139812689\n",
      "accuracy : 0.974\n",
      "time : 302.7966480255127 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12200 ---------\n",
      "loss : 56.35421766810689\n",
      "accuracy : 0.972\n",
      "time : 305.2108931541443 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch12300 ---------\n",
      "loss : 69.01688581242698\n",
      "accuracy : 0.966\n",
      "time : 307.6872589588165 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12400 ---------\n",
      "loss : 75.01126692951712\n",
      "accuracy : 0.952\n",
      "time : 310.13525009155273 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12500 ---------\n",
      "loss : 74.71086665228502\n",
      "accuracy : 0.964\n",
      "time : 312.59285712242126 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12600 ---------\n",
      "loss : 58.917844664855835\n",
      "accuracy : 0.966\n",
      "time : 315.0829429626465 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12700 ---------\n",
      "loss : 56.06702710325429\n",
      "accuracy : 0.98\n",
      "time : 317.5118579864502 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12800 ---------\n",
      "loss : 67.07009300551229\n",
      "accuracy : 0.958\n",
      "time : 319.97557306289673 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12900 ---------\n",
      "loss : 78.01669532703113\n",
      "accuracy : 0.96\n",
      "time : 322.449490070343 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13000 ---------\n",
      "loss : 72.49565284075283\n",
      "accuracy : 0.962\n",
      "time : 324.8590421676636 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13100 ---------\n",
      "loss : 44.5819138358211\n",
      "accuracy : 0.976\n",
      "time : 327.33977603912354 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13200 ---------\n",
      "loss : 62.52811407508645\n",
      "accuracy : 0.974\n",
      "time : 329.81252217292786 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13300 ---------\n",
      "loss : 55.219842639242614\n",
      "accuracy : 0.974\n",
      "time : 332.2507131099701 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13400 ---------\n",
      "loss : 41.32658547079754\n",
      "accuracy : 0.982\n",
      "time : 334.7436339855194 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13500 ---------\n",
      "loss : 50.81065140132141\n",
      "accuracy : 0.978\n",
      "time : 337.15874218940735 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13600 ---------\n",
      "loss : 102.41979527369624\n",
      "accuracy : 0.954\n",
      "time : 339.6393141746521 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13700 ---------\n",
      "loss : 65.03884687684848\n",
      "accuracy : 0.964\n",
      "time : 342.1015441417694 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13800 ---------\n",
      "loss : 55.08428634913267\n",
      "accuracy : 0.968\n",
      "time : 344.52131605148315 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13900 ---------\n",
      "loss : 44.346504369637934\n",
      "accuracy : 0.972\n",
      "time : 346.99930000305176 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14000 ---------\n",
      "loss : 54.364907537936446\n",
      "accuracy : 0.972\n",
      "time : 349.42124104499817 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14100 ---------\n",
      "loss : 50.84182189598796\n",
      "accuracy : 0.982\n",
      "time : 351.8731110095978 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14200 ---------\n",
      "loss : 56.12053598928566\n",
      "accuracy : 0.97\n",
      "time : 354.3506569862366 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14300 ---------\n",
      "loss : 53.36291469115351\n",
      "accuracy : 0.97\n",
      "time : 356.77535009384155 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14400 ---------\n",
      "loss : 35.608422374611365\n",
      "accuracy : 0.98\n",
      "time : 359.3022530078888 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14500 ---------\n",
      "loss : 44.51074846589509\n",
      "accuracy : 0.978\n",
      "time : 361.7898190021515 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14600 ---------\n",
      "loss : 49.51849262966472\n",
      "accuracy : 0.978\n",
      "time : 364.2038290500641 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14700 ---------\n",
      "loss : 43.03624465027528\n",
      "accuracy : 0.982\n",
      "time : 366.6913650035858 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14800 ---------\n",
      "loss : 62.602507130223806\n",
      "accuracy : 0.968\n",
      "time : 369.13993406295776 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14900 ---------\n",
      "loss : 65.26597503846237\n",
      "accuracy : 0.956\n",
      "time : 371.5794131755829 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15000 ---------\n",
      "loss : 51.470622646590755\n",
      "accuracy : 0.976\n",
      "time : 374.0896511077881 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15100 ---------\n",
      "loss : 60.70061162525616\n",
      "accuracy : 0.976\n",
      "time : 376.5065290927887 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15200 ---------\n",
      "loss : 46.158354371342554\n",
      "accuracy : 0.962\n",
      "time : 378.97811007499695 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15300 ---------\n",
      "loss : 44.44700415843274\n",
      "accuracy : 0.972\n",
      "time : 381.4353771209717 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15400 ---------\n",
      "loss : 41.20846261082579\n",
      "accuracy : 0.984\n",
      "time : 383.8520851135254 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15500 ---------\n",
      "loss : 44.56964397724279\n",
      "accuracy : 0.98\n",
      "time : 386.3290421962738 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15600 ---------\n",
      "loss : 50.64158768746066\n",
      "accuracy : 0.974\n",
      "time : 388.9185080528259 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15700 ---------\n",
      "loss : 36.08558812288599\n",
      "accuracy : 0.984\n",
      "time : 391.4693260192871 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15800 ---------\n",
      "loss : 50.78569674648087\n",
      "accuracy : 0.976\n",
      "time : 393.92642998695374 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15900 ---------\n",
      "loss : 37.09204844596326\n",
      "accuracy : 0.98\n",
      "time : 396.3454079627991 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16000 ---------\n",
      "loss : 35.91495286449833\n",
      "accuracy : 0.98\n",
      "time : 398.8325021266937 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16100 ---------\n",
      "loss : 60.63052104410233\n",
      "accuracy : 0.974\n",
      "time : 401.2685081958771 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16200 ---------\n",
      "loss : 49.56928194178029\n",
      "accuracy : 0.98\n",
      "time : 403.733323097229 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16300 ---------\n",
      "loss : 60.67691257104819\n",
      "accuracy : 0.976\n",
      "time : 406.192538022995 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16400 ---------\n",
      "loss : 56.66663814815679\n",
      "accuracy : 0.972\n",
      "time : 408.6061670780182 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16500 ---------\n",
      "loss : 36.90481354081604\n",
      "accuracy : 0.982\n",
      "time : 411.1096999645233 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16600 ---------\n",
      "loss : 36.965299924011504\n",
      "accuracy : 0.982\n",
      "time : 413.5407681465149 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16700 ---------\n",
      "loss : 56.982565396213644\n",
      "accuracy : 0.974\n",
      "time : 415.9608039855957 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16800 ---------\n",
      "loss : 39.55402837251686\n",
      "accuracy : 0.98\n",
      "time : 418.44416213035583 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16900 ---------\n",
      "loss : 27.967123154898836\n",
      "accuracy : 0.988\n",
      "time : 420.85533905029297 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17000 ---------\n",
      "loss : 42.75081831013691\n",
      "accuracy : 0.98\n",
      "time : 423.43411803245544 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17100 ---------\n",
      "loss : 64.22200755566641\n",
      "accuracy : 0.98\n",
      "time : 426.1143009662628 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17200 ---------\n",
      "loss : 47.69200282617032\n",
      "accuracy : 0.976\n",
      "time : 428.68087911605835 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17300 ---------\n",
      "loss : 46.6488360878036\n",
      "accuracy : 0.978\n",
      "time : 431.1404559612274 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17400 ---------\n",
      "loss : 49.21068801598399\n",
      "accuracy : 0.98\n",
      "time : 433.6655921936035 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17500 ---------\n",
      "loss : 26.263495241248485\n",
      "accuracy : 0.99\n",
      "time : 436.09163308143616 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17600 ---------\n",
      "loss : 38.09456537056418\n",
      "accuracy : 0.982\n",
      "time : 438.60959100723267 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17700 ---------\n",
      "loss : 28.11139218871075\n",
      "accuracy : 0.988\n",
      "time : 441.0627701282501 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17800 ---------\n",
      "loss : 51.223375258669776\n",
      "accuracy : 0.984\n",
      "time : 443.4891240596771 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17900 ---------\n",
      "loss : 45.86291464222229\n",
      "accuracy : 0.984\n",
      "time : 445.97201800346375 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18000 ---------\n",
      "loss : 29.604788915840643\n",
      "accuracy : 0.982\n",
      "time : 448.4008491039276 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18100 ---------\n",
      "loss : 32.52972646624771\n",
      "accuracy : 0.98\n",
      "time : 450.85840702056885 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18200 ---------\n",
      "loss : 60.5423485332431\n",
      "accuracy : 0.972\n",
      "time : 453.33169412612915 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18300 ---------\n",
      "loss : 33.494459122453165\n",
      "accuracy : 0.986\n",
      "time : 455.75317215919495 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch18400 ---------\n",
      "loss : 33.91786055657303\n",
      "accuracy : 0.984\n",
      "time : 458.19793605804443 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18500 ---------\n",
      "loss : 52.66316923898306\n",
      "accuracy : 0.988\n",
      "time : 460.64683198928833 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18600 ---------\n",
      "loss : 46.0293052472568\n",
      "accuracy : 0.986\n",
      "time : 463.06574296951294 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18700 ---------\n",
      "loss : 29.06493928972762\n",
      "accuracy : 0.986\n",
      "time : 465.53796911239624 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18800 ---------\n",
      "loss : 27.97209293134429\n",
      "accuracy : 0.988\n",
      "time : 467.962543964386 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18900 ---------\n",
      "loss : 28.587406464628216\n",
      "accuracy : 0.986\n",
      "time : 470.39058208465576 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19000 ---------\n",
      "loss : 30.184545145892375\n",
      "accuracy : 0.982\n",
      "time : 472.8834819793701 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19100 ---------\n",
      "loss : 29.133806394627356\n",
      "accuracy : 0.992\n",
      "time : 475.2992739677429 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19200 ---------\n",
      "loss : 59.096994413013505\n",
      "accuracy : 0.968\n",
      "time : 477.72462797164917 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19300 ---------\n",
      "loss : 33.43760052614908\n",
      "accuracy : 0.986\n",
      "time : 480.21423506736755 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19400 ---------\n",
      "loss : 24.51013714154619\n",
      "accuracy : 0.988\n",
      "time : 482.6721291542053 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19500 ---------\n",
      "loss : 32.77927381573794\n",
      "accuracy : 0.994\n",
      "time : 485.0808811187744 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19600 ---------\n",
      "loss : 25.04771700923228\n",
      "accuracy : 0.988\n",
      "time : 487.54337310791016 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19700 ---------\n",
      "loss : 26.73123620616942\n",
      "accuracy : 0.986\n",
      "time : 489.97202014923096 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19800 ---------\n",
      "loss : 28.237499855702513\n",
      "accuracy : 0.984\n",
      "time : 492.4996659755707 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19900 ---------\n",
      "loss : 23.383683899578536\n",
      "accuracy : 0.99\n",
      "time : 494.9900631904602 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20000 ---------\n",
      "loss : 20.389675214344916\n",
      "accuracy : 0.994\n",
      "time : 497.4653980731964 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20100 ---------\n",
      "loss : 50.515940815391765\n",
      "accuracy : 0.982\n",
      "time : 499.90482211112976 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20200 ---------\n",
      "loss : 43.67908689228278\n",
      "accuracy : 0.986\n",
      "time : 502.36925506591797 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20300 ---------\n",
      "loss : 24.186559054921037\n",
      "accuracy : 0.992\n",
      "time : 504.9192740917206 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20400 ---------\n",
      "loss : 40.11605738503887\n",
      "accuracy : 0.982\n",
      "time : 507.35102105140686 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20500 ---------\n",
      "loss : 22.603375284500018\n",
      "accuracy : 0.996\n",
      "time : 509.87040305137634 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20600 ---------\n",
      "loss : 30.857573350277285\n",
      "accuracy : 0.988\n",
      "time : 512.3601741790771 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20700 ---------\n",
      "loss : 31.108417707230764\n",
      "accuracy : 0.99\n",
      "time : 514.8131799697876 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20800 ---------\n",
      "loss : 43.81526165137211\n",
      "accuracy : 0.974\n",
      "time : 517.2291650772095 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20900 ---------\n",
      "loss : 25.690297253163443\n",
      "accuracy : 0.988\n",
      "time : 519.6778001785278 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21000 ---------\n",
      "loss : 27.448724555305866\n",
      "accuracy : 0.984\n",
      "time : 522.1283850669861 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21100 ---------\n",
      "loss : 46.69864190458085\n",
      "accuracy : 0.984\n",
      "time : 524.5491931438446 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21200 ---------\n",
      "loss : 25.43241301611544\n",
      "accuracy : 0.988\n",
      "time : 527.0346891880035 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21300 ---------\n",
      "loss : 37.904491177788316\n",
      "accuracy : 0.982\n",
      "time : 529.4946150779724 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21400 ---------\n",
      "loss : 25.637208496907768\n",
      "accuracy : 0.994\n",
      "time : 531.9491000175476 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21500 ---------\n",
      "loss : 12.987898895301516\n",
      "accuracy : 0.998\n",
      "time : 534.5116319656372 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21600 ---------\n",
      "loss : 14.414282063675422\n",
      "accuracy : 1.0\n",
      "time : 536.9654531478882 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21700 ---------\n",
      "loss : 35.22756833602981\n",
      "accuracy : 0.984\n",
      "time : 539.3801970481873 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21800 ---------\n",
      "loss : 21.774905200316006\n",
      "accuracy : 0.994\n",
      "time : 541.8051471710205 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21900 ---------\n",
      "loss : 38.16114066436904\n",
      "accuracy : 0.99\n",
      "time : 544.3460471630096 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22000 ---------\n",
      "loss : 27.576646103397973\n",
      "accuracy : 0.992\n",
      "time : 546.8041679859161 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22100 ---------\n",
      "loss : 21.8593988844096\n",
      "accuracy : 0.99\n",
      "time : 549.2182490825653 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22200 ---------\n",
      "loss : 39.42291942675592\n",
      "accuracy : 0.982\n",
      "time : 551.6624360084534 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22300 ---------\n",
      "loss : 44.4162335624234\n",
      "accuracy : 0.986\n",
      "time : 554.1576001644135 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22400 ---------\n",
      "loss : 14.994566612901638\n",
      "accuracy : 0.994\n",
      "time : 556.6484131813049 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22500 ---------\n",
      "loss : 18.76642160302668\n",
      "accuracy : 0.994\n",
      "time : 559.0642201900482 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22600 ---------\n",
      "loss : 31.282767382420037\n",
      "accuracy : 0.984\n",
      "time : 561.5583341121674 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22700 ---------\n",
      "loss : 35.94095683042379\n",
      "accuracy : 0.984\n",
      "time : 563.9734621047974 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22800 ---------\n",
      "loss : 15.847641250818883\n",
      "accuracy : 0.998\n",
      "time : 566.3824751377106 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22900 ---------\n",
      "loss : 11.747890478710136\n",
      "accuracy : 0.998\n",
      "time : 568.8289849758148 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23000 ---------\n",
      "loss : 13.886228036426196\n",
      "accuracy : 0.998\n",
      "time : 571.2786581516266 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23100 ---------\n",
      "loss : 15.159136488391528\n",
      "accuracy : 0.996\n",
      "time : 573.7208580970764 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23200 ---------\n",
      "loss : 31.676344173474412\n",
      "accuracy : 0.984\n",
      "time : 576.1806411743164 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23300 ---------\n",
      "loss : 21.72976738900558\n",
      "accuracy : 0.992\n",
      "time : 578.643275976181 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23400 ---------\n",
      "loss : 30.655125203229012\n",
      "accuracy : 0.996\n",
      "time : 581.0838961601257 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23500 ---------\n",
      "loss : 31.257170744300325\n",
      "accuracy : 0.99\n",
      "time : 583.508162021637 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23600 ---------\n",
      "loss : 27.244606302472395\n",
      "accuracy : 0.99\n",
      "time : 585.9227910041809 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23700 ---------\n",
      "loss : 22.29516603127106\n",
      "accuracy : 0.99\n",
      "time : 588.3580071926117 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23800 ---------\n",
      "loss : 31.07607858109951\n",
      "accuracy : 0.992\n",
      "time : 590.8227171897888 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23900 ---------\n",
      "loss : 17.217403855626227\n",
      "accuracy : 0.996\n",
      "time : 593.2486071586609 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24000 ---------\n",
      "loss : 21.588038795186236\n",
      "accuracy : 0.992\n",
      "time : 595.6635911464691 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24100 ---------\n",
      "loss : 14.13393186004567\n",
      "accuracy : 0.996\n",
      "time : 598.0939590930939 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24200 ---------\n",
      "loss : 21.524336231898516\n",
      "accuracy : 0.994\n",
      "time : 600.5540080070496 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24300 ---------\n",
      "loss : 11.431604316747663\n",
      "accuracy : 0.998\n",
      "time : 602.978639125824 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24400 ---------\n",
      "loss : 25.599620468084105\n",
      "accuracy : 0.992\n",
      "time : 605.3883721828461 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch24500 ---------\n",
      "loss : 23.88255697031345\n",
      "accuracy : 0.994\n",
      "time : 607.8050711154938 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24600 ---------\n",
      "loss : 39.52255917150735\n",
      "accuracy : 0.99\n",
      "time : 610.2773821353912 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24700 ---------\n",
      "loss : 20.672300946611283\n",
      "accuracy : 0.992\n",
      "time : 612.7349560260773 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24800 ---------\n",
      "loss : 21.67048072693038\n",
      "accuracy : 0.992\n",
      "time : 615.1494491100311 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24900 ---------\n",
      "loss : 21.282597124594872\n",
      "accuracy : 0.996\n",
      "time : 617.567018032074 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25000 ---------\n",
      "loss : 14.902519443916187\n",
      "accuracy : 0.996\n",
      "time : 619.9939801692963 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25100 ---------\n",
      "loss : 15.935960220599336\n",
      "accuracy : 0.994\n",
      "time : 622.4792029857635 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25200 ---------\n",
      "loss : 18.151706891634888\n",
      "accuracy : 0.994\n",
      "time : 624.8878359794617 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25300 ---------\n",
      "loss : 24.14105241633454\n",
      "accuracy : 0.994\n",
      "time : 627.3080701828003 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25400 ---------\n",
      "loss : 13.388752614431933\n",
      "accuracy : 0.994\n",
      "time : 629.8581941127777 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25500 ---------\n",
      "loss : 14.030487167360892\n",
      "accuracy : 0.998\n",
      "time : 632.3427741527557 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25600 ---------\n",
      "loss : 25.808351963057405\n",
      "accuracy : 0.99\n",
      "time : 634.7671000957489 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25700 ---------\n",
      "loss : 11.646707468328973\n",
      "accuracy : 1.0\n",
      "time : 637.1967971324921 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25800 ---------\n",
      "loss : 14.539231907653498\n",
      "accuracy : 0.996\n",
      "time : 639.6355080604553 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25900 ---------\n",
      "loss : 14.046089579240078\n",
      "accuracy : 0.994\n",
      "time : 642.0748670101166 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26000 ---------\n",
      "loss : 20.593755251843643\n",
      "accuracy : 0.994\n",
      "time : 644.5606369972229 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26100 ---------\n",
      "loss : 13.048198037847431\n",
      "accuracy : 1.0\n",
      "time : 646.9701759815216 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26200 ---------\n",
      "loss : 20.13172332542296\n",
      "accuracy : 0.996\n",
      "time : 649.4467220306396 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26300 ---------\n",
      "loss : 25.87066467555372\n",
      "accuracy : 0.996\n",
      "time : 651.9384481906891 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26400 ---------\n",
      "loss : 17.323907570443787\n",
      "accuracy : 0.992\n",
      "time : 654.3840751647949 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26500 ---------\n",
      "loss : 20.972654675142827\n",
      "accuracy : 0.994\n",
      "time : 656.797285079956 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26600 ---------\n",
      "loss : 16.604052707358548\n",
      "accuracy : 0.994\n",
      "time : 659.2125761508942 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26700 ---------\n",
      "loss : 17.01552073812652\n",
      "accuracy : 0.994\n",
      "time : 661.6951220035553 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26800 ---------\n",
      "loss : 20.336677561468463\n",
      "accuracy : 0.998\n",
      "time : 664.124792098999 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26900 ---------\n",
      "loss : 12.496746621884947\n",
      "accuracy : 0.996\n",
      "time : 666.5348861217499 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27000 ---------\n",
      "loss : 12.346406821259226\n",
      "accuracy : 0.996\n",
      "time : 668.9534041881561 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27100 ---------\n",
      "loss : 18.630337873583358\n",
      "accuracy : 0.994\n",
      "time : 671.4281690120697 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27200 ---------\n",
      "loss : 11.840919893449843\n",
      "accuracy : 1.0\n",
      "time : 673.8688840866089 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27300 ---------\n",
      "loss : 13.805884559088726\n",
      "accuracy : 0.994\n",
      "time : 676.2788960933685 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27400 ---------\n",
      "loss : 14.711874988548397\n",
      "accuracy : 0.996\n",
      "time : 678.6910820007324 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27500 ---------\n",
      "loss : 19.421837025911856\n",
      "accuracy : 0.996\n",
      "time : 681.1748521327972 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27600 ---------\n",
      "loss : 13.173402288607798\n",
      "accuracy : 0.994\n",
      "time : 683.6004490852356 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27700 ---------\n",
      "loss : 14.451026097387423\n",
      "accuracy : 0.998\n",
      "time : 686.0107309818268 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27800 ---------\n",
      "loss : 47.75806840202114\n",
      "accuracy : 0.988\n",
      "time : 688.4627420902252 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27900 ---------\n",
      "loss : 7.90027557176148\n",
      "accuracy : 1.0\n",
      "time : 690.8802950382233 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28000 ---------\n",
      "loss : 19.95387250318953\n",
      "accuracy : 0.996\n",
      "time : 693.3560330867767 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28100 ---------\n",
      "loss : 16.508172935134784\n",
      "accuracy : 0.994\n",
      "time : 695.8312630653381 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28200 ---------\n",
      "loss : 16.170964761931373\n",
      "accuracy : 0.998\n",
      "time : 698.3046181201935 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28300 ---------\n",
      "loss : 9.197230520633132\n",
      "accuracy : 0.998\n",
      "time : 700.7227590084076 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28400 ---------\n",
      "loss : 16.617660896069903\n",
      "accuracy : 0.994\n",
      "time : 703.1396980285645 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28500 ---------\n",
      "loss : 11.469952601091517\n",
      "accuracy : 1.0\n",
      "time : 705.6009330749512 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28600 ---------\n",
      "loss : 12.368222724594467\n",
      "accuracy : 0.996\n",
      "time : 708.0440511703491 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28700 ---------\n",
      "loss : 13.417564203112985\n",
      "accuracy : 0.998\n",
      "time : 710.4999120235443 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28800 ---------\n",
      "loss : 10.83856965788999\n",
      "accuracy : 0.998\n",
      "time : 712.9184710979462 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28900 ---------\n",
      "loss : 11.864386865827946\n",
      "accuracy : 0.996\n",
      "time : 715.3270461559296 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29000 ---------\n",
      "loss : 11.64954413533694\n",
      "accuracy : 0.998\n",
      "time : 717.7454221248627 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29100 ---------\n",
      "loss : 18.340683310033945\n",
      "accuracy : 0.994\n",
      "time : 720.2098500728607 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29200 ---------\n",
      "loss : 10.706953943158325\n",
      "accuracy : 0.998\n",
      "time : 722.6457810401917 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29300 ---------\n",
      "loss : 13.244488946416599\n",
      "accuracy : 0.998\n",
      "time : 725.0541870594025 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29400 ---------\n",
      "loss : 9.150838901413032\n",
      "accuracy : 0.998\n",
      "time : 727.575756072998 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29500 ---------\n",
      "loss : 13.905197100228914\n",
      "accuracy : 0.996\n",
      "time : 730.0747811794281 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29600 ---------\n",
      "loss : 15.374662821795475\n",
      "accuracy : 0.996\n",
      "time : 732.5127191543579 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29700 ---------\n",
      "loss : 15.906871550102295\n",
      "accuracy : 0.992\n",
      "time : 734.9992160797119 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29800 ---------\n",
      "loss : 13.39114880910477\n",
      "accuracy : 0.996\n",
      "time : 737.4844481945038 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29900 ---------\n",
      "loss : 9.975857792158523\n",
      "accuracy : 0.996\n",
      "time : 740.1534340381622 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30000 ---------\n",
      "loss : 10.05139561144571\n",
      "accuracy : 1.0\n",
      "time : 742.8479390144348 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30100 ---------\n",
      "loss : 7.018230384914595\n",
      "accuracy : 1.0\n",
      "time : 745.5944941043854 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30200 ---------\n",
      "loss : 21.995003808154916\n",
      "accuracy : 0.996\n",
      "time : 748.3841230869293 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30300 ---------\n",
      "loss : 14.836219673257382\n",
      "accuracy : 0.996\n",
      "time : 751.145966053009 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30400 ---------\n",
      "loss : 14.741518407771007\n",
      "accuracy : 0.994\n",
      "time : 753.6092441082001 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30500 ---------\n",
      "loss : 13.660879941132263\n",
      "accuracy : 0.998\n",
      "time : 756.036082983017 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch30600 ---------\n",
      "loss : 18.194283520080063\n",
      "accuracy : 0.996\n",
      "time : 758.4512009620667 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30700 ---------\n",
      "loss : 10.802272577468385\n",
      "accuracy : 0.998\n",
      "time : 760.9331049919128 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30800 ---------\n",
      "loss : 6.568191704396796\n",
      "accuracy : 1.0\n",
      "time : 763.3487989902496 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30900 ---------\n",
      "loss : 12.637787654545791\n",
      "accuracy : 0.994\n",
      "time : 765.7629721164703 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31000 ---------\n",
      "loss : 8.131817194871891\n",
      "accuracy : 0.998\n",
      "time : 768.2303960323334 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31100 ---------\n",
      "loss : 6.365817397263346\n",
      "accuracy : 1.0\n",
      "time : 770.7046830654144 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31200 ---------\n",
      "loss : 16.19428289298387\n",
      "accuracy : 0.994\n",
      "time : 773.122435092926 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31300 ---------\n",
      "loss : 9.514738728132535\n",
      "accuracy : 0.998\n",
      "time : 775.6039049625397 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31400 ---------\n",
      "loss : 9.434962200767494\n",
      "accuracy : 0.998\n",
      "time : 778.0341420173645 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31500 ---------\n",
      "loss : 7.0080863560407565\n",
      "accuracy : 1.0\n",
      "time : 780.4682111740112 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31600 ---------\n",
      "loss : 12.908176333637561\n",
      "accuracy : 0.998\n",
      "time : 782.9392240047455 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31700 ---------\n",
      "loss : 6.321550523416322\n",
      "accuracy : 1.0\n",
      "time : 785.388099193573 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31800 ---------\n",
      "loss : 7.954276975605553\n",
      "accuracy : 0.998\n",
      "time : 787.809319972992 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31900 ---------\n",
      "loss : 7.972600110882189\n",
      "accuracy : 1.0\n",
      "time : 790.2378461360931 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32000 ---------\n",
      "loss : 20.179768822864297\n",
      "accuracy : 0.994\n",
      "time : 792.982136964798 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32100 ---------\n",
      "loss : 6.7042520797871274\n",
      "accuracy : 1.0\n",
      "time : 795.4151639938354 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32200 ---------\n",
      "loss : 17.835715516017768\n",
      "accuracy : 0.994\n",
      "time : 797.8535940647125 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32300 ---------\n",
      "loss : 7.481027545593604\n",
      "accuracy : 1.0\n",
      "time : 800.3278670310974 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32400 ---------\n",
      "loss : 8.118912112543047\n",
      "accuracy : 0.998\n",
      "time : 802.7481091022491 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32500 ---------\n",
      "loss : 8.31291120341838\n",
      "accuracy : 0.998\n",
      "time : 805.1627149581909 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32600 ---------\n",
      "loss : 6.846328265563915\n",
      "accuracy : 1.0\n",
      "time : 807.6324670314789 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32700 ---------\n",
      "loss : 16.188857372674143\n",
      "accuracy : 0.998\n",
      "time : 810.0577981472015 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32800 ---------\n",
      "loss : 11.500247052108522\n",
      "accuracy : 0.998\n",
      "time : 812.4739620685577 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32900 ---------\n",
      "loss : 9.658975272796027\n",
      "accuracy : 0.998\n",
      "time : 814.8934180736542 [sec]\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "<< All training epochs ended. >>\n",
      "========= result =========\n",
      "Elapsed time : 817.3679661750793 [sec]\n",
      "Train set accuracy : 0.9976666666666667\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "elapsed_time,train_acc = net.train(x_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< successfully layers are updated >>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural.neuralNetwork at 0x7fc9e6c06860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralNetwork.SETTINGS['activation']['output'] = 'softmax'\n",
    "net = neuralNetwork(\n",
    "    epoch = 33000,\n",
    "    learning_rate = 0.01,\n",
    "    batch_size = 500,\n",
    "    loss_func = 'cross_entropy'\n",
    ")\n",
    "layer_list = [784,[500,80],10]\n",
    "net.set_layer(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.9976666666666667\n",
      "test accuracy : 0.8964\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy : {}\\ntest accuracy : {}'.format(\n",
    "    net.accuracy(x_train,t_train),net.accuracy(x_test,t_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfdf8b0ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully network was constructed!\n"
     ]
    }
   ],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net = neuralNetwork.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.326\n",
      "epoch : 101, loss : 0.0313\n",
      "epoch : 201, loss : 0.024\n",
      "epoch : 301, loss : 0.0174\n",
      "epoch : 401, loss : 0.0159\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device('cpu')\n",
    "model = MLP(784,400,50,10).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(y,t)\n",
    "\n",
    "def train_step(x,t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    #print(preds.shape)\n",
    "    loss = compute_loss(t,preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 500\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    batch = np.random.choice(x_train.shape[0],batch_size)\n",
    "    x_ = x_train[batch]\n",
    "    t_ = t_train[batch]\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    t_ = torch.Tensor(t_).to(device)\n",
    "    \n",
    "    loss = train_step(x_,t_)\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        \n",
    "        print('epoch : {}, loss : {:.3}'.format(\n",
    "            epoch + 1,\n",
    "            train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc : 0.979, test_acc : 0.893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_step(x,t):\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t,preds)\n",
    "    return loss,preds\n",
    "\n",
    "test_loss,test_preds = test_step(x_test,t_test)\n",
    "train_loss,train_preds = test_step(x_train,t_train)\n",
    "test_loss = test_loss.item()\n",
    "train_loss = train_loss.item()\n",
    "test_preds = np.argmax(test_preds.data.cpu().numpy(),axis=1)\n",
    "train_preds = np.argmax(train_preds.data.cpu().numpy(),axis=1)\n",
    "test_ans = np.argmax(t_test,axis=1)\n",
    "test_acc = accuracy_score(test_ans,test_preds)\n",
    "train_ans = np.argmax(t_train,axis=1)\n",
    "train_acc = accuracy_score(train_ans,train_preds)\n",
    "\n",
    "print('train_acc : {:.3f}, test_acc : {:.3f}'.format(\n",
    "    train_acc,\n",
    "    test_acc\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1208e-04, 5.7649e-04, 1.5671e-03, 4.2597e-03, 1.1579e-02, 3.1475e-02,\n",
       "         8.5559e-02, 2.3257e-01, 6.3220e-01]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7,8,9]])\n",
    "a = torch.Tensor(a).to(device)\n",
    "l = nn.Softmax(dim = 1)\n",
    "l(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,train = True):\n",
    "        x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "        t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "        x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "        t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "        t_train = np.identity(10)[t_train]\n",
    "        t_test = np.identity(10)[t_test]\n",
    "        x_train = x_train.reshape((60000,-1)).astype(float)\n",
    "        x_test = x_test.reshape((10000,-1)).astype(float)\n",
    "        x_train = x_train/255\n",
    "        x_test = x_test/255\n",
    "        if train:\n",
    "            #self.x = torch.from_numpy(x_train).float\n",
    "            #self.t = torch.from_numpy(t_train).long\n",
    "            self.x = x_train\n",
    "            self.t = t_train\n",
    "            self.size = x_train.shape[0]\n",
    "        else:\n",
    "            #self.x = torch.from_numpy(x_test).float\n",
    "            #self.t = torch.from_numpy(t_test).long\n",
    "            self.x = x_test\n",
    "            self.t = t_test\n",
    "            self.size = x_test.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kuzushijiMNIST(batch_size = 500):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(True),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(False),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train' : train_loader,\n",
    "        'test' : test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "history = {\n",
    "    'train_loss' : [],\n",
    "    'test_loss' : [],\n",
    "    'test_acc' : []\n",
    "}\n",
    "\n",
    "net = Net(784,400,40,10)\n",
    "loaders = load_kuzushijiMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0157, 0.7804, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0471, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0039, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4824, 0.4000, 0.1255],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4549,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9412, 0.0941, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7569, 0.1451, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5216, 0.5412, 0.0353]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6824, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0980, 0.2627,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0431, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.6118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9843, 0.3020, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0353,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0784, 0.1765, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.1490,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0588, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.5804, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.8941, 0.3490, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9529, 0.3098, 0.0039],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2902, 0.0784, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0314, 0.1922],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3216, 0.1451, 0.0196],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.2706,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3843, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4235, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0627, 0.3137, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1216, 0.8824, 0.1765,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.2314, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6118, 0.9843, 0.6118,  ..., 0.4824, 0.0078, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data,target in loaders['train']:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(params = net.parameters(),lr = 0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1,batch : 128/60000,loss : 0.32562965154647827\n",
      "epoch : 1,batch : 1408/60000,loss : 0.15830664336681366\n",
      "epoch : 1,batch : 2688/60000,loss : 0.10345988720655441\n",
      "epoch : 1,batch : 3968/60000,loss : 0.07579276710748672\n",
      "epoch : 1,batch : 5248/60000,loss : 0.07180974632501602\n",
      "epoch : 1,batch : 6528/60000,loss : 0.07020606100559235\n",
      "epoch : 1,batch : 7808/60000,loss : 0.060317933559417725\n",
      "epoch : 1,batch : 9088/60000,loss : 0.05069664120674133\n",
      "epoch : 1,batch : 10368/60000,loss : 0.05856812745332718\n",
      "epoch : 1,batch : 11648/60000,loss : 0.04413367435336113\n",
      "epoch : 1,batch : 12928/60000,loss : 0.039065614342689514\n",
      "epoch : 1,batch : 14208/60000,loss : 0.047319211065769196\n",
      "test accuracy : 0.8411\n",
      "epoch : 2,batch : 128/60000,loss : 0.03204628825187683\n",
      "epoch : 2,batch : 1408/60000,loss : 0.025458727031946182\n",
      "epoch : 2,batch : 2688/60000,loss : 0.03425682336091995\n",
      "epoch : 2,batch : 3968/60000,loss : 0.028589818626642227\n",
      "epoch : 2,batch : 5248/60000,loss : 0.02421424724161625\n",
      "epoch : 2,batch : 6528/60000,loss : 0.02936953492462635\n",
      "epoch : 2,batch : 7808/60000,loss : 0.023337045684456825\n",
      "epoch : 2,batch : 9088/60000,loss : 0.030201995745301247\n",
      "epoch : 2,batch : 10368/60000,loss : 0.03466672822833061\n",
      "epoch : 2,batch : 11648/60000,loss : 0.023305097594857216\n",
      "epoch : 2,batch : 12928/60000,loss : 0.026867486536502838\n",
      "epoch : 2,batch : 14208/60000,loss : 0.03513367101550102\n",
      "test accuracy : 0.8708\n",
      "epoch : 3,batch : 128/60000,loss : 0.02319392003118992\n",
      "epoch : 3,batch : 1408/60000,loss : 0.01709127239882946\n",
      "epoch : 3,batch : 2688/60000,loss : 0.018111469224095345\n",
      "epoch : 3,batch : 3968/60000,loss : 0.014557821676135063\n",
      "epoch : 3,batch : 5248/60000,loss : 0.01512590330094099\n",
      "epoch : 3,batch : 6528/60000,loss : 0.017109690234065056\n",
      "epoch : 3,batch : 7808/60000,loss : 0.017189402133226395\n",
      "epoch : 3,batch : 9088/60000,loss : 0.019132234156131744\n",
      "epoch : 3,batch : 10368/60000,loss : 0.020565830171108246\n",
      "epoch : 3,batch : 11648/60000,loss : 0.018769145011901855\n",
      "epoch : 3,batch : 12928/60000,loss : 0.01944355107843876\n",
      "epoch : 3,batch : 14208/60000,loss : 0.01974104717373848\n",
      "test accuracy : 0.8862\n",
      "epoch : 4,batch : 128/60000,loss : 0.011614253744482994\n",
      "epoch : 4,batch : 1408/60000,loss : 0.012034856714308262\n",
      "epoch : 4,batch : 2688/60000,loss : 0.009736406616866589\n",
      "epoch : 4,batch : 3968/60000,loss : 0.021139031276106834\n",
      "epoch : 4,batch : 5248/60000,loss : 0.015447190962731838\n",
      "epoch : 4,batch : 6528/60000,loss : 0.013809082098305225\n",
      "epoch : 4,batch : 7808/60000,loss : 0.010202538222074509\n",
      "epoch : 4,batch : 9088/60000,loss : 0.013362913392484188\n",
      "epoch : 4,batch : 10368/60000,loss : 0.026109125465154648\n",
      "epoch : 4,batch : 11648/60000,loss : 0.011653976514935493\n",
      "epoch : 4,batch : 12928/60000,loss : 0.020759090781211853\n",
      "epoch : 4,batch : 14208/60000,loss : 0.016076456755399704\n",
      "test accuracy : 0.8965\n",
      "epoch : 5,batch : 128/60000,loss : 0.012907855212688446\n",
      "epoch : 5,batch : 1408/60000,loss : 0.01028241217136383\n",
      "epoch : 5,batch : 2688/60000,loss : 0.011401785537600517\n",
      "epoch : 5,batch : 3968/60000,loss : 0.013149754144251347\n",
      "epoch : 5,batch : 5248/60000,loss : 0.014900248497724533\n",
      "epoch : 5,batch : 6528/60000,loss : 0.010914977639913559\n",
      "epoch : 5,batch : 7808/60000,loss : 0.013847623020410538\n",
      "epoch : 5,batch : 9088/60000,loss : 0.014637126587331295\n",
      "epoch : 5,batch : 10368/60000,loss : 0.01335443090647459\n",
      "epoch : 5,batch : 11648/60000,loss : 0.014864697121083736\n",
      "epoch : 5,batch : 12928/60000,loss : 0.01892690733075142\n",
      "epoch : 5,batch : 14208/60000,loss : 0.020673399791121483\n",
      "test accuracy : 0.8996\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    loss = None\n",
    "    net.train()\n",
    "    \n",
    "    for j ,(data,target) in enumerate(loaders['train']):\n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        #print('flag')\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 10 == 0:\n",
    "            print('epoch : {},batch : {}/60000,loss : {}'.format(\n",
    "                i+1,\n",
    "                (j+1)*128,\n",
    "                loss.item()\n",
    "            ))\n",
    "    history['train_loss'].append(loss)\n",
    "    \n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in loaders['test']:\n",
    "            data = data.float()\n",
    "            target = target.float()\n",
    "            output = net(data)\n",
    "            test_loss += criterion(output,target).item()\n",
    "            pred = output.argmax(dim=1,keepdim = False)\n",
    "            ans = target.argmax(dim = 1,keepdim=False)\n",
    "            correct += (pred == ans).sum().item()\n",
    "    test_loss /= 10000\n",
    "    \n",
    "    print('test accuracy : {}'.format(correct/10000))\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(correct/10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
