{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# くずし字 MNIST データセットの学習\n",
    "[github](https://github.com/rois-codh/kmnist)からダウンロードしたくずし字データセットを今回作成したニューラルネットワークのクラスneuralNetworkを用いて学習させ、その精度を求めた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural import neuralNetwork #自作ライブラリ\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "t_train = np.identity(10)[t_train]\n",
    "t_test = np.identity(10)[t_test]\n",
    "x_train = x_train.reshape((60000,-1))\n",
    "x_test = x_test.reshape((10000,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<< successfully layers are updated >>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural.neuralNetwork at 0x7fb50821cac8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = neuralNetwork(\n",
    "    epoch = 33000,\n",
    "    learning_rate = 0.05,\n",
    "    batch_size = 500\n",
    ")\n",
    "layer_list = [784,[500,80],10]\n",
    "net.set_layer(layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch0 ---------\n",
      "loss : 670.1247074688224\n",
      "accuracy : 0.086\n",
      "time : 0.05405402183532715 [sec]\n",
      "--------------------------\n",
      "\n",
      "--------- epoch100 ---------\n",
      "loss : 222.03280341631665\n",
      "accuracy : 0.268\n",
      "time : 2.7167701721191406 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch200 ---------\n",
      "loss : 212.96258699978046\n",
      "accuracy : 0.36\n",
      "time : 5.509479999542236 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch300 ---------\n",
      "loss : 196.69352657717843\n",
      "accuracy : 0.544\n",
      "time : 7.932871103286743 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch400 ---------\n",
      "loss : 176.80351092850782\n",
      "accuracy : 0.642\n",
      "time : 10.386381149291992 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch500 ---------\n",
      "loss : 151.7850906035798\n",
      "accuracy : 0.684\n",
      "time : 12.805037021636963 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch600 ---------\n",
      "loss : 139.43057859882754\n",
      "accuracy : 0.706\n",
      "time : 15.307155132293701 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch700 ---------\n",
      "loss : 126.86368275003767\n",
      "accuracy : 0.722\n",
      "time : 17.77483296394348 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch800 ---------\n",
      "loss : 108.28523179044745\n",
      "accuracy : 0.748\n",
      "time : 20.511389017105103 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch900 ---------\n",
      "loss : 103.21767845250679\n",
      "accuracy : 0.76\n",
      "time : 22.999858140945435 [sec]\n",
      "----------------------------\n",
      "\n",
      "--------- epoch1000 ---------\n",
      "loss : 105.24842700341472\n",
      "accuracy : 0.74\n",
      "time : 25.505701065063477 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1100 ---------\n",
      "loss : 92.1569592174985\n",
      "accuracy : 0.778\n",
      "time : 27.930071115493774 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1200 ---------\n",
      "loss : 95.49406589756133\n",
      "accuracy : 0.764\n",
      "time : 30.346194982528687 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1300 ---------\n",
      "loss : 87.71148978844667\n",
      "accuracy : 0.77\n",
      "time : 32.69483399391174 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1400 ---------\n",
      "loss : 85.53001088703174\n",
      "accuracy : 0.796\n",
      "time : 35.01625418663025 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1500 ---------\n",
      "loss : 83.62218347829844\n",
      "accuracy : 0.79\n",
      "time : 37.3482391834259 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1600 ---------\n",
      "loss : 79.79483520946795\n",
      "accuracy : 0.794\n",
      "time : 40.44726300239563 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1700 ---------\n",
      "loss : 82.39305160311847\n",
      "accuracy : 0.8\n",
      "time : 43.011924028396606 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1800 ---------\n",
      "loss : 83.62313280549539\n",
      "accuracy : 0.782\n",
      "time : 45.5560200214386 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch1900 ---------\n",
      "loss : 86.65080391990283\n",
      "accuracy : 0.776\n",
      "time : 47.87758803367615 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2000 ---------\n",
      "loss : 77.31324348981856\n",
      "accuracy : 0.786\n",
      "time : 50.22566103935242 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2100 ---------\n",
      "loss : 75.19223670315264\n",
      "accuracy : 0.818\n",
      "time : 52.57120108604431 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2200 ---------\n",
      "loss : 73.60563886925065\n",
      "accuracy : 0.82\n",
      "time : 54.95013403892517 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2300 ---------\n",
      "loss : 68.09473867090438\n",
      "accuracy : 0.822\n",
      "time : 57.39567518234253 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2400 ---------\n",
      "loss : 68.95352766312611\n",
      "accuracy : 0.816\n",
      "time : 65.90260410308838 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2500 ---------\n",
      "loss : 70.73849115583764\n",
      "accuracy : 0.82\n",
      "time : 71.68589305877686 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2600 ---------\n",
      "loss : 75.87799830455158\n",
      "accuracy : 0.816\n",
      "time : 76.86384916305542 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2700 ---------\n",
      "loss : 70.5195918659029\n",
      "accuracy : 0.814\n",
      "time : 84.04144215583801 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2800 ---------\n",
      "loss : 78.85410450603935\n",
      "accuracy : 0.778\n",
      "time : 88.57112717628479 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch2900 ---------\n",
      "loss : 70.60771113494349\n",
      "accuracy : 0.804\n",
      "time : 92.94933199882507 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3000 ---------\n",
      "loss : 68.39180473410404\n",
      "accuracy : 0.834\n",
      "time : 96.36055707931519 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3100 ---------\n",
      "loss : 66.581081929976\n",
      "accuracy : 0.834\n",
      "time : 99.6782820224762 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3200 ---------\n",
      "loss : 62.35850325061075\n",
      "accuracy : 0.85\n",
      "time : 103.54270315170288 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3300 ---------\n",
      "loss : 61.33690789265924\n",
      "accuracy : 0.858\n",
      "time : 107.03165602684021 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3400 ---------\n",
      "loss : 60.1512415604225\n",
      "accuracy : 0.854\n",
      "time : 110.44759011268616 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3500 ---------\n",
      "loss : 64.48384860438608\n",
      "accuracy : 0.842\n",
      "time : 113.88028812408447 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3600 ---------\n",
      "loss : 66.68033407115185\n",
      "accuracy : 0.828\n",
      "time : 117.36241507530212 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3700 ---------\n",
      "loss : 56.80430061734172\n",
      "accuracy : 0.866\n",
      "time : 121.2268180847168 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3800 ---------\n",
      "loss : 59.43798867373252\n",
      "accuracy : 0.862\n",
      "time : 124.64273309707642 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch3900 ---------\n",
      "loss : 59.4891950209853\n",
      "accuracy : 0.848\n",
      "time : 128.0692331790924 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4000 ---------\n",
      "loss : 59.358434778599\n",
      "accuracy : 0.86\n",
      "time : 131.36417603492737 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4100 ---------\n",
      "loss : 54.98921866802802\n",
      "accuracy : 0.858\n",
      "time : 135.14074206352234 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4200 ---------\n",
      "loss : 50.28431920944812\n",
      "accuracy : 0.888\n",
      "time : 138.86514115333557 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4300 ---------\n",
      "loss : 55.525922958414995\n",
      "accuracy : 0.854\n",
      "time : 142.40810108184814 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4400 ---------\n",
      "loss : 57.217578537813964\n",
      "accuracy : 0.86\n",
      "time : 145.8361620903015 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4500 ---------\n",
      "loss : 53.45631438921541\n",
      "accuracy : 0.858\n",
      "time : 149.77193307876587 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4600 ---------\n",
      "loss : 55.503866920716476\n",
      "accuracy : 0.866\n",
      "time : 153.46115803718567 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4700 ---------\n",
      "loss : 49.860044494462045\n",
      "accuracy : 0.886\n",
      "time : 156.73551511764526 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4800 ---------\n",
      "loss : 53.786184361791\n",
      "accuracy : 0.856\n",
      "time : 160.07441401481628 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch4900 ---------\n",
      "loss : 56.10557908485731\n",
      "accuracy : 0.848\n",
      "time : 163.32076406478882 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5000 ---------\n",
      "loss : 48.624877830341546\n",
      "accuracy : 0.89\n",
      "time : 167.1128180027008 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5100 ---------\n",
      "loss : 55.1376356280226\n",
      "accuracy : 0.85\n",
      "time : 170.48649406433105 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5200 ---------\n",
      "loss : 48.79204611688215\n",
      "accuracy : 0.89\n",
      "time : 173.96206212043762 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5300 ---------\n",
      "loss : 44.81154285464312\n",
      "accuracy : 0.884\n",
      "time : 177.54055500030518 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5400 ---------\n",
      "loss : 45.51143337911438\n",
      "accuracy : 0.892\n",
      "time : 180.95429801940918 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5500 ---------\n",
      "loss : 55.556674285842846\n",
      "accuracy : 0.854\n",
      "time : 184.33646512031555 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5600 ---------\n",
      "loss : 49.7455892501594\n",
      "accuracy : 0.89\n",
      "time : 187.61932611465454 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5700 ---------\n",
      "loss : 52.447753227462364\n",
      "accuracy : 0.868\n",
      "time : 191.24027109146118 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5800 ---------\n",
      "loss : 44.68657542960065\n",
      "accuracy : 0.886\n",
      "time : 194.66189098358154 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch5900 ---------\n",
      "loss : 53.72080884555535\n",
      "accuracy : 0.86\n",
      "time : 198.40104508399963 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6000 ---------\n",
      "loss : 48.77953664464806\n",
      "accuracy : 0.886\n",
      "time : 201.83238816261292 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6100 ---------\n",
      "loss : 50.148761979190425\n",
      "accuracy : 0.876\n",
      "time : 205.28564500808716 [sec]\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch6200 ---------\n",
      "loss : 44.98289250182699\n",
      "accuracy : 0.884\n",
      "time : 208.99479508399963 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6300 ---------\n",
      "loss : 46.14712477504404\n",
      "accuracy : 0.88\n",
      "time : 212.9601411819458 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6400 ---------\n",
      "loss : 46.57528234567499\n",
      "accuracy : 0.89\n",
      "time : 216.393128156662 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6500 ---------\n",
      "loss : 41.612387463507275\n",
      "accuracy : 0.91\n",
      "time : 219.7502281665802 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6600 ---------\n",
      "loss : 45.74052509138288\n",
      "accuracy : 0.898\n",
      "time : 223.09082198143005 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6700 ---------\n",
      "loss : 46.39137803086649\n",
      "accuracy : 0.894\n",
      "time : 226.51594305038452 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6800 ---------\n",
      "loss : 43.9383948051084\n",
      "accuracy : 0.894\n",
      "time : 230.54314613342285 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch6900 ---------\n",
      "loss : 39.2353632304047\n",
      "accuracy : 0.908\n",
      "time : 234.00888395309448 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7000 ---------\n",
      "loss : 47.88408539064397\n",
      "accuracy : 0.868\n",
      "time : 237.49934101104736 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7100 ---------\n",
      "loss : 41.50213782792011\n",
      "accuracy : 0.888\n",
      "time : 240.94940495491028 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7200 ---------\n",
      "loss : 49.450253276554506\n",
      "accuracy : 0.864\n",
      "time : 244.32948303222656 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7300 ---------\n",
      "loss : 42.74565576684681\n",
      "accuracy : 0.89\n",
      "time : 247.6857500076294 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7400 ---------\n",
      "loss : 44.944897598684456\n",
      "accuracy : 0.89\n",
      "time : 251.57768607139587 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7500 ---------\n",
      "loss : 40.241821546012986\n",
      "accuracy : 0.912\n",
      "time : 255.23198199272156 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7600 ---------\n",
      "loss : 40.09811828675071\n",
      "accuracy : 0.91\n",
      "time : 258.88282918930054 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7700 ---------\n",
      "loss : 45.075132434716764\n",
      "accuracy : 0.882\n",
      "time : 262.67656207084656 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7800 ---------\n",
      "loss : 39.13565320384404\n",
      "accuracy : 0.91\n",
      "time : 266.0825080871582 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch7900 ---------\n",
      "loss : 40.02946042648537\n",
      "accuracy : 0.896\n",
      "time : 269.4640271663666 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8000 ---------\n",
      "loss : 42.99472036068823\n",
      "accuracy : 0.902\n",
      "time : 272.8455710411072 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8100 ---------\n",
      "loss : 39.13764465364207\n",
      "accuracy : 0.902\n",
      "time : 276.2637801170349 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8200 ---------\n",
      "loss : 37.95433356989497\n",
      "accuracy : 0.918\n",
      "time : 279.61065196990967 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8300 ---------\n",
      "loss : 43.186746241222124\n",
      "accuracy : 0.888\n",
      "time : 285.66232204437256 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8400 ---------\n",
      "loss : 45.810565116569435\n",
      "accuracy : 0.888\n",
      "time : 291.24469804763794 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8500 ---------\n",
      "loss : 47.75821806853726\n",
      "accuracy : 0.88\n",
      "time : 299.311026096344 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8600 ---------\n",
      "loss : 49.50086287957941\n",
      "accuracy : 0.882\n",
      "time : 302.76108503341675 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8700 ---------\n",
      "loss : 40.63596677786983\n",
      "accuracy : 0.906\n",
      "time : 306.3506290912628 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8800 ---------\n",
      "loss : 37.76324096965325\n",
      "accuracy : 0.91\n",
      "time : 310.1164300441742 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch8900 ---------\n",
      "loss : 39.64090505688547\n",
      "accuracy : 0.914\n",
      "time : 313.6395971775055 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9000 ---------\n",
      "loss : 40.29724686174892\n",
      "accuracy : 0.912\n",
      "time : 317.1134111881256 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9100 ---------\n",
      "loss : 34.8135788037403\n",
      "accuracy : 0.926\n",
      "time : 320.4448051452637 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9200 ---------\n",
      "loss : 46.58724099281876\n",
      "accuracy : 0.88\n",
      "time : 324.394406080246 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9300 ---------\n",
      "loss : 37.81939434796746\n",
      "accuracy : 0.91\n",
      "time : 328.0011351108551 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9400 ---------\n",
      "loss : 42.888636455641816\n",
      "accuracy : 0.902\n",
      "time : 331.7389860153198 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9500 ---------\n",
      "loss : 35.63144939338402\n",
      "accuracy : 0.918\n",
      "time : 335.62505316734314 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9600 ---------\n",
      "loss : 38.1500082418508\n",
      "accuracy : 0.916\n",
      "time : 339.05864000320435 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9700 ---------\n",
      "loss : 29.238523324877903\n",
      "accuracy : 0.936\n",
      "time : 342.7100820541382 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9800 ---------\n",
      "loss : 33.80506303211243\n",
      "accuracy : 0.924\n",
      "time : 347.6821930408478 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch9900 ---------\n",
      "loss : 39.73553188567156\n",
      "accuracy : 0.912\n",
      "time : 351.82112097740173 [sec]\n",
      "-----------------------------\n",
      "\n",
      "--------- epoch10000 ---------\n",
      "loss : 36.75189627611001\n",
      "accuracy : 0.916\n",
      "time : 356.48698711395264 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10100 ---------\n",
      "loss : 37.18706546835174\n",
      "accuracy : 0.91\n",
      "time : 360.14543318748474 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10200 ---------\n",
      "loss : 31.917169284765553\n",
      "accuracy : 0.932\n",
      "time : 363.59864115715027 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10300 ---------\n",
      "loss : 41.16456804836779\n",
      "accuracy : 0.902\n",
      "time : 367.5530230998993 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10400 ---------\n",
      "loss : 33.80992328746157\n",
      "accuracy : 0.92\n",
      "time : 372.17419600486755 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10500 ---------\n",
      "loss : 35.950999017456084\n",
      "accuracy : 0.914\n",
      "time : 375.5827679634094 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10600 ---------\n",
      "loss : 34.98215792323262\n",
      "accuracy : 0.91\n",
      "time : 379.03878808021545 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10700 ---------\n",
      "loss : 35.46448638167902\n",
      "accuracy : 0.924\n",
      "time : 382.61411118507385 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10800 ---------\n",
      "loss : 37.10637450136124\n",
      "accuracy : 0.91\n",
      "time : 386.27944111824036 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch10900 ---------\n",
      "loss : 29.58600330706954\n",
      "accuracy : 0.936\n",
      "time : 390.1074080467224 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11000 ---------\n",
      "loss : 34.59862418254367\n",
      "accuracy : 0.916\n",
      "time : 393.7119550704956 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11100 ---------\n",
      "loss : 32.954941013067845\n",
      "accuracy : 0.93\n",
      "time : 397.3200671672821 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11200 ---------\n",
      "loss : 33.37428386052477\n",
      "accuracy : 0.926\n",
      "time : 401.215115070343 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11300 ---------\n",
      "loss : 38.72832012105273\n",
      "accuracy : 0.908\n",
      "time : 405.5268840789795 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11400 ---------\n",
      "loss : 34.50058494452891\n",
      "accuracy : 0.922\n",
      "time : 409.31897616386414 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11500 ---------\n",
      "loss : 33.94016622937451\n",
      "accuracy : 0.93\n",
      "time : 412.91352796554565 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11600 ---------\n",
      "loss : 31.079019213347717\n",
      "accuracy : 0.922\n",
      "time : 416.4754960536957 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11700 ---------\n",
      "loss : 28.256090368230012\n",
      "accuracy : 0.946\n",
      "time : 420.4512541294098 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11800 ---------\n",
      "loss : 30.627056351209138\n",
      "accuracy : 0.93\n",
      "time : 424.03972601890564 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch11900 ---------\n",
      "loss : 29.662127825436734\n",
      "accuracy : 0.928\n",
      "time : 427.39984798431396 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12000 ---------\n",
      "loss : 26.76924604813852\n",
      "accuracy : 0.948\n",
      "time : 430.78962111473083 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12100 ---------\n",
      "loss : 27.897750227086277\n",
      "accuracy : 0.934\n",
      "time : 434.2720420360565 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12200 ---------\n",
      "loss : 27.0559805709304\n",
      "accuracy : 0.948\n",
      "time : 438.3162360191345 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch12300 ---------\n",
      "loss : 31.24153259771832\n",
      "accuracy : 0.918\n",
      "time : 442.4092969894409 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12400 ---------\n",
      "loss : 27.663865750617237\n",
      "accuracy : 0.942\n",
      "time : 446.13337898254395 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12500 ---------\n",
      "loss : 32.3774432931948\n",
      "accuracy : 0.918\n",
      "time : 449.7327780723572 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12600 ---------\n",
      "loss : 34.15178486588829\n",
      "accuracy : 0.918\n",
      "time : 453.2192151546478 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12700 ---------\n",
      "loss : 25.825644139232708\n",
      "accuracy : 0.942\n",
      "time : 456.76302313804626 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12800 ---------\n",
      "loss : 35.37826256107569\n",
      "accuracy : 0.916\n",
      "time : 460.23594999313354 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch12900 ---------\n",
      "loss : 35.25665806010615\n",
      "accuracy : 0.922\n",
      "time : 463.7368710041046 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13000 ---------\n",
      "loss : 27.074816983430892\n",
      "accuracy : 0.954\n",
      "time : 467.3845980167389 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13100 ---------\n",
      "loss : 27.847644184591232\n",
      "accuracy : 0.946\n",
      "time : 470.93882298469543 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13200 ---------\n",
      "loss : 29.399779143172793\n",
      "accuracy : 0.926\n",
      "time : 475.0092661380768 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13300 ---------\n",
      "loss : 29.013213296665285\n",
      "accuracy : 0.942\n",
      "time : 478.87533807754517 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13400 ---------\n",
      "loss : 29.782318819297046\n",
      "accuracy : 0.932\n",
      "time : 482.46174597740173 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13500 ---------\n",
      "loss : 29.44131675285778\n",
      "accuracy : 0.936\n",
      "time : 486.0647830963135 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13600 ---------\n",
      "loss : 23.28941807055601\n",
      "accuracy : 0.958\n",
      "time : 489.8177270889282 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13700 ---------\n",
      "loss : 31.536447407289156\n",
      "accuracy : 0.924\n",
      "time : 493.6301670074463 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13800 ---------\n",
      "loss : 29.160273091059647\n",
      "accuracy : 0.942\n",
      "time : 497.3183870315552 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch13900 ---------\n",
      "loss : 26.98630867713189\n",
      "accuracy : 0.938\n",
      "time : 500.8919870853424 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14000 ---------\n",
      "loss : 28.704877338931674\n",
      "accuracy : 0.934\n",
      "time : 505.5222930908203 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14100 ---------\n",
      "loss : 26.84240348941234\n",
      "accuracy : 0.936\n",
      "time : 512.8522560596466 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14200 ---------\n",
      "loss : 27.110720792895883\n",
      "accuracy : 0.936\n",
      "time : 517.8158030509949 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14300 ---------\n",
      "loss : 29.47362756751999\n",
      "accuracy : 0.934\n",
      "time : 521.5524430274963 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14400 ---------\n",
      "loss : 22.427173845431376\n",
      "accuracy : 0.954\n",
      "time : 525.3267230987549 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14500 ---------\n",
      "loss : 29.45232584376035\n",
      "accuracy : 0.946\n",
      "time : 528.8928761482239 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14600 ---------\n",
      "loss : 27.162552799096396\n",
      "accuracy : 0.938\n",
      "time : 532.6443071365356 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14700 ---------\n",
      "loss : 30.343694403459374\n",
      "accuracy : 0.934\n",
      "time : 536.3817591667175 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14800 ---------\n",
      "loss : 25.488808755222816\n",
      "accuracy : 0.942\n",
      "time : 540.0559849739075 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch14900 ---------\n",
      "loss : 26.196985651957284\n",
      "accuracy : 0.944\n",
      "time : 543.4730710983276 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15000 ---------\n",
      "loss : 25.53147303891437\n",
      "accuracy : 0.94\n",
      "time : 547.3948550224304 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15100 ---------\n",
      "loss : 25.724275346631245\n",
      "accuracy : 0.936\n",
      "time : 551.9748439788818 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15200 ---------\n",
      "loss : 24.265853187377203\n",
      "accuracy : 0.94\n",
      "time : 555.8415501117706 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15300 ---------\n",
      "loss : 24.956314067979577\n",
      "accuracy : 0.952\n",
      "time : 559.8121490478516 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15400 ---------\n",
      "loss : 22.63403398631506\n",
      "accuracy : 0.954\n",
      "time : 563.6639611721039 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15500 ---------\n",
      "loss : 24.020579480982253\n",
      "accuracy : 0.946\n",
      "time : 567.2119870185852 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15600 ---------\n",
      "loss : 29.705420549774907\n",
      "accuracy : 0.936\n",
      "time : 570.6177310943604 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15700 ---------\n",
      "loss : 20.058915580091977\n",
      "accuracy : 0.952\n",
      "time : 574.0201480388641 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15800 ---------\n",
      "loss : 29.17403711138492\n",
      "accuracy : 0.924\n",
      "time : 577.4094481468201 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch15900 ---------\n",
      "loss : 27.197096779200795\n",
      "accuracy : 0.94\n",
      "time : 581.3229100704193 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16000 ---------\n",
      "loss : 23.751809500057732\n",
      "accuracy : 0.95\n",
      "time : 585.9876191616058 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16100 ---------\n",
      "loss : 24.63016623956345\n",
      "accuracy : 0.95\n",
      "time : 589.7005059719086 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16200 ---------\n",
      "loss : 22.48361427898688\n",
      "accuracy : 0.956\n",
      "time : 593.3397250175476 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16300 ---------\n",
      "loss : 21.927135404411736\n",
      "accuracy : 0.958\n",
      "time : 596.8627240657806 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16400 ---------\n",
      "loss : 22.911559064356403\n",
      "accuracy : 0.952\n",
      "time : 600.4120690822601 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16500 ---------\n",
      "loss : 21.31811393220677\n",
      "accuracy : 0.96\n",
      "time : 603.9495561122894 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16600 ---------\n",
      "loss : 21.845541332829292\n",
      "accuracy : 0.954\n",
      "time : 607.5916640758514 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16700 ---------\n",
      "loss : 27.351325326169466\n",
      "accuracy : 0.946\n",
      "time : 611.1304750442505 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16800 ---------\n",
      "loss : 19.935865878520826\n",
      "accuracy : 0.958\n",
      "time : 615.139326095581 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch16900 ---------\n",
      "loss : 27.171504964332478\n",
      "accuracy : 0.938\n",
      "time : 620.0536961555481 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17000 ---------\n",
      "loss : 21.771931026525145\n",
      "accuracy : 0.952\n",
      "time : 623.9548261165619 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17100 ---------\n",
      "loss : 25.626475523677456\n",
      "accuracy : 0.93\n",
      "time : 627.4632000923157 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17200 ---------\n",
      "loss : 24.505325520317115\n",
      "accuracy : 0.948\n",
      "time : 631.0699119567871 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17300 ---------\n",
      "loss : 22.815241381704247\n",
      "accuracy : 0.946\n",
      "time : 635.4116849899292 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17400 ---------\n",
      "loss : 22.583965244727064\n",
      "accuracy : 0.948\n",
      "time : 639.5768339633942 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17500 ---------\n",
      "loss : 27.841004727118495\n",
      "accuracy : 0.94\n",
      "time : 643.168035030365 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17600 ---------\n",
      "loss : 17.06283964339132\n",
      "accuracy : 0.964\n",
      "time : 647.5975670814514 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17700 ---------\n",
      "loss : 24.062792125707315\n",
      "accuracy : 0.948\n",
      "time : 651.2684919834137 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17800 ---------\n",
      "loss : 23.51289415332801\n",
      "accuracy : 0.948\n",
      "time : 655.1229410171509 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch17900 ---------\n",
      "loss : 23.021017611553717\n",
      "accuracy : 0.952\n",
      "time : 658.5836219787598 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18000 ---------\n",
      "loss : 19.56038259552283\n",
      "accuracy : 0.958\n",
      "time : 662.1414370536804 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18100 ---------\n",
      "loss : 24.122322671015194\n",
      "accuracy : 0.946\n",
      "time : 666.0237791538239 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18200 ---------\n",
      "loss : 22.60814174937154\n",
      "accuracy : 0.956\n",
      "time : 669.8268539905548 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch18300 ---------\n",
      "loss : 18.82521428830087\n",
      "accuracy : 0.956\n",
      "time : 673.623859167099 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18400 ---------\n",
      "loss : 24.796673086787155\n",
      "accuracy : 0.948\n",
      "time : 677.6103851795197 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18500 ---------\n",
      "loss : 19.036104575313338\n",
      "accuracy : 0.962\n",
      "time : 681.3620810508728 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18600 ---------\n",
      "loss : 22.363827183858714\n",
      "accuracy : 0.948\n",
      "time : 685.0190961360931 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18700 ---------\n",
      "loss : 21.776192587521855\n",
      "accuracy : 0.956\n",
      "time : 688.966245174408 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18800 ---------\n",
      "loss : 16.006497597675875\n",
      "accuracy : 0.964\n",
      "time : 692.6892940998077 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch18900 ---------\n",
      "loss : 20.075011244756993\n",
      "accuracy : 0.966\n",
      "time : 696.8208479881287 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19000 ---------\n",
      "loss : 21.695503884437784\n",
      "accuracy : 0.946\n",
      "time : 700.280846118927 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19100 ---------\n",
      "loss : 20.966627024413512\n",
      "accuracy : 0.958\n",
      "time : 704.1785509586334 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19200 ---------\n",
      "loss : 18.840273271754132\n",
      "accuracy : 0.956\n",
      "time : 708.5720319747925 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19300 ---------\n",
      "loss : 21.00541247189667\n",
      "accuracy : 0.956\n",
      "time : 712.1039650440216 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19400 ---------\n",
      "loss : 20.72689622123014\n",
      "accuracy : 0.95\n",
      "time : 715.6077871322632 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19500 ---------\n",
      "loss : 17.336202758752115\n",
      "accuracy : 0.968\n",
      "time : 719.4721040725708 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19600 ---------\n",
      "loss : 17.15650383884898\n",
      "accuracy : 0.964\n",
      "time : 723.4172790050507 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19700 ---------\n",
      "loss : 24.484071829313855\n",
      "accuracy : 0.944\n",
      "time : 727.0388531684875 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19800 ---------\n",
      "loss : 22.864693565675946\n",
      "accuracy : 0.948\n",
      "time : 730.7188131809235 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch19900 ---------\n",
      "loss : 17.570760730537437\n",
      "accuracy : 0.966\n",
      "time : 734.3879959583282 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20000 ---------\n",
      "loss : 19.122255106761063\n",
      "accuracy : 0.962\n",
      "time : 738.2875189781189 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20100 ---------\n",
      "loss : 25.068894443039003\n",
      "accuracy : 0.942\n",
      "time : 741.7706260681152 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20200 ---------\n",
      "loss : 17.591540654974267\n",
      "accuracy : 0.958\n",
      "time : 745.1724650859833 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20300 ---------\n",
      "loss : 18.482429837816845\n",
      "accuracy : 0.958\n",
      "time : 748.8070330619812 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20400 ---------\n",
      "loss : 24.096410606740758\n",
      "accuracy : 0.946\n",
      "time : 752.6007239818573 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20500 ---------\n",
      "loss : 24.68858138956962\n",
      "accuracy : 0.95\n",
      "time : 756.2765209674835 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20600 ---------\n",
      "loss : 19.738694882943946\n",
      "accuracy : 0.956\n",
      "time : 761.3547279834747 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20700 ---------\n",
      "loss : 19.80955625433577\n",
      "accuracy : 0.962\n",
      "time : 766.1909201145172 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20800 ---------\n",
      "loss : 21.174713634659707\n",
      "accuracy : 0.954\n",
      "time : 770.2951309680939 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch20900 ---------\n",
      "loss : 19.675096197456185\n",
      "accuracy : 0.958\n",
      "time : 773.7876951694489 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21000 ---------\n",
      "loss : 19.438883997619655\n",
      "accuracy : 0.96\n",
      "time : 777.3675379753113 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21100 ---------\n",
      "loss : 21.026547009637117\n",
      "accuracy : 0.954\n",
      "time : 780.8606281280518 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21200 ---------\n",
      "loss : 20.528900384803777\n",
      "accuracy : 0.954\n",
      "time : 784.4983179569244 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21300 ---------\n",
      "loss : 19.473808635934546\n",
      "accuracy : 0.964\n",
      "time : 788.7428181171417 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21400 ---------\n",
      "loss : 18.23716653791996\n",
      "accuracy : 0.968\n",
      "time : 792.6974210739136 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21500 ---------\n",
      "loss : 13.906290890648737\n",
      "accuracy : 0.974\n",
      "time : 796.178619146347 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21600 ---------\n",
      "loss : 17.09205316663071\n",
      "accuracy : 0.964\n",
      "time : 799.9430911540985 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21700 ---------\n",
      "loss : 19.61945847781817\n",
      "accuracy : 0.96\n",
      "time : 803.4976019859314 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21800 ---------\n",
      "loss : 21.596688824269236\n",
      "accuracy : 0.948\n",
      "time : 807.329617023468 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch21900 ---------\n",
      "loss : 21.840818450990497\n",
      "accuracy : 0.956\n",
      "time : 810.9107210636139 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22000 ---------\n",
      "loss : 18.051847746319005\n",
      "accuracy : 0.958\n",
      "time : 814.7377791404724 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22100 ---------\n",
      "loss : 18.142950702583768\n",
      "accuracy : 0.956\n",
      "time : 818.6813151836395 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22200 ---------\n",
      "loss : 14.999661881238584\n",
      "accuracy : 0.97\n",
      "time : 823.3227529525757 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22300 ---------\n",
      "loss : 19.866662849953528\n",
      "accuracy : 0.952\n",
      "time : 826.9085810184479 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22400 ---------\n",
      "loss : 20.24012015352236\n",
      "accuracy : 0.956\n",
      "time : 830.5094549655914 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22500 ---------\n",
      "loss : 18.272443729752432\n",
      "accuracy : 0.954\n",
      "time : 834.1413791179657 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22600 ---------\n",
      "loss : 16.280474175853456\n",
      "accuracy : 0.966\n",
      "time : 837.8683099746704 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22700 ---------\n",
      "loss : 18.265980079925306\n",
      "accuracy : 0.962\n",
      "time : 841.3870360851288 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22800 ---------\n",
      "loss : 17.18112656103444\n",
      "accuracy : 0.964\n",
      "time : 844.7882890701294 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch22900 ---------\n",
      "loss : 19.419019064157947\n",
      "accuracy : 0.964\n",
      "time : 848.1636710166931 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23000 ---------\n",
      "loss : 22.489093390620255\n",
      "accuracy : 0.95\n",
      "time : 851.6608030796051 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23100 ---------\n",
      "loss : 16.815940898804136\n",
      "accuracy : 0.962\n",
      "time : 855.4234721660614 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23200 ---------\n",
      "loss : 17.07492254446469\n",
      "accuracy : 0.966\n",
      "time : 858.9969849586487 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23300 ---------\n",
      "loss : 18.70104902285307\n",
      "accuracy : 0.962\n",
      "time : 862.4946231842041 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23400 ---------\n",
      "loss : 12.247484055276985\n",
      "accuracy : 0.986\n",
      "time : 866.2029340267181 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23500 ---------\n",
      "loss : 15.141366599980397\n",
      "accuracy : 0.972\n",
      "time : 869.7983231544495 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23600 ---------\n",
      "loss : 18.41789834961073\n",
      "accuracy : 0.962\n",
      "time : 873.1938209533691 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23700 ---------\n",
      "loss : 18.514136100592097\n",
      "accuracy : 0.956\n",
      "time : 876.6370360851288 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23800 ---------\n",
      "loss : 12.72444498273284\n",
      "accuracy : 0.974\n",
      "time : 880.0463919639587 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch23900 ---------\n",
      "loss : 15.468791007632618\n",
      "accuracy : 0.97\n",
      "time : 883.9741911888123 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24000 ---------\n",
      "loss : 19.82758673460675\n",
      "accuracy : 0.954\n",
      "time : 887.4410631656647 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24100 ---------\n",
      "loss : 17.21386383464384\n",
      "accuracy : 0.97\n",
      "time : 890.9775149822235 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24200 ---------\n",
      "loss : 13.86643354755946\n",
      "accuracy : 0.978\n",
      "time : 894.4873349666595 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24300 ---------\n",
      "loss : 15.823084660645398\n",
      "accuracy : 0.96\n",
      "time : 898.0227410793304 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch24400 ---------\n",
      "loss : 15.986897410071016\n",
      "accuracy : 0.966\n",
      "time : 901.5173380374908 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24500 ---------\n",
      "loss : 21.380167484954633\n",
      "accuracy : 0.954\n",
      "time : 904.9833111763 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24600 ---------\n",
      "loss : 20.58288981612482\n",
      "accuracy : 0.946\n",
      "time : 908.3541691303253 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24700 ---------\n",
      "loss : 15.713830830579884\n",
      "accuracy : 0.966\n",
      "time : 911.8950431346893 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24800 ---------\n",
      "loss : 13.845037538015449\n",
      "accuracy : 0.972\n",
      "time : 915.6861779689789 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch24900 ---------\n",
      "loss : 12.048962347052587\n",
      "accuracy : 0.976\n",
      "time : 919.9044160842896 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25000 ---------\n",
      "loss : 17.162811876339248\n",
      "accuracy : 0.964\n",
      "time : 923.4715349674225 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25100 ---------\n",
      "loss : 16.668954983414892\n",
      "accuracy : 0.962\n",
      "time : 927.6342620849609 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25200 ---------\n",
      "loss : 13.815234809155994\n",
      "accuracy : 0.976\n",
      "time : 931.2904579639435 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25300 ---------\n",
      "loss : 16.47897418330283\n",
      "accuracy : 0.956\n",
      "time : 934.6702830791473 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25400 ---------\n",
      "loss : 18.777132598337328\n",
      "accuracy : 0.958\n",
      "time : 938.1019601821899 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25500 ---------\n",
      "loss : 14.547021432010329\n",
      "accuracy : 0.97\n",
      "time : 941.4693751335144 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25600 ---------\n",
      "loss : 14.508549004346374\n",
      "accuracy : 0.972\n",
      "time : 945.4438920021057 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25700 ---------\n",
      "loss : 16.299833024145048\n",
      "accuracy : 0.96\n",
      "time : 949.3184280395508 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25800 ---------\n",
      "loss : 19.809060914514873\n",
      "accuracy : 0.958\n",
      "time : 953.4390699863434 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch25900 ---------\n",
      "loss : 12.118092561601381\n",
      "accuracy : 0.98\n",
      "time : 957.2238440513611 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26000 ---------\n",
      "loss : 11.875303969401998\n",
      "accuracy : 0.978\n",
      "time : 960.9307370185852 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26100 ---------\n",
      "loss : 16.843284767075556\n",
      "accuracy : 0.96\n",
      "time : 964.5132730007172 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26200 ---------\n",
      "loss : 16.143454901294543\n",
      "accuracy : 0.966\n",
      "time : 967.9412121772766 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26300 ---------\n",
      "loss : 13.235708605835118\n",
      "accuracy : 0.972\n",
      "time : 971.7809309959412 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26400 ---------\n",
      "loss : 12.08486643971117\n",
      "accuracy : 0.976\n",
      "time : 975.3048729896545 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26500 ---------\n",
      "loss : 14.62263128835251\n",
      "accuracy : 0.968\n",
      "time : 979.120884180069 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26600 ---------\n",
      "loss : 16.529085298551397\n",
      "accuracy : 0.964\n",
      "time : 982.6175310611725 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26700 ---------\n",
      "loss : 11.142693585632664\n",
      "accuracy : 0.982\n",
      "time : 986.1247260570526 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26800 ---------\n",
      "loss : 15.741480009115335\n",
      "accuracy : 0.968\n",
      "time : 989.6908760070801 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch26900 ---------\n",
      "loss : 13.141463324762405\n",
      "accuracy : 0.97\n",
      "time : 993.493047952652 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27000 ---------\n",
      "loss : 10.937443588646858\n",
      "accuracy : 0.984\n",
      "time : 997.4821181297302 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27100 ---------\n",
      "loss : 19.52208163056472\n",
      "accuracy : 0.956\n",
      "time : 1001.071408033371 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27200 ---------\n",
      "loss : 16.16936818132079\n",
      "accuracy : 0.962\n",
      "time : 1004.3930101394653 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27300 ---------\n",
      "loss : 14.592709858746712\n",
      "accuracy : 0.974\n",
      "time : 1008.0119349956512 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27400 ---------\n",
      "loss : 16.283895545557783\n",
      "accuracy : 0.962\n",
      "time : 1011.7764191627502 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27500 ---------\n",
      "loss : 18.185912861376856\n",
      "accuracy : 0.96\n",
      "time : 1015.5097739696503 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27600 ---------\n",
      "loss : 18.291910833415155\n",
      "accuracy : 0.95\n",
      "time : 1019.7153241634369 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27700 ---------\n",
      "loss : 12.39877421659432\n",
      "accuracy : 0.976\n",
      "time : 1023.6935181617737 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27800 ---------\n",
      "loss : 14.719298106789001\n",
      "accuracy : 0.968\n",
      "time : 1027.6022219657898 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch27900 ---------\n",
      "loss : 13.175094112060075\n",
      "accuracy : 0.972\n",
      "time : 1031.172993183136 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28000 ---------\n",
      "loss : 12.127484789988031\n",
      "accuracy : 0.982\n",
      "time : 1034.6753101348877 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28100 ---------\n",
      "loss : 15.432201842964115\n",
      "accuracy : 0.966\n",
      "time : 1038.662204027176 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28200 ---------\n",
      "loss : 15.510090131693106\n",
      "accuracy : 0.97\n",
      "time : 1043.264829158783 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28300 ---------\n",
      "loss : 13.444359145768612\n",
      "accuracy : 0.966\n",
      "time : 1046.9787640571594 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28400 ---------\n",
      "loss : 13.449621545124733\n",
      "accuracy : 0.97\n",
      "time : 1050.5256280899048 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28500 ---------\n",
      "loss : 16.327452170001497\n",
      "accuracy : 0.962\n",
      "time : 1054.0676319599152 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28600 ---------\n",
      "loss : 15.170959194524318\n",
      "accuracy : 0.962\n",
      "time : 1057.4927070140839 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28700 ---------\n",
      "loss : 13.577975592649096\n",
      "accuracy : 0.966\n",
      "time : 1061.031012058258 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28800 ---------\n",
      "loss : 11.1032436353946\n",
      "accuracy : 0.98\n",
      "time : 1064.5701801776886 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch28900 ---------\n",
      "loss : 15.271086079471274\n",
      "accuracy : 0.962\n",
      "time : 1068.5654480457306 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29000 ---------\n",
      "loss : 10.187124939666202\n",
      "accuracy : 0.978\n",
      "time : 1072.7189741134644 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29100 ---------\n",
      "loss : 13.991262332202474\n",
      "accuracy : 0.968\n",
      "time : 1076.951059103012 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29200 ---------\n",
      "loss : 13.140314671863493\n",
      "accuracy : 0.976\n",
      "time : 1081.3351140022278 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29300 ---------\n",
      "loss : 14.2596784273657\n",
      "accuracy : 0.968\n",
      "time : 1084.823147058487 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29400 ---------\n",
      "loss : 12.191620013308068\n",
      "accuracy : 0.972\n",
      "time : 1088.404452085495 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29500 ---------\n",
      "loss : 11.375054777431874\n",
      "accuracy : 0.976\n",
      "time : 1091.880639076233 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29600 ---------\n",
      "loss : 12.606753352047884\n",
      "accuracy : 0.978\n",
      "time : 1095.4426391124725 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29700 ---------\n",
      "loss : 12.491576179620559\n",
      "accuracy : 0.974\n",
      "time : 1099.638955116272 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29800 ---------\n",
      "loss : 12.699541663464451\n",
      "accuracy : 0.972\n",
      "time : 1103.5961849689484 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch29900 ---------\n",
      "loss : 11.854542555683583\n",
      "accuracy : 0.978\n",
      "time : 1107.6008310317993 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30000 ---------\n",
      "loss : 17.560928141993703\n",
      "accuracy : 0.968\n",
      "time : 1111.631599187851 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30100 ---------\n",
      "loss : 12.04617719131517\n",
      "accuracy : 0.978\n",
      "time : 1115.8262650966644 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30200 ---------\n",
      "loss : 12.139865113616873\n",
      "accuracy : 0.98\n",
      "time : 1119.4011421203613 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30300 ---------\n",
      "loss : 13.603256519108918\n",
      "accuracy : 0.968\n",
      "time : 1122.871127128601 [sec]\n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- epoch30400 ---------\n",
      "loss : 13.613004833892148\n",
      "accuracy : 0.968\n",
      "time : 1126.4323210716248 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30500 ---------\n",
      "loss : 17.013886008222876\n",
      "accuracy : 0.964\n",
      "time : 1129.855885028839 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30600 ---------\n",
      "loss : 13.180691771563305\n",
      "accuracy : 0.974\n",
      "time : 1133.5940310955048 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30700 ---------\n",
      "loss : 9.071542903569092\n",
      "accuracy : 0.986\n",
      "time : 1137.5101871490479 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30800 ---------\n",
      "loss : 9.420515730472202\n",
      "accuracy : 0.976\n",
      "time : 1142.0490341186523 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch30900 ---------\n",
      "loss : 12.077464621544205\n",
      "accuracy : 0.976\n",
      "time : 1145.8741099834442 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31000 ---------\n",
      "loss : 12.7228347409381\n",
      "accuracy : 0.974\n",
      "time : 1149.9425911903381 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31100 ---------\n",
      "loss : 10.13173638909485\n",
      "accuracy : 0.98\n",
      "time : 1153.5167980194092 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31200 ---------\n",
      "loss : 7.4515554860047\n",
      "accuracy : 0.992\n",
      "time : 1157.7275350093842 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31300 ---------\n",
      "loss : 13.294160029380588\n",
      "accuracy : 0.966\n",
      "time : 1161.8273379802704 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31400 ---------\n",
      "loss : 11.319932000585661\n",
      "accuracy : 0.978\n",
      "time : 1165.8906691074371 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31500 ---------\n",
      "loss : 14.34935574394564\n",
      "accuracy : 0.962\n",
      "time : 1169.3361780643463 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31600 ---------\n",
      "loss : 10.430245940749206\n",
      "accuracy : 0.978\n",
      "time : 1172.784056186676 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31700 ---------\n",
      "loss : 14.13101499022179\n",
      "accuracy : 0.966\n",
      "time : 1176.607966184616 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31800 ---------\n",
      "loss : 9.979318470162758\n",
      "accuracy : 0.982\n",
      "time : 1181.1548190116882 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch31900 ---------\n",
      "loss : 12.775754790574664\n",
      "accuracy : 0.976\n",
      "time : 1184.9657020568848 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32000 ---------\n",
      "loss : 10.513310417065217\n",
      "accuracy : 0.978\n",
      "time : 1188.5056171417236 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32100 ---------\n",
      "loss : 10.805327892626579\n",
      "accuracy : 0.978\n",
      "time : 1192.0154249668121 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32200 ---------\n",
      "loss : 9.527469116051078\n",
      "accuracy : 0.978\n",
      "time : 1195.4146931171417 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32300 ---------\n",
      "loss : 8.283816334481493\n",
      "accuracy : 0.99\n",
      "time : 1199.1247041225433 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32400 ---------\n",
      "loss : 13.043218176004716\n",
      "accuracy : 0.972\n",
      "time : 1203.3415729999542 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32500 ---------\n",
      "loss : 9.544177909776284\n",
      "accuracy : 0.98\n",
      "time : 1206.9877171516418 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32600 ---------\n",
      "loss : 12.982889107564759\n",
      "accuracy : 0.97\n",
      "time : 1211.044272184372 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32700 ---------\n",
      "loss : 9.116059866889803\n",
      "accuracy : 0.984\n",
      "time : 1214.8775000572205 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32800 ---------\n",
      "loss : 9.635938111875555\n",
      "accuracy : 0.984\n",
      "time : 1218.8415060043335 [sec]\n",
      "------------------------------\n",
      "\n",
      "--------- epoch32900 ---------\n",
      "loss : 12.478271749574883\n",
      "accuracy : 0.978\n",
      "time : 1222.6063981056213 [sec]\n",
      "------------------------------\n",
      "\n",
      "\n",
      "\n",
      "<< All training epochs ended. >>\n",
      "========= result =========\n",
      "Elapsed time : 1226.3995361328125 [sec]\n",
      "Train set accuracy : 0.975\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "elapsed_time,train_acc = net.train(x_train,t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.975\n",
      "test accuracy : 0.8801\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy : {}\\ntest accuracy : {}'.format(\n",
    "    net.accuracy(x_train,t_train),net.accuracy(x_test,t_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb50821c278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully network was constructed!\n"
     ]
    }
   ],
   "source": [
    "name = 'train_0.9904,test_0.904'\n",
    "net = neuralNetwork.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.326\n",
      "epoch : 101, loss : 0.0313\n",
      "epoch : 201, loss : 0.024\n",
      "epoch : 301, loss : 0.0174\n",
      "epoch : 401, loss : 0.0159\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device('cpu')\n",
    "model = MLP(784,400,50,10).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "def compute_loss(t,y):\n",
    "    return criterion(y,t)\n",
    "\n",
    "def train_step(x,t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    #print(preds.shape)\n",
    "    loss = compute_loss(t,preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 500\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    batch = np.random.choice(x_train.shape[0],batch_size)\n",
    "    x_ = x_train[batch]\n",
    "    t_ = t_train[batch]\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    t_ = torch.Tensor(t_).to(device)\n",
    "    \n",
    "    loss = train_step(x_,t_)\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        \n",
    "        print('epoch : {}, loss : {:.3}'.format(\n",
    "            epoch + 1,\n",
    "            train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc : 0.979, test_acc : 0.893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def test_step(x,t):\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t,preds)\n",
    "    return loss,preds\n",
    "\n",
    "test_loss,test_preds = test_step(x_test,t_test)\n",
    "train_loss,train_preds = test_step(x_train,t_train)\n",
    "test_loss = test_loss.item()\n",
    "train_loss = train_loss.item()\n",
    "test_preds = np.argmax(test_preds.data.cpu().numpy(),axis=1)\n",
    "train_preds = np.argmax(train_preds.data.cpu().numpy(),axis=1)\n",
    "test_ans = np.argmax(t_test,axis=1)\n",
    "test_acc = accuracy_score(test_ans,test_preds)\n",
    "train_ans = np.argmax(t_train,axis=1)\n",
    "train_acc = accuracy_score(train_ans,train_preds)\n",
    "\n",
    "print('train_acc : {:.3f}, test_acc : {:.3f}'.format(\n",
    "    train_acc,\n",
    "    test_acc\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1208e-04, 5.7649e-04, 1.5671e-03, 4.2597e-03, 1.1579e-02, 3.1475e-02,\n",
       "         8.5559e-02, 2.3257e-01, 6.3220e-01]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5,6,7,8,9]])\n",
    "a = torch.Tensor(a).to(device)\n",
    "l = nn.Softmax(dim = 1)\n",
    "l(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim_1,\n",
    "        hidden_dim_2,\n",
    "        output_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim,hidden_dim_1)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim_1,hidden_dim_2)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(hidden_dim_2,output_dim)\n",
    "        self.a3 = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.layers = [self.l1,self.a1,self.l2,self.a2,self.l3,self.a3]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,train = True):\n",
    "        x_train = np.load('./datasets/kmnist-train-imgs.npz')['arr_0']\n",
    "        t_train = np.load('./datasets/kmnist-train-labels.npz')['arr_0']\n",
    "        x_test = np.load('./datasets/kmnist-test-imgs.npz')['arr_0']\n",
    "        t_test = np.load('./datasets/kmnist-test-labels.npz')['arr_0']\n",
    "\n",
    "        t_train = np.identity(10)[t_train]\n",
    "        t_test = np.identity(10)[t_test]\n",
    "        x_train = x_train.reshape((60000,-1)).astype(float)\n",
    "        x_test = x_test.reshape((10000,-1)).astype(float)\n",
    "        x_train = x_train/255\n",
    "        x_test = x_test/255\n",
    "        if train:\n",
    "            #self.x = torch.from_numpy(x_train).float\n",
    "            #self.t = torch.from_numpy(t_train).long\n",
    "            self.x = x_train\n",
    "            self.t = t_train\n",
    "            self.size = x_train.shape[0]\n",
    "        else:\n",
    "            #self.x = torch.from_numpy(x_test).float\n",
    "            #self.t = torch.from_numpy(t_test).long\n",
    "            self.x = x_test\n",
    "            self.t = t_test\n",
    "            self.size = x_test.shape[0]\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.t[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kuzushijiMNIST(batch_size = 500):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(True),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Dataset(False),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train' : train_loader,\n",
    "        'test' : test_loader\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "history = {\n",
    "    'train_loss' : [],\n",
    "    'test_loss' : [],\n",
    "    'test_acc' : []\n",
    "}\n",
    "\n",
    "net = Net(784,400,40,10)\n",
    "loaders = load_kuzushijiMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0157, 0.7804, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0471, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0039, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4824, 0.4000, 0.1255],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0627, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4549,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9412, 0.0941, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.7569, 0.1451, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5216, 0.5412, 0.0353]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.2745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6824, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0745, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0980, 0.2627,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0431, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0157, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.6118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.9843, 0.3020, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0353,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0784, 0.1765, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0118, 0.1490,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0588, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.5804, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.8941, 0.3490, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.9529, 0.3098, 0.0039],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0118, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2902, 0.0784, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0314, 0.1922],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3216, 0.1451, 0.0196],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.2706,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.3843, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.4235, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0627, 0.3137, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.1216, 0.8824, 0.1765,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.2314, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6118, 0.9843, 0.6118,  ..., 0.4824, 0.0078, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for data,target in loaders['train']:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(params = net.parameters(),lr = 0.01)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1,batch : 128/60000,loss : 0.32562965154647827\n",
      "epoch : 1,batch : 1408/60000,loss : 0.15830664336681366\n",
      "epoch : 1,batch : 2688/60000,loss : 0.10345988720655441\n",
      "epoch : 1,batch : 3968/60000,loss : 0.07579276710748672\n",
      "epoch : 1,batch : 5248/60000,loss : 0.07180974632501602\n",
      "epoch : 1,batch : 6528/60000,loss : 0.07020606100559235\n",
      "epoch : 1,batch : 7808/60000,loss : 0.060317933559417725\n",
      "epoch : 1,batch : 9088/60000,loss : 0.05069664120674133\n",
      "epoch : 1,batch : 10368/60000,loss : 0.05856812745332718\n",
      "epoch : 1,batch : 11648/60000,loss : 0.04413367435336113\n",
      "epoch : 1,batch : 12928/60000,loss : 0.039065614342689514\n",
      "epoch : 1,batch : 14208/60000,loss : 0.047319211065769196\n",
      "test accuracy : 0.8411\n",
      "epoch : 2,batch : 128/60000,loss : 0.03204628825187683\n",
      "epoch : 2,batch : 1408/60000,loss : 0.025458727031946182\n",
      "epoch : 2,batch : 2688/60000,loss : 0.03425682336091995\n",
      "epoch : 2,batch : 3968/60000,loss : 0.028589818626642227\n",
      "epoch : 2,batch : 5248/60000,loss : 0.02421424724161625\n",
      "epoch : 2,batch : 6528/60000,loss : 0.02936953492462635\n",
      "epoch : 2,batch : 7808/60000,loss : 0.023337045684456825\n",
      "epoch : 2,batch : 9088/60000,loss : 0.030201995745301247\n",
      "epoch : 2,batch : 10368/60000,loss : 0.03466672822833061\n",
      "epoch : 2,batch : 11648/60000,loss : 0.023305097594857216\n",
      "epoch : 2,batch : 12928/60000,loss : 0.026867486536502838\n",
      "epoch : 2,batch : 14208/60000,loss : 0.03513367101550102\n",
      "test accuracy : 0.8708\n",
      "epoch : 3,batch : 128/60000,loss : 0.02319392003118992\n",
      "epoch : 3,batch : 1408/60000,loss : 0.01709127239882946\n",
      "epoch : 3,batch : 2688/60000,loss : 0.018111469224095345\n",
      "epoch : 3,batch : 3968/60000,loss : 0.014557821676135063\n",
      "epoch : 3,batch : 5248/60000,loss : 0.01512590330094099\n",
      "epoch : 3,batch : 6528/60000,loss : 0.017109690234065056\n",
      "epoch : 3,batch : 7808/60000,loss : 0.017189402133226395\n",
      "epoch : 3,batch : 9088/60000,loss : 0.019132234156131744\n",
      "epoch : 3,batch : 10368/60000,loss : 0.020565830171108246\n",
      "epoch : 3,batch : 11648/60000,loss : 0.018769145011901855\n",
      "epoch : 3,batch : 12928/60000,loss : 0.01944355107843876\n",
      "epoch : 3,batch : 14208/60000,loss : 0.01974104717373848\n",
      "test accuracy : 0.8862\n",
      "epoch : 4,batch : 128/60000,loss : 0.011614253744482994\n",
      "epoch : 4,batch : 1408/60000,loss : 0.012034856714308262\n",
      "epoch : 4,batch : 2688/60000,loss : 0.009736406616866589\n",
      "epoch : 4,batch : 3968/60000,loss : 0.021139031276106834\n",
      "epoch : 4,batch : 5248/60000,loss : 0.015447190962731838\n",
      "epoch : 4,batch : 6528/60000,loss : 0.013809082098305225\n",
      "epoch : 4,batch : 7808/60000,loss : 0.010202538222074509\n",
      "epoch : 4,batch : 9088/60000,loss : 0.013362913392484188\n",
      "epoch : 4,batch : 10368/60000,loss : 0.026109125465154648\n",
      "epoch : 4,batch : 11648/60000,loss : 0.011653976514935493\n",
      "epoch : 4,batch : 12928/60000,loss : 0.020759090781211853\n",
      "epoch : 4,batch : 14208/60000,loss : 0.016076456755399704\n",
      "test accuracy : 0.8965\n",
      "epoch : 5,batch : 128/60000,loss : 0.012907855212688446\n",
      "epoch : 5,batch : 1408/60000,loss : 0.01028241217136383\n",
      "epoch : 5,batch : 2688/60000,loss : 0.011401785537600517\n",
      "epoch : 5,batch : 3968/60000,loss : 0.013149754144251347\n",
      "epoch : 5,batch : 5248/60000,loss : 0.014900248497724533\n",
      "epoch : 5,batch : 6528/60000,loss : 0.010914977639913559\n",
      "epoch : 5,batch : 7808/60000,loss : 0.013847623020410538\n",
      "epoch : 5,batch : 9088/60000,loss : 0.014637126587331295\n",
      "epoch : 5,batch : 10368/60000,loss : 0.01335443090647459\n",
      "epoch : 5,batch : 11648/60000,loss : 0.014864697121083736\n",
      "epoch : 5,batch : 12928/60000,loss : 0.01892690733075142\n",
      "epoch : 5,batch : 14208/60000,loss : 0.020673399791121483\n",
      "test accuracy : 0.8996\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    loss = None\n",
    "    net.train()\n",
    "    \n",
    "    for j ,(data,target) in enumerate(loaders['train']):\n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        #print('flag')\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 10 == 0:\n",
    "            print('epoch : {},batch : {}/60000,loss : {}'.format(\n",
    "                i+1,\n",
    "                (j+1)*128,\n",
    "                loss.item()\n",
    "            ))\n",
    "    history['train_loss'].append(loss)\n",
    "    \n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data,target in loaders['test']:\n",
    "            data = data.float()\n",
    "            target = target.float()\n",
    "            output = net(data)\n",
    "            test_loss += criterion(output,target).item()\n",
    "            pred = output.argmax(dim=1,keepdim = False)\n",
    "            ans = target.argmax(dim = 1,keepdim=False)\n",
    "            correct += (pred == ans).sum().item()\n",
    "    test_loss /= 10000\n",
    "    \n",
    "    print('test accuracy : {}'.format(correct/10000))\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(correct/10000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
